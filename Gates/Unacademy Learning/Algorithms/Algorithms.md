# Algorithms

## Course Link

* Link -> https://unacademy.com/course/complete-course-on-algorithm-768/MKL1PBOY

## Syllabus

![image](https://user-images.githubusercontent.com/54589605/229165900-6a29602a-d898-4e24-ba8c-b402cc2fe2bc.png)


## Time Complexity (1) [31st March 2023]

![image](https://user-images.githubusercontent.com/54589605/229171932-718dbe68-e46e-4d3a-9207-ba295985e033.png)
![image](https://user-images.githubusercontent.com/54589605/229172682-b9f36d76-c52d-48e8-94b1-b39b77cc24c7.png)

> Algorithm is a combination of sequence of finite steps to solve a problem.

> Combination of some(finite) statements.

> Algorithms is a generic programming language. From one language to another language, syntax will change a little bit.

![image](https://user-images.githubusercontent.com/54589605/229176423-2a904b6d-7ac9-4198-b545-c33c994860a3.png)
![image](https://user-images.githubusercontent.com/54589605/229176605-da580b3a-d2b3-4a93-8594-a39d3d26a44d.png)

> After writing the **algorithm**, we can write it in some **programming language** also.

> Algorithm is for **humans**. If we write the algorithm in some **programming language** then the computer will understand.

> We will first write **algorithm** then we will write **program**.

> We have an **algorithm** and we want to convert it into a **programming language**, the programming language we will **choose/prefer** depends on the **use case or what problem it is solving**.

![image](https://user-images.githubusercontent.com/54589605/229180078-515d676f-6e4f-4bee-bcda-7331c2708762.png)

## Programming of Algorithm

> Finite steps doesn't mean finite time.

![image](https://user-images.githubusercontent.com/54589605/229281293-38ed4065-ceb0-4780-93d2-c3050eceb2c7.png)

> It is a program but not an algorithm. Every algorithm is a **program** but every program is not an **algorithm**. Program may halt and may not halt. Program is a **turing machine**. For a problem, algorithm is possible which means **HTM or halt turing machine** is possible.

![image](https://user-images.githubusercontent.com/54589605/229282357-a3fe704d-1501-4054-a8a5-254fd4513ed8.png)

> Algorithm possible means program possible. Program possible doesn't mean algorithm possible. Program contains **infinite loop**.

* Difference between algo and program?

> Program may stop and may not stop. It may go to **infinite loop**. Algorithm has to **stop**. So, algorithm is a **HTM or halt turing machine**.

* Algorithm -> **HTM or halt turing machine** -> It will terminate after finite time.
* Program -> **Turing machine**

![image](https://user-images.githubusercontent.com/54589605/229284887-1973e0f8-56bf-4df2-b297-536a21c086c0.png)
![image](https://user-images.githubusercontent.com/54589605/229286759-629bf52e-d197-41e0-8ddb-e82cd7dc30e7.png)
![image](https://user-images.githubusercontent.com/54589605/229286825-a414e8e6-9eb8-436c-b6cd-b730b3a01259.png)
![image](https://user-images.githubusercontent.com/54589605/229286830-527b2280-b8a7-4520-92f7-6accfcf33014.png)

1) It should terminate after finite time
2) It should provide atleast one output
3) It should be deterministic
4) Every statement in algo should be effective
5) It is independent of **programming language**.

## Time Complexity-II (2) [1st April 2023]

## Steps to design algorithm for given problem

> With them procedures if we construct an algorithm then the properties are satisfied.

![image](https://user-images.githubusercontent.com/54589605/229287724-0cedcdd3-bb21-4f89-9a5e-5ae8ce210566.png)

1) Problem Definition
2) Select designing technique
3) Draw Flowchart
4) Testing
5) Implementation means coding
6) Analysis

> We have **3** designing technique in the syllabus, **Divide and conquor, Greedy and Dynamic programming**. There are **2** more which are not in syllabus, **Backtracking, branch and bound**.

![image](https://user-images.githubusercontent.com/54589605/229289909-51c4fa62-338b-41e4-bb61-454b75f7b46d.png)
![image](https://user-images.githubusercontent.com/54589605/229290767-b5f3187d-8d0f-46c9-bfe2-e51685df4a36.png)
![image](https://user-images.githubusercontent.com/54589605/229290775-9caa7490-667e-4aca-bc7d-b4e93a659269.png)

## Analysis

1) Finding Time and space complexity
2) 

![image](https://user-images.githubusercontent.com/54589605/229291429-c0f0a728-8db9-4a84-87ba-539ac61b0edb.png)

> Better solution will be provided by **analysis**. If **time complexity** is **same** then go for **space complexity**.

![image](https://user-images.githubusercontent.com/54589605/229291609-9b22ec38-09b3-483a-84f6-66f9a3004250.png)

> If the question, simply asks for **which is better**?

* Then give chance to **time** first.

> If the problem having more than one algo?

* Then, the **best one** is decided based on **time complexity(CPU time)** and **space complexity(Main memory)**. 

![image](https://user-images.githubusercontent.com/54589605/229291954-08421313-1964-4260-a96b-fe371dbd3b86.png)
![image](https://user-images.githubusercontent.com/54589605/229292024-04f749de-c1bc-4f97-ad92-571dde3894fb.png)

## Time Complexity

* 'p' is a program 
* Time complexity or T(p) = Compile time or C(p) + Running time or R(p).

![image](https://user-images.githubusercontent.com/54589605/229299347-0bf03c23-4020-44b1-95ef-9d4adfd22510.png)

> **Time complexity of a program** is **based/dependent** on the **language of the compiler and type of processor**.

## Types of Analysis

1) **Aposteriori analysis** -> **Based/Dependent** on the **language of the compiler and type of processor**. Exact answer. Computer-computer time complexity changes.
2) **Apriori analysis** -> **Independent** of the **language of the compiler and type of processor**. Appropriate answer. Same answer in every computer.

![image](https://user-images.githubusercontent.com/54589605/229301833-7e8fddfa-f9a4-426e-a75c-dfffb02db141.png)
![image](https://user-images.githubusercontent.com/54589605/229302215-e54baa48-232c-4b3c-84ba-cde47fabf1c9.png)

> According to **Apriori analysis**, everyone cannot buy **super computer** but everyone can write **super algorithm** because god gave **same  brain** to all.

![image](https://user-images.githubusercontent.com/54589605/229303214-bb14f85c-420c-432f-b7ea-29822503ed5d.png)

> Some poeple use it effictively and some not. Some people believe in themselves and some not.

## Apriori analysis

> Instead of saying **best logic**, they are saying it in some other way like **employee of the month**.

> It is a determination of order of magnitude of a statement.

> It is **indirectly** talking about **logic**.


> While running, the statement will run only **once or one time only**. This **once or one time** is called as **order of magnitude**.

> **Order of magnitude** of a statement means that while running **the statement will be executed by the processor for how many times**. So add **theta** to it  and it will be like **theta(1)** then it is called as the **time complexity**.
 
 > The **order of magnitude** with **theta symbol** is called as **time complexity**.
 
![image](https://user-images.githubusercontent.com/54589605/229303840-d1c8f434-032c-4829-b799-61ffe5cbcd41.png)
![image](https://user-images.githubusercontent.com/54589605/229303934-0a4124ee-a413-45e5-9932-7f79a6c79c4e.png)

> Every **constant** can be represented as **theta(1)**.
 
![image](https://user-images.githubusercontent.com/54589605/229304161-b151ec85-0e26-4aff-9e02-a7c369d48fde.png)
![image](https://user-images.githubusercontent.com/54589605/229304170-fc834516-18d4-46fe-96e8-2cbcfe57f76c.png)

> **1** will be **executed** once only.

![image](https://user-images.githubusercontent.com/54589605/229304857-4f848126-5396-4993-9cb7-376c255bbd16.png)

> So, time complexity is **theta(n)**. We are ignoring the  **small constant**. **Small constant** are nothing but **processor's speed**.

![image](https://user-images.githubusercontent.com/54589605/229305044-dbc08dca-7151-44b0-8db3-708cc2368385.png)

> We don't need to go **inside**. It still gives the **same analysis**.

## Time Complexity-III (3) [2nd April 2023]

> We have **3** statements here

> We are doing **approximate** analysis. Small things(constants) don't matter. Functions matter.

> Inner for loops are nothing but **product rule**.

* Inner loops -> Multiply
* Outer loops -> Add

![image](https://user-images.githubusercontent.com/54589605/229334747-af798f6b-fe13-4adc-9eb5-9478430d40dc.png)

> **Theta** means we can write **Omega and big O**. But **big O** doesn't mean **theta** and **Omega** doesn't mean **theta**.

> **Theta** work means **Omega and big O** will work also. We are not saying **reverse** is possible.

![image](https://user-images.githubusercontent.com/54589605/229334991-150870f6-5a3d-4d4e-b26d-9c6c079dacbd.png)

> According to **Apriori** analysis, **time complexity** is nothing but **finding loops only but also larger loops as well**.

> **Time complexity** is finding **where the cpu is spending the more time**.

> If **no loops** is there in the program **O(1) or constant**

> If **one loop** is there in the program **O(n) or linear**.

* What is kept in the cache memory?

> It doesn't have much storage, so we keep the **valuable content** in it.

* What is the **valuable content**?

> **bigger loops**, because it is the place where CPU spending a lot of time.

![image](https://user-images.githubusercontent.com/54589605/229339523-88dcd9f7-f142-4b1a-8da1-cb5e543d624d.png)
![image](https://user-images.githubusercontent.com/54589605/229339552-ff559af1-fc12-427d-ae30-04325d873e20.png)
![image](https://user-images.githubusercontent.com/54589605/229339577-2e4ad668-2cc8-4bb6-8b86-bd778f8658ad.png)

> In the first loop, condition is **True** for **'n' times**.

> In the fourth loop, condition is **True** for **'n^(1/2) or sqrt(n)' times**.

![image](https://user-images.githubusercontent.com/54589605/229339992-99d7aece-35f9-4103-b075-fd5a84499c44.png)
![image](https://user-images.githubusercontent.com/54589605/229340135-0bb65e07-ec0e-4ef4-8f00-adfb0ebee439.png)
![image](https://user-images.githubusercontent.com/54589605/229340464-e42a3e51-ed88-4ef3-83df-82afe298a2ad.png)

* pf -> printf();

![image](https://user-images.githubusercontent.com/54589605/229340590-0b238405-e873-4e9a-954d-59c4b5d0aac2.png)
![image](https://user-images.githubusercontent.com/54589605/229341332-cfe9cc2f-fcb4-4440-8da6-ae243454325a.png)

> First loop is going on for **k** times where **k=n^(27/5)**. So, that both the sides are **equal**.

![image](https://user-images.githubusercontent.com/54589605/229341399-281e7842-e9fb-4eef-a435-35210423cdb7.png)
![image](https://user-images.githubusercontent.com/54589605/229341576-4cf83bca-6d01-4dad-a118-7a56a7ac876c.png)

> Third loop is going on for **k** times where **k=n^(6/14)**. So, that both the sides are **equal**.

![image](https://user-images.githubusercontent.com/54589605/229341656-b154adc5-2b75-4a1c-821a-4c8b88fa1b16.png)

> **n^7** is bigger as **27/5 -> 5.4** and **6/14 -> 0.4** both are **smaller**.

> Loop is how many time.

![image](https://user-images.githubusercontent.com/54589605/229342051-bdcbb4f5-9752-423c-a75c-4496ef582d5a.png)

> **Recursion** is loop.

![image](https://user-images.githubusercontent.com/54589605/229342062-0bbcec3e-a01a-4477-be62-7118d3852da1.png)

![image](https://user-images.githubusercontent.com/54589605/229342416-7006c3b2-ff8e-4b94-8eef-5fc624e32d80.png)
![image](https://user-images.githubusercontent.com/54589605/229342547-04bad110-ecf7-4be8-8252-668c792219d3.png)
![image](https://user-images.githubusercontent.com/54589605/229342558-909f4fff-12bc-4fe0-af46-7e9f090b3362.png)
![image](https://user-images.githubusercontent.com/54589605/229342563-3a771f6e-9790-4d95-8d2f-d9190639063e.png)
![image](https://user-images.githubusercontent.com/54589605/229342571-ad2faa59-27b0-44e1-846f-4f5458fd4d8a.png)

> **2** loops. **n/5** since **i** is getting **incremented by 5**.

> Always whenever there is an incrementation, then **divide by that incrementation** to get the **time complexity**. In the above question, **i** was incremented by **5** so, the time complexity was **n/5**. If **i** was incremented by **50** then the time complexity will be **n/50**

![image](https://user-images.githubusercontent.com/54589605/229342585-ce510fa1-bdb5-4e0f-82c5-f33496042959.png)
![image](https://user-images.githubusercontent.com/54589605/229342662-61bd79fc-0364-426d-854d-33944558b575.png)
![image](https://user-images.githubusercontent.com/54589605/229342706-08e28d9d-610f-46ee-bcc5-323243b2266b.png)
![image](https://user-images.githubusercontent.com/54589605/229342782-ee653ff3-5fe1-46bc-8e1e-8241b12bb1d5.png)

> Whatever is the **power of n**, just put it in the **time complexity** and the **incrementation** stays the **same**. 

> In the **second while loop**, **i=n** and **i value is increasing**. It is an **infinite** loop. It will not stop. So, **it is not an algorithm** as it is not stopping. It is a program and the time complexity of the program is **infinite**.

![image](https://user-images.githubusercontent.com/54589605/229343139-4045f163-dd95-4ff8-ad7b-40a0a1331abf.png)

> In the first question we started from **big number** as **i=n**, so we have to **decrement or go in decreaseing order**.

> If we started from **small number** like **i=0 or i=1**, then we have to **increment or go in increasing order**.

![image](https://user-images.githubusercontent.com/54589605/229343228-06526dd6-dc6c-4e48-955b-eef4e2e5fa91.png)

> In the **second while loop**, the time complexity is **n**.

![image](https://user-images.githubusercontent.com/54589605/229343274-da5dc060-f3ce-4843-a9ac-a2eb562aaaf2.png)

> In the **second while loop**, the loops runs for **once or one time only**.

![image](https://user-images.githubusercontent.com/54589605/229343421-bb48e8aa-7df9-4cfd-ae9d-3ebec7fc5cc5.png)
![image](https://user-images.githubusercontent.com/54589605/229343426-268ceb68-1c4c-419b-a4b0-3dc38936e79f.png)

* Yes

![image](https://user-images.githubusercontent.com/54589605/229343433-c4efddaa-8586-4fb6-a655-4555a5e490c6.png)
![image](https://user-images.githubusercontent.com/54589605/229343478-8d416473-76f1-429c-a656-d4b337cd4307.png)

> Same only whether **addition or increment** and **substraction or decrement**.

![image](https://user-images.githubusercontent.com/54589605/229343552-f3bde92c-b923-4c18-acf9-eb4b885c725c.png)

> Overall is substraction means the program started with a **big number** i.e **i=n**.

![image](https://user-images.githubusercontent.com/54589605/229343597-837ef707-1b54-4b93-aa25-85fb4bfebe91.png)

> Overall is addition means the program started with a **small number** i.e **i=1 or i=0**.

![image](https://user-images.githubusercontent.com/54589605/229343718-d6a77cea-00ef-4da4-a562-ad8b12996483.png)

> So it is **i=i-50** and **time complexity** is **n/50**. See the overall effect and it is still overall **substraction**, so the program started with a **big number** i.e **i=n**.

![image](https://user-images.githubusercontent.com/54589605/229343796-84e8e8be-64d5-4dc2-9b41-ad3953c0c92f.png)

> So it is **i=i+90** and **time complexity** is **n/90**. See the overall effect and it is still overall **addition**, so the program started with a **small number** i.e **i=1 or i=0**.

> Otherwise for **both** addition and substraction it will case problems of **infinite loops**.

![image](https://user-images.githubusercontent.com/54589605/229343975-2b7c769c-2113-4112-b5e4-fd3b996f385b.png)
![image](https://user-images.githubusercontent.com/54589605/229344013-73f1c7c5-933d-450a-b09c-568f5c50f835.png)

> If the program started with a **big number** i.e **i=n** and we did **i= i+1000** in the **first while loop** then the loop will be **infinite** loop.

![image](https://user-images.githubusercontent.com/54589605/229344177-8acf7b96-a426-4edf-9c02-98f7a013427f.png)

## Doubt Clearing Session (4) [2nd April 2023]

![image](https://user-images.githubusercontent.com/54589605/229349862-73b2a70e-6345-4fc6-a4a7-06a0f10ce3cc.png)
![image](https://user-images.githubusercontent.com/54589605/229349870-1d8e505c-9c32-4385-93b5-276e711caf20.png)

> First for loop is **increasing** and the second for loop is **decreasing**. One is **increasing** and one is **decreasing** but both are taking the **same time**.

> After **K times**, we got **2^K=n**, which is the last iteration of the **first for** loop. So, after applying **log** on both the sides, we got **K= log n base 2**. So, the **time complexity** for the **first for** loop is **O(log n base 2)**.

![image](https://user-images.githubusercontent.com/54589605/229350276-a7762caf-8950-4e42-bea4-58086221325c.png)
![image](https://user-images.githubusercontent.com/54589605/229350290-e4eec45f-df14-4ce8-a0d6-f17caab10565.png)

> Everytime, **i** is **increasing by double**, then the time complexity is **O(log n base 2)**.

![image](https://user-images.githubusercontent.com/54589605/229351964-f76521c9-f06a-4c52-933b-0209f75b8f93.png)
![image](https://user-images.githubusercontent.com/54589605/229352028-9ec44231-d60d-4da0-8211-43f15bb3a7e9.png)
![image](https://user-images.githubusercontent.com/54589605/229352197-e49c3b0d-5bd4-4ee3-841d-1f7d21f3f4f5.png)

> If we **divide by 2 or multiply by 2**, the value of **i** when incrementing the value of **i**, then the **time complexity** will be **O(log n base 2)**.

> If we **divide by x or multiply by x**, the value of **i** when incrementing the value of **i**, then the **time complexity** will be **O(log n base x)**.

![image](https://user-images.githubusercontent.com/54589605/229352430-a212e56c-4125-4f70-b31a-97af79c87eab.png)

> **i=5 * i and i=12 * 1**, we wrote together, then the **i** value is **incremented** by **i= 60 * i**. Then the **time complexity** is **O(log n base 60)**.  

![image](https://user-images.githubusercontent.com/54589605/229352593-76da8a14-da18-4045-a3f3-715a046bbb1d.png)
![image](https://user-images.githubusercontent.com/54589605/229352717-07dc02b0-a0d7-4e0f-89d1-97695a4517b8.png)
![image](https://user-images.githubusercontent.com/54589605/229352818-45696cfa-6bf3-4d31-8e1d-892258d6766c.png)
![image](https://user-images.githubusercontent.com/54589605/229352948-2cc2ba3b-42bd-4bb1-b644-53ab5a5ae2d6.png)
![image](https://user-images.githubusercontent.com/54589605/229353768-9cecc04f-d127-4e07-a8aa-f432fc142c29.png)

> **log n base 2** is bigger. Whichever base is **small**, we will take that.

![image](https://user-images.githubusercontent.com/54589605/229353802-b930c798-068b-4998-b7fc-d61dce895be8.png)
![image](https://user-images.githubusercontent.com/54589605/229353807-3bc17e59-dd76-4574-9e2c-e51b06178815.png)
![image](https://user-images.githubusercontent.com/54589605/229353886-12398664-8899-4b9b-ae87-e7060ef5de00.png)
![image](https://user-images.githubusercontent.com/54589605/229355507-22d62859-86f3-4d52-9f45-215b225027c6.png)
![image](https://user-images.githubusercontent.com/54589605/229355571-2ac9850f-87d9-4df9-bfc4-00e347821c51.png)
![image](https://user-images.githubusercontent.com/54589605/229355617-faaede82-e486-4f95-a3cb-5ff50566476b.png)
![image](https://user-images.githubusercontent.com/54589605/229355673-97455b13-01f0-41f5-9a2b-dab0439cc142.png)
![image](https://user-images.githubusercontent.com/54589605/229355727-8e9d3755-47fe-4e10-9a08-8ed24f0649ac.png)

> For the first loop, it is **incrementing** as it has started from **smaller value** ie **i=1**.

> For the second loop, it is **decrementing** as it has started from **bigger value** ie **j=n**.

> What is the **overall effect** we have to check.

* **Add and sub** -> n/2 or n/5 etc. -> These loops are **bigger** than the **log** loops below.
* **Div and Mul** -> log n base 2 or log n base 20 etc. -> These loops are **smaller** but **faster** than above loops.

> For multiplication, multiply the **numbers** only and for **division**, divide the **numbers** only.

> **Less time complexity**, loop is repeating **less**, the **better**. So **log** is better than **Add and sub** -> n/2 or n/5**.

> Loop should repeat **minimum** time as possible.

![image](https://user-images.githubusercontent.com/54589605/229356272-5fe38aba-dc13-4fa8-93e6-ac19c717653e.png)

* O(log n base 35) [Ans]

![image](https://user-images.githubusercontent.com/54589605/229356507-ba125e31-6ab7-432b-b6ed-d1395bbc487d.png)

> As starting value of **i=5** and it will not affect that much as **5** is a **constant** value, we can ignore it.

> For **multiplication**, the **reverse** is **division** and vice-versa.

> For **addition**, the **reverse** is **substraction** and vice-versa.

> If we do **multiplication and addition** togerther then we get **7007** which is closer to **multiplication** and it gave **7000**. For the **addition**, we got **1007**. So,  **multiplication and addition** togerther is approximately equal to **multiplication**. Exactly not possible.

![image](https://user-images.githubusercontent.com/54589605/229357155-9466c0e2-4fc6-4c01-9515-4cf03176d88e.png)
![image](https://user-images.githubusercontent.com/54589605/229357239-d6743186-915a-4b1c-9ad4-910dfd2e815a.png)

> So **multiplication** is faster than **addition**, that's why it is affecting more and for **addition**, it is affecting in **constant** values.

![image](https://user-images.githubusercontent.com/54589605/229357689-4c9500e2-72a2-40de-a193-c632f8e118bc.png)
![image](https://user-images.githubusercontent.com/54589605/229357956-e58bff4c-5dd1-49bc-b664-cdcefdb45802.png)

[**IMPORTANT**]

* i + 2 -> n/2
* i * 2 -> log n base 2
* i * i or i^2 -> log(log n)

![image](https://user-images.githubusercontent.com/54589605/229358415-4b380b13-4c16-4a0e-a484-0ea122ea6aee.png)
![image](https://user-images.githubusercontent.com/54589605/229358602-865544b6-6614-462f-a331-44849290a8e0.png)
![image](https://user-images.githubusercontent.com/54589605/229358750-549d09b4-028a-48db-b3a7-1332c5e325a9.png)

![image](https://user-images.githubusercontent.com/54589605/229359090-e9f13bdd-7796-48e4-8596-205a4cf96039.png)

> The **time complexity** is **log(log n base 2) base 10**. 

> Because the **initial value** of **i** is **i=2**, so the **inner base** is **2** as it has come **before/earlier**. At the end the **power** of **i** is **i^10**, so the **outer base** is **10** as it has come **after/later**.

> This is how we got the **time complexity** of **log(log n base 2) base 10**. 

![image](https://user-images.githubusercontent.com/54589605/229359259-d856333b-c5e8-4bd5-ae05-2092c4c079f3.png)
![image](https://user-images.githubusercontent.com/54589605/229359296-a63b614a-ba6d-489c-abd9-8109f750df01.png)

> The **time complexity** is **log(log n base 2) base 30**. Even if we add **i= i =7** in the for loop, it has very small effect which is **some constant**. So, the result remains **same** still. It is **baccha** only.

![image](https://user-images.githubusercontent.com/54589605/229359399-249e129c-0a6a-489b-a1d2-95912b6d29e9.png)

> If we also include **i= i * 7**, then also the result remains the **same** as it has very small effect which is **some constant**. It is **baccha** only

![image](https://user-images.githubusercontent.com/54589605/229359506-85a8a026-06e9-41f6-9e9a-cd956c337594.png)
![image](https://user-images.githubusercontent.com/54589605/229359522-a014b913-19d9-4b63-b6d4-20779aaaab8a.png)

> **log(log n)** is faster compared to **n/2 or log n**. So **log(log n)** is dominating the **time complexity** value compared to them. Every oen is **participating** but **log(log n)** is dominating. So, **overall**, **time complexity** remains the **same** which is **log(log n base 2) base 30**.

> **Constants** doesn't have much effects.

* 9 * 6 * 5/(9) -> 6 * 5 -> 30 
* log(log n base 1500) base 30

> So, we got **log(log n base 1500) base 30** as the **time complexity** value.

> Because the **initial value** of **i** is **i=1500**, so the **inner base** is **1500** as it has come **before/earlier**. At the end the **power** of **i** is **i^30**, so the **outer base** is **30** as it has come **after/later**.

> This is how we got the **time complexity** of **log(log n base 1500) base 30**. 

![image](https://user-images.githubusercontent.com/54589605/229360322-f893ef84-4f51-4192-beff-e6a088cab979.png)
![image](https://user-images.githubusercontent.com/54589605/229360445-870e27a9-188d-49a7-b948-9fb67861ba25.png)

> Answer will be **same** only even if we remove **less than equal to** to **less than** only. As **i^9 or i^6 or i^(1/9)** have the **highest power** compared to **add, mul and divide** that why they are dominating here. We have **ignored** the **rest**.

## Asymptotic Notation-I (5) [3rd April 2023]

> As **i** is starting from a **larger no.**, **i=n**, hence the **overall** effect should be **decreasing or decrement**.

* 5 * 4 / 3 * 15 * 25 -> 4/ 9 * 25 -> 4/225
* log(log n base 2) base 4/225

![image](https://user-images.githubusercontent.com/54589605/229436098-855e308e-58d4-4fd2-bffa-aa5598aa3b09.png)

> So, we got **log(log n base 2) base 4/225** as the **time complexity** value.

> Because the **initial value** of **i** is **i=n**, so it has a **greater value**, so now we have to check the **initial value** where the **condition** ends, which is **i >=2**. So the **inner base** is **2** as it has come **before/earlier**. At the end the **power** of **i** is **i^(4/225)**, so the **outer base** is **4/225** as it has come **after/later**.

> This is how we got the **time complexity** of **log(log n base 2) base 4/225**. 

> This is also **wrong** because of the **below proof**.

![image](https://user-images.githubusercontent.com/54589605/229445145-f47c35d0-3c16-4869-9553-a0a4822a08f1.png)
![image](https://user-images.githubusercontent.com/54589605/229446072-049a5c25-8c90-4c6c-bf62-8f3f146ecc24.png)
![image](https://user-images.githubusercontent.com/54589605/229446245-bf099211-58f3-44f9-abb7-cd1f5aac3adf.png)
![image](https://user-images.githubusercontent.com/54589605/229451172-5cb10e53-0796-4fed-8c8e-cd47d89ff4fb.png)

> So, the **time complexity** is  **O(log(log n base 2) base 255/4)**.


![image](https://user-images.githubusercontent.com/54589605/229436734-f0c42dd7-a885-4b66-8281-5b86b20d82cd.png)

> If we got final value of **i** as **i^(1/2)**. Then, the **time complexity** is **O(log(log n base 2) base 1/2**.

> But **sir** is saying it should be **O(log(log n base 2) base 2**. Let's see his **proof** for these solution.

![image](https://user-images.githubusercontent.com/54589605/229438172-40197edc-20df-4d56-b7fc-1ea12be76696.png)
![image](https://user-images.githubusercontent.com/54589605/229451172-5cb10e53-0796-4fed-8c8e-cd47d89ff4fb.png)

> Here is the **proof** why we are getting **base 2** in **outer** base even though **i^(1/2)**. So, remember when we get **1/2** as the **power** then put **2** as the base. In the proof we got **O(log(log n base 2) base 2**, so for **i^(1/2)** we got **time complexity** as **O(log(log n base 2) base 2** and not **O(log(log n base 2) base 1/2**, which we thought **initially**. 

> If it is **i^(1/2)** then it is **ulta/opposite** i.e **base 2** as the **outer base**.

![image](https://user-images.githubusercontent.com/54589605/229447306-8acf58ba-a21c-46ea-bac2-7b69ab6f6815.png)

> For **square**, reverse is **root**. They(square and root) both are the **same**. So, **i^(1/2)** is **root** only.

> Initially **i=n** and after **k times**, it is **n^(1/2^k) = 2**, which is the **termination** condition for the loop. We want the **k** value as it has looped for **k times**. So after applying **log**, we get **1/(2^k) * log n base 2=1**. So, **log n base 2 = 2^k** and after applying another **log**, we got **k = log(log n base 2) base 2**.

![image](https://user-images.githubusercontent.com/54589605/229451172-5cb10e53-0796-4fed-8c8e-cd47d89ff4fb.png)
![image](https://user-images.githubusercontent.com/54589605/229448219-3d9d39f6-5d57-47b9-8358-5f46bd4f9598.png)

> Initially **i=n** and after **k times**, it is **n^(4/255)^k = 2**, which is the **termination** condition for the loop. We want the **k** value as it has looped for **k times**. So after applying **log**, we get **(4/255)^k * log n base 2=1**. So, **log n base 2 = (255/4)^k** and after applying another **log**, we got **k = log(log n base 2) base 255/4**.

![image](https://user-images.githubusercontent.com/54589605/229450647-f70a7f71-4b00-4dd4-8d88-2fd6be134bbd.png)
![image](https://user-images.githubusercontent.com/54589605/229449100-7c669f9a-baf4-43e0-807c-e740f6f2681e.png)

> So, when we are doing **i^20** and the **initial value** is **i=2**, the time complexity is **log(log n base 2) base 20**.

> So, when we are doing **i^65** and the **initial value** is **i=2**, the time complexity is **log(log n base 2) base 65**.

> It is similar for **root** also. So, when we are doing **i^(1/2)** and the **initial value** for the **termination** condition for the loop is **i=2**, the time complexity is **log(log n base 2) base 2**. So, **reverse** is happening.

![image](https://user-images.githubusercontent.com/54589605/229454189-cfd8032b-7ca6-4f4e-8041-4ee4b8c58a7a.png)

> If we add **i= i + 75**, then also the **result** remains the **same** as  it has **very small effect**. If we add **i= i * 75**, then also the **result** remains the **same** as  it has **very small effect**.

![image](https://user-images.githubusercontent.com/54589605/229454633-edbc6237-8d4f-4db1-8dab-e56c1877d019.png)

> So, if the  **initial value** for the **termination** condition for the loop is **i=23**, then we get **n^(4/225)^k = 23**. Hence, the value of **k= log(log n base 23) base 255/4)**. So, the **time complexity** is **O(log(log n base 23) base 255/4)**.

> Try to understand what is **happening**. **Time complexity** means **how many times the loop is running and what is happening within the loop**.

## GATE Questions

* Find **time complexity** and **value of q**.

> For the first loop, the **time complexity** is **log n base 2** and **p** value is **incrementing everytime**. The loop is repeating **log n base 2** time and **p** is **incrementing everytime**. So, **p** value is **p= log n base 2** only. So, how many times the loop is repeating that many times only **p** is incremented.

> After the end of the first loop, **p= log n**.

> For the second for loop, the **time complexity** is **log p base 2 -> log(log n base 2) base 2**. The second loop is **log p** time and not **log n** times as **j <=p** is the condition.

> As from the first for loop, we gathered whatever is the **time complexity**, that value is the value of **p**. So, here in the second for loop as well, whatever is the **time complexity**, that value is the value of **q** which is **q= log(log n base 2) base 2**.

![image](https://user-images.githubusercontent.com/54589605/229472063-cd52d5b5-b7f4-4acb-9bcd-3553238a8382.png)
![image](https://user-images.githubusercontent.com/54589605/229484717-2e29daf4-7aff-4e5c-b8d4-47f9372e097b.png)
![image](https://user-images.githubusercontent.com/54589605/229488396-fec7b740-17de-42ce-86c1-38250c7cccb5.png)
![image](https://user-images.githubusercontent.com/54589605/229488623-74c42aee-b4d5-401a-9084-479fccb4ec2e.png)

> This is for when we have many values within **one** loop only. If we have **add and mul** within one loop then **mul** will be **faster** than **add**, so it will have much more effect than **add**. That's why we ignored **add** in that case and took the **faster value**.

> When finding **time complexity**, then we have to take the larger value like **log n > log(log n)** in the above example as if **n=16**, then **log 16 -> 4** and **log(log 16) -> log 4 -> 2**. As **4 > 2** which means **log n > log(log n)**. Hence we took **log n** as the **time complexity** in the above question.

[**IMPORTANT**]

> They are **two** different loops and they are **outer** loops, when **outer** loops, take the **larger one**.

![image](https://user-images.githubusercontent.com/54589605/229489833-b7094cbd-6aa4-491f-9e0b-85eba2b46e68.png)
![image](https://user-images.githubusercontent.com/54589605/229491861-8bd6410e-4516-4b4c-a3f5-b48bfabcd48a.png)

> Time complexity is **O(nlog n)** because the time complexity between the inner for loops is **log n** but the outer for loop is running for **n times**. So, it is **O(nlog n)**. The **q** value remains the same because every in the outer for loop, **p and q** are initialized by 0 only.

* return -> Get out of the function.
* exit -> Get out of the entire program or stop the program.

![image](https://user-images.githubusercontent.com/54589605/229493160-63908197-026f-4d08-a8a0-99c5c291754f.png)
![image](https://user-images.githubusercontent.com/54589605/229498658-742e3bc2-fa3f-45f9-810f-bd4a613428e1.png)
![image](https://user-images.githubusercontent.com/54589605/229499000-3e3da2fb-eaac-42a5-916a-1dffa2725d37.png)

> If **q=0** was within the first for loop like **p=0**, then the **q** value would have been **q= log n**, as after every loop, q value would have been initialized with **q=0** only.

* break -> outside loop or out of the loop.
* return -> outside the function(same as above), just different wording.
* exit -> program stops

![image](https://user-images.githubusercontent.com/54589605/229500169-d964c9f0-4f2e-4d42-83e5-4f6cc08b0848.png)

> For the first loop, time complexity is **log n^2 base 7** as the termination condition for the loop is **i <= n^2** that why.

> For the second loop, time complexity is **log n^2 base 7** as the termination condition for the loop is **i <= n^2** that why.

![image](https://user-images.githubusercontent.com/54589605/229502823-f7f097b7-0546-41d8-ac04-33e012c59105.png)
![image](https://user-images.githubusercontent.com/54589605/229503671-6dbfb9a4-7dae-4fee-ad9c-5ed7fdce71e4.png)

> Both are correct if we ignore the **constants**. Check which is given in the **options** of the question. Choose that one.

![image](https://user-images.githubusercontent.com/54589605/229505160-0a9114d3-7db8-4966-a2fe-94414755cf50.png)

> For the **value of x**, as the **inner loop** is repeating **log n** times and every time **n** is getting added so **n log n** but the **outer loop** is also there which is **log n** times. So, value of **x = log n * nlogn -> n * (log n)^2**.

![image](https://user-images.githubusercontent.com/54589605/229505864-77653c1c-7b46-4776-8359-026cf1ded495.png)
![image](https://user-images.githubusercontent.com/54589605/229506380-2c667974-8038-47a7-b56c-ee41add96fe9.png)

> If we have replaced the variable **n** in **x= x + n** with **x=x+1**, then the **value of x** is **log n * log n -> (log n)^2**. As the inner loop runs for **log n** times and the outer loop also runs for **log n** times.

> By replacing **n** with **1**, the **value** is changing only. The **time complexity** is **same** only. Time complexity will only change when loops are **increasing or decreasing**.

![image](https://user-images.githubusercontent.com/54589605/229507869-3706aefb-48c6-478e-961e-9066f9677571.png)

> Even if we put **0**, then also only the **value** changes. The **time complexity** remains **same** only.

> In **power**, constants matter, don't ignore them there.

![image](https://user-images.githubusercontent.com/54589605/229513967-e69ba091-bc02-4051-b9b2-f326e8cae36b.png)
![image](https://user-images.githubusercontent.com/54589605/229516312-1b66d5e2-7d55-4c94-812d-9252496a1841.png)
![image](https://user-images.githubusercontent.com/54589605/229516249-abe8a073-a836-4692-b8fe-199d8467ff15.png)
![image](https://user-images.githubusercontent.com/54589605/229516472-ecd2a386-997a-4998-b6a4-a7f951ad85c5.png)
![image](https://user-images.githubusercontent.com/54589605/229516823-dd337e48-f32b-45e3-bfc0-cf7bc2aaf8f7.png)

> If both the loops have **n** complexity then the value of **x** will be **n^(n^2)**. As **j** loop has run **n** times and each time **n** is multiplied to **x** then the value of **x** after whole of **j** loop is **n * n -> n^2**. So, **n * n -> n^2** will be for each loop of **i**, so for **n** loops of **i**, we get **n^(n^2)**.

![image](https://user-images.githubusercontent.com/54589605/229517864-ec76b7f1-355f-474e-b50b-339c380ea928.png)
![image](https://user-images.githubusercontent.com/54589605/229518106-566ea1c0-95dd-4296-a20f-3781f41d598d.png)

> So multiply **n^(1.57) * log n^7 base 8** and that is the **answer** for the given question.

![image](https://user-images.githubusercontent.com/54589605/229521532-a59fcc11-2c5d-4a57-a2f7-3aea51a22d12.png)
![image](https://user-images.githubusercontent.com/54589605/229521845-0e5338df-6e86-4b3a-b21d-5a71d2a0d21c.png)

> If **x=0**, then **0 * anything -> 0**. So, the value of **x** will be **0** only.

> There are **2** loops in the program. They are **inner** loops as **j** has come before **i** has completely stopped. AS they are **inner**, so we have to **multiply**.

> As **n** is a **prime no**, it has **only two factors** i.e **1 and itself**. So, for all the values of **i**, only **two** values will enter the **j** loop.

![image](https://user-images.githubusercontent.com/54589605/229525351-ff33b8a5-6dd6-41ee-bbef-a6f69111cc9b.png)
![image](https://user-images.githubusercontent.com/54589605/229525731-040aacb7-feb2-44be-b5c6-80d8d319ce75.png)
![image](https://user-images.githubusercontent.com/54589605/229525849-0890ab9c-f0e7-44d9-9b18-11c4d9d74a46.png)

> Even though there are **two** loops and they are **inner** loops. We only got **time complexity** as **O(n)** as there is an **if** condition which is stopping most of the **i** iterations to go to **j** loop. Everyone not allowed into **j** loop. Because of **n** being **prime number**, only **two** values can go into **j** loop.

![image](https://user-images.githubusercontent.com/54589605/229526008-c669800a-d873-4aac-b86f-e4a726abf724.png)

> If we remove the **condition** then the **time complexity** as **O(n^2)*.

![image](https://user-images.githubusercontent.com/54589605/229610057-63d39edf-fc3e-4f3f-a04c-444b937b3a20.png)
![image](https://user-images.githubusercontent.com/54589605/229610083-5ed96e12-f13e-4771-a543-08de173875e7.png)
![image](https://user-images.githubusercontent.com/54589605/229610117-fa09f375-4011-419e-94f8-78919579c1e2.png)
![image](https://user-images.githubusercontent.com/54589605/229610141-f21463be-d26d-4661-bec2-2d524e5a91cf.png)
![image](https://user-images.githubusercontent.com/54589605/229610164-75e7104b-2869-4289-9ef0-39b018acd540.png)
![image](https://user-images.githubusercontent.com/54589605/229610188-cb14c423-f0bd-4327-b9d6-0d282bf3ea82.png)
![image](https://user-images.githubusercontent.com/54589605/229610201-9735d2e5-c655-43d4-a010-b63421294136.png)



## Asymptotic Notation-II (6) [3rd April 2023]

### Time Complexity Questions continued

> There are **two** loops and they are **inner** loops. In **j** loop, it is dependent on **i**. Without mentioning **i**, we cannot define **j**. As **j** is dependent on **i**, or when **one** is dependent on **another** then we can't write them individually. We have to write them **combinedly** only.

> Based on the **dependency**, we cannot **divide**. Based on **i**, **j** will come. **j** is how many times? **i** times. Whenever there is a  **dependency**, we cannot **separate** them. We have to take **both** of them into consideration.

![image](https://user-images.githubusercontent.com/54589605/229578017-d9cf42fd-595f-4dac-a768-e6fe24d3e71d.png)

> If **n terms** are there then **each term** is **one loop**. We are getting the **terms** because of the **combination of i and j**. **i** will say how many loops. **j** will say every loop how many time.

![image](https://user-images.githubusercontent.com/54589605/229582397-11aa207b-9eb5-49a1-82e5-74d4f01e91f2.png)
![image](https://user-images.githubusercontent.com/54589605/229582500-1649aff7-3fc2-4944-aa2d-eb9e7deee18f.png)

> So, the **time complexity** will be **O(n^2)**.

> If **i=1**, then **j** loops  **one** time only.

![image](https://user-images.githubusercontent.com/54589605/229582790-576b0543-4ea8-4511-bcdf-a951bbc99c86.png)

> Instead of **i**, we have put **n** in the **j** loop, then also we would get **O(n^2)** as the **time complexity** which is the **same** as before. But in the **above question**, the actual answer is **n(n+1)/2** but we are simply ignoring the **constants**. So we get **O(n^2)**.

> For the **2nd question** we get **O(n^2) or n * n**, which is the actual correct solution. So they are not the same solutions.

> So the symbol we write on the right hand side which is the **Theta**, are simply **approximation**. But before **Theta**, whatever we write that's the **actual** solution.

> We are **approximating** because the **actual values** differ from system to system, if the system is **slower** then we could get **n(n+1)/2^t** or if the system is **faster** then we could get **n(n+1)/1.2**. So the **actual** answer is varrying with **constant** values. That's why we use **approximations**.

> So the **actual value**, **n(n+1)/2** will change from system to system. It could be **n(n+1)/20** or **n(n+1)/200** or **n(n+1)/2000000**. They keep on **changing**, but in every system one thing is **common** that is **n^2**. **Constant factor** will only **change**. This is the **meaning** of **Theta(n^2)**. From system to system in the **actual answers**, the **constant** factor can **change**. But one thing is **common** in every system which is **n^2**. Some constant factor **n^2**.

![image](https://user-images.githubusercontent.com/54589605/229583693-5e948183-2cc2-43d7-98a6-29e60a59197b.png)

* 1 + 4 + 9 + ........ + n^2 -> Series

* Above series explaination -> https://math.stackexchange.com/questions/1544526/the-sum-of-the-first-n-squares-1-4-9-cdots-n2-is-fracnn12

![image](https://user-images.githubusercontent.com/54589605/229589693-8d7753ca-fa17-402d-bc97-4385e90ca287.png)

> So it givens **n^3**. Hence the time complexity is **Theta(n^3)**. So, in every system **n^3** is **common**.

![image](https://user-images.githubusercontent.com/54589605/229590344-6a20a21d-ba93-4b54-960f-b69ba8ee783d.png)

> The loop is **dependent** on **s**. **s** is always incremented by **i**, but **i** is always incremented by **1**. After doing **k times**, the total sum is equal to **n**.

![image](https://user-images.githubusercontent.com/54589605/229593178-08f36cd9-065c-4bc8-8513-bfe952a97276.png)

> If **s** is incrementing by **s= s + i^2**. Then, the **time complexity** will be **Theta(cube(n)) -> Theta(n^(1/3)**.

![image](https://user-images.githubusercontent.com/54589605/229594030-c427c7bf-1497-45d5-a63a-11f8c22b6ff1.png)

> **j** is based on **i** loop. **YES**. If a for loop **j** is incremeneted by **3** then **time complexity** is **n/3**. If a for loop **j** is incremeneted by **10** then **time complexity** is **n/10**. If a for loop **j** is incremeneted by **20** then **time complexity** is **n/20**.

> So, in the below question **j** is incremented by **i** then **time complexity** is **n/i**. There is **dependency**. So, if **i=1**, then the **j** loop will repeat, **n/i -> n/1 -> n** time.  So, if **i=5**, then the **j** loop will repeat, **n/i -> n/5** time.  So, if **i=n**, then the **j** loop will repeat, **n/i -> n/n -> 1** time. The **series** we got is by considering **both, i and j**.

![image](https://user-images.githubusercontent.com/54589605/229597235-984ca85c-a5e0-4f3a-bf99-41612ef02c8c.png)

* n/1 + n/2 + n/3 ............. + n/n -> n[1/1 + 1/2 + 1/3 + ........ 1/n] 

> This is a **logarithmetic series**. So we get **n * log n -> n(log n)**. The **constant factor**, **[1/1 + 1/2 + 1/3 + ........ 1/n]** is equal to **log n**.

* [1/1 + 1/2 + 1/3 + ........ 1/n] -> log n

> As **1/n** is there so **log n**.

* [1/1 + 1/2 + 1/3 + ........ 1/log n] -> log(log n)

> As **1/log n** is there so **log(log n)**.

> So, whatever is there at the end **1/whatever**, then we do **log** of it so, **log(whatever)**. That's the **logic**.

> They are **inner** loops. They are **dependent** on each other. They are based on **one variable**.

> **int i** means **i** is declared and **memory** is allocated for it.

![image](https://user-images.githubusercontent.com/54589605/229601850-49e40c3c-e57e-4f38-b368-cf247af0f3d5.png)
![image](https://user-images.githubusercontent.com/54589605/229601964-cf7df09f-3a5e-4761-91fd-a92d019d5906.png)
![image](https://user-images.githubusercontent.com/54589605/229602095-6ee91b9e-d3ea-4703-8fdd-180f86e0ca94.png)

> We got **n^3** from the inner most loop and in the next iteration it was **n^3 + 1** which is greater than **n^3**, so the condition of the loop fails and we go to the **second loop**. We check the condition that **n^3 + 1** is less than **n^2** and it is **false**, so we go to the **first/outer** loop. We check condition that **n^3 + 1** less than **n** and it is **false**. So, we get out of all the loops. We got **1** itiration in **first loop**, then **1** itiration in **second loop** and **n^3** iteration in the **third/last** loop. So the **time complexity** is **O(1 * 1 * n^3) -> O(n^3)**.

![image](https://user-images.githubusercontent.com/54589605/229602918-0417a5b8-c2be-4139-959f-2e828b68f631.png)

> If we do like that then **each i** value is localized to their respective **for loop** blocks only. So, they are **different** now. Now, there are **two** declarations. First loop has it's own declaration and the **second and third** loops have their own declaration.

![image](https://user-images.githubusercontent.com/54589605/229603089-a59164c5-9196-43fd-831e-d5845205c438.png)
![image](https://user-images.githubusercontent.com/54589605/229603054-cc0bc2ad-df4f-4e60-89ef-66f854c750b4.png)

> If we write **int i** in every for loop, then there are **three** declaration and each and every loop is **different**. It is like **i, j and k**. It is like **three** different variables. One person don't see the **other person**. Everyone is individual. Their scope is **inside** their respective **for loop** blocks.

![image](https://user-images.githubusercontent.com/54589605/229603558-0ec35f2e-78d6-4f94-a8cc-881e366f4db6.png)
![image](https://user-images.githubusercontent.com/54589605/229604245-288c988d-fa18-4bab-a0ac-2cb00b7f7c48.png)

> Now, there is only **one i**.

![image](https://user-images.githubusercontent.com/54589605/229604504-ea0d11a5-8166-4cf2-a294-48ed0cc1bc22.png)
![image](https://user-images.githubusercontent.com/54589605/229605386-2b910a46-f155-448b-a652-5a1ffba17d48.png)
![image](https://user-images.githubusercontent.com/54589605/229605859-6267f4da-66bd-4286-abec-17cd32c2679c.png)

> It is forming an **infinite loop**. So, it is not an **algorithm**. It is a **program** which is going to  **infinite loop**.

![image](https://user-images.githubusercontent.com/54589605/229606268-a822465d-caac-47ea-9a83-c2b59e5c8a2d.png)

> Inner loops affecting outer loops.

![image](https://user-images.githubusercontent.com/54589605/229610287-aecda8f1-f14b-4c88-a8a1-23693cb27b8f.png)
![image](https://user-images.githubusercontent.com/54589605/229610310-03c68713-57d0-409f-8ca4-eae1d1b5a897.png)
![image](https://user-images.githubusercontent.com/54589605/229610337-e9fde60f-c3c2-4ae7-bf2e-a165a911d2a6.png)
![image](https://user-images.githubusercontent.com/54589605/229610357-63d12144-f145-4051-b844-201b1395b768.png)
![image](https://user-images.githubusercontent.com/54589605/229610373-5b502678-b0f8-4708-bd7e-d910a2b9d58f.png)


[**IMPORTANT**]
> **Practice** all of the questions. Before starting the new topic. Do some **practice** questions and revise them again.

## Asymptotic Notations

> Approximate answer

1) Big-O Notation -> (**<=**)
2) Omega Notation -> (**>=**)
3) Theta Notation -> It means **equal**. It means **Big O(<=)** as well as **Omega(>=)** also. If both(Big-O and omega) satisfied then it is **theta**.

> If between two people <= and >=, both are possible. Then, they are **equal**. If both are **True**, then they are **equal**. If both are **True**, then they are **not equal**.

![image](https://user-images.githubusercontent.com/54589605/231459382-4c202308-2b11-44dc-804f-5118a5db48bf.png)

> If we know **Big-O** then we know how to apply **<=**. If we know **<=**, then we also know **>=**. As we know both(**<=** and **>=**), then we can apply **theta**. 

> If we learn **Big-O**, then automatically **all** will come.

> If we used **Theta** for one problem, then we can use **Big-O** as well as **Omega** for the same problem. **Theta** means **Big-O** as well as **Omega** only. 

![image](https://user-images.githubusercontent.com/54589605/231461655-2466978b-7f27-4f76-b0c5-8119a53f523a.png)
![image](https://user-images.githubusercontent.com/54589605/231462675-ab0129e5-85c1-4963-bbbc-35009ce892f8.png)

* Time and Space complexity cannot be **negative**.

![image](https://user-images.githubusercontent.com/54589605/231463083-bc937018-244f-41a0-b8e9-8a4f2ff6698d.png)

## Big-O Notation(<=)

* O -> <= [Less than or equal too]
* o -> <  [Less than]

![image](https://user-images.githubusercontent.com/54589605/231464989-cafdd352-b73e-44bb-937a-5517092b8aa2.png)

> **Big-O** means **right side** person would be **more or equal too** when compared with the **left side** person.

> In **Big-O**, **more or equal too** is on the **right side**. 

> According to **Big-O**, **right side** is **more/greater/bigger or equal too** than the **left side**.

![image](https://user-images.githubusercontent.com/54589605/231469636-b90040ec-603d-46ee-b7d5-69655dca5f15.png)

## Example

> We want to prove **right bigger** but frankly in the question, **left** is bigger.

![image](https://user-images.githubusercontent.com/54589605/231471403-9b66972c-0e8f-410c-990f-be5735920aff.png)

> The **2n** on the **left side** is far bigger than the **n + 5**. So, we will take **c=2**. Now, **n + 5 <= 2n**, so the **right side** is **bigger**. When comparing **left and right** side, **right side** is bigger with the help of **constant, c**. That's the meaning of **Big-O**.

![image](https://user-images.githubusercontent.com/54589605/231472294-b8c72faa-3f94-48b6-a8fa-72372f6e31ba.png)
![image](https://user-images.githubusercontent.com/54589605/231474437-ab0449d2-ce95-42ba-a0f9-eb77314a36a4.png)
![image](https://user-images.githubusercontent.com/54589605/231476493-3e7eaff7-802a-4585-a4d2-1b5a066c93a5.png)
![image](https://user-images.githubusercontent.com/54589605/231477937-9e2fcc06-2b19-49ee-bdb4-f91b18258e3a.png)

> In **Big=O**, we can take the support of **one** person, which is the **constant, c** and using that **constant, c**, we can prove that **right side** is **bigger or equal too**.

* **right side** is **bigger or equal too** -> **Big O**.

> In **example 2**, we can see that **right side** is **bigger** and we want to prove that **right side** is **bigger** only. So, **we don't need the help of the** **constant, c** here. We can set **c=1**, as support of **constant, c**, is not needed.

> From which value of **n** onwards, this relation will hold? Minimum value, start checking from **n0=1**. May or may not work. **Left** is **1** and **right** is **6**. So, **1(one)** onwards it is working. So, **right side** is **bigger**, proved. It is working from **zero(0)** also but don't write **zero(0)** when analyzing **algorithm**, **minimum one input is required**, so from **one** onwards start checking.

![image](https://user-images.githubusercontent.com/54589605/231481969-f28ac272-1acb-4725-8da1-42fe35754262.png)

> So, it is working **one(1) onwards**, and not **one(1) only**.

![image](https://user-images.githubusercontent.com/54589605/231482186-6d4974c7-c6e3-446e-9c9c-15c878a10a59.png)

> So for **Big-O** notation, it is the **starting** boundary. **From which point onwards it is working**, then is no **until** point here, until **infinite**. There is no **ending boundary** to it. Just say, the **starting point** and **from that point onwards, it is working**.

![image](https://user-images.githubusercontent.com/54589605/231483165-a6ec8330-4c8d-411d-8c18-7271eec4ee5a.png)

> From **1** point onwards, it is working. The constant value is **c=1** and **n0=1**. In place of **c** anything is ok, but is should be **constant**. Greater than **zero(0)**, we can take **anything**.

![image](https://user-images.githubusercontent.com/54589605/231485311-af4739fe-6b64-4fd5-8db6-a7b28cf6a236.png)
![image](https://user-images.githubusercontent.com/54589605/231485852-b607f18a-d5c8-47c5-bc68-7d4a00190317.png)

> The line **n= O(n+5)**, means that when comparing **n** with **O(n+5)** then **O(n+5)** is **bigger or equal too**, **n**, after taking **constant, c** help from some **n0** onwards. **Right side** is **bigger**.

> Even though the **constant, c** is available, we have to take it as **right side** is already **bigger** and we want the **right side** to be **bigger** that's we didn't need any help.


## Recursion-Part-I (7) [13th April 2023]

> **Big-O** means **right side** is **greater**.

> **Omega** means **right side** is **smaller**.

## Questions

![image](https://user-images.githubusercontent.com/54589605/231685712-f14fbe0b-1e42-4a85-8b59-de4af086664d.png)
![image](https://user-images.githubusercontent.com/54589605/231686479-07342880-7e32-45df-a26d-af7e9f0048f3.png)

> With respect to **c**, **n0** value will **change**. If we take **bigger c** value then **n0** value will be **smaller**. 

> **n0=3** means **3 onwards** upto **infinite**. Starting boundary is **n0=3** but there is no **ending boundary**.

![image](https://user-images.githubusercontent.com/54589605/231694994-9a4bdedc-c654-4e48-b7f0-82b8a75511c1.png)
![image](https://user-images.githubusercontent.com/54589605/231695183-1088a399-f0cb-45c9-b543-8bf4438c41b3.png)

> Starting boundary is **n0=10** but there is no **ending boundary**.

![image](https://user-images.githubusercontent.com/54589605/231688210-8bd04214-1a35-4b73-947c-26058dc4eda3.png)

> **f(n)= O(g(n))** means that comparing **f(n)**, **g(n)** will be **greater or equal too** after taking **constant help**. After comparing left and right, right will be **greater or equal too** after taking **constant help**, some **n0** onwards.

![image](https://user-images.githubusercontent.com/54589605/231690377-714b1934-42d3-45d1-b831-cffdd087d91d.png)
![image](https://user-images.githubusercontent.com/54589605/231690539-a0ddc063-d04a-4774-aba4-1d2aacc1839b.png)

> **n** is a function and we cannot take a **function**. Constant help is only allowed.

> The constant(c) cannot take a function **n** as on the left side it is **n * n** and on the right side is **c * n**. Only way it is possible if **c=n** but that is not allowed in notations, we cannot take a **function**.
 
![image](https://user-images.githubusercontent.com/54589605/231691836-9cb4ac0a-2090-4a11-8401-2b17ae8f1958.png)

> Using **Big-O**, we cannot prove any person is **bigger**. We can take only **constant** help and prove whatever possible. By using **constant** help if we can prove **right side** is **bigger** then that is **Big-O**.

> There is a limit for everything, we can only use **constant** help. More than **constant** help is not allowed. 


## Omega Notation(>=)

> In **Omega**, **less or equal too** is on the **right side**.

> By taking **constant, c** help, we can prove that **right side** is **less or equal too**. That is **Omega**.

* **right side** is **less or equal too** -> **Omega**.

![image](https://user-images.githubusercontent.com/54589605/231696283-2dd5ae72-b306-40fe-87c0-8834c2cc4b92.png)

> Not necessary that **c** value should be in **integers** only it can be in **fractions** as well like **1/2 or 0.5, 1/4 or 0.25**. More than **zero(0)**, take anything, which is a **constant**. Less than **zero(0)** not allowed and more than **zero(0)** anything which is **constant** is allowed. 

> **n0** indicates **inputs**, so it has to in **integer** and cannot be in **fractions**. We cannot have **1.5** inputs it should be either **1** or **2** inputs but not **1.5** inputs.

![image](https://user-images.githubusercontent.com/54589605/231698060-84cff2a3-ffd9-4bb6-a7d7-ccfb7b57a613.png)

> As it is **Omega**, we want to prove that the **left side** is **bigger** or directly that the **right side** is **smaller or equal too** as it is the **opposite** of **Big-O**.

>  We want to prove that the **left side** is **greater** but to be frank, the **right side** is **greater**.

![image](https://user-images.githubusercontent.com/54589605/231702689-008e17aa-b172-43af-9c6e-182fb92449a7.png)

> Whenever **c** value changes, then automatically **n0** value also changes. We don't need to find out every **c and n0** value. Find out **one pair** of **c and n0** value.

![image](https://user-images.githubusercontent.com/54589605/231703200-10bc7f82-d997-4e65-9a19-ec7b9951a4f1.png)

> One **c** value is **enough**. After fixing **c** value, adjust **n0** value accordingly.

![image](https://user-images.githubusercontent.com/54589605/231706580-2389733c-7f81-4f54-9e97-99a5f5d3c2b5.png)

> **n = Omega(n+5)** means that when comparing **n** with **Omega(n+5)**, we can prove that **n** is **bigger or equal too**, **n+5** with the **constant help** of **c**.

> Without any help, **n + 5** is **bigger**.

> After taking **constant help**, we proved **n** is **bigger**. **Omega** means **left side** is **bigger or equal too**.

![image](https://user-images.githubusercontent.com/54589605/231708907-f54d580f-1eff-4705-bb26-3eb1ec055921.png)
![image](https://user-images.githubusercontent.com/54589605/231709685-4f89887a-6fe0-4d73-b8a0-51d3da9d41cd.png)

> **c** cannot take a **function**. How small the function is, **c** cannot take a **function**. It can only take **constant** values.

![image](https://user-images.githubusercontent.com/54589605/231710063-88d5db24-e96e-45e0-9af1-019459a89837.png)

> For only few people it is possible to prove with **constant help** and not for all.

![image](https://user-images.githubusercontent.com/54589605/231712069-b4d26761-6b33-4521-a3ce-ba92f8cad741.png)

> Bigger one(n^2 here) will **decide** the answer. Think of the **bigger ones** they will **decide** the answer. Don't worry about the **smaller** ones.

![image](https://user-images.githubusercontent.com/54589605/231712165-8d30bc15-3f98-4806-b33d-7c0e7f32316a.png)

> Comparing **n^2** and **n^2 + n + 1**, we proved **n^2** is **bigger** by taking **constant help** that the **left side** is **bigger**.

## Summary

* With the help of **constant** prove **right side** is **bigger or equal too** is **Big-O**.
* With the help of **constant** prove **left side** is **bigger or equal too** is **Omega**.

> We cannot take **function help**, we have to take **constant help** only to prove them. There is no **requirement** of **every c or every n0**. Just find **one(1)** pair of **c and n0**.

> Until **constant** help is **only possible**. If not possible with **constant** help or more than **constant** help is needed then **Big-O or Omega** is not possible there.

![image](https://user-images.githubusercontent.com/54589605/231714728-a3db7f75-a6f8-4502-b814-6a54fccf4160.png)

![image](https://user-images.githubusercontent.com/54589605/231906104-834a66aa-8262-40a6-ac46-19132abefd0e.png)

> From **c=1/2 and n0=5 onwards**, the **omega** notation is working.

![image](https://user-images.githubusercontent.com/54589605/231906337-c7802369-0621-4b53-8a45-7d0ab9a39e01.png)
![image](https://user-images.githubusercontent.com/54589605/231906672-9b6691e0-6c7b-4df6-9391-48792204260e.png)

> Here also, we proved that for **c=1 and n0=1 onwards**, the **Big-O** notation is working.

> For the given two functions **f(n) and g(n)**, we have proved that **f(n)** is **bigger** by taking the constant help of **c=1/2 and n0=5 onwards**, the **omega** notation is working.

> For the given two functions **f(n) and g(n)**, we have also proved that **g(n)** is **bigger** by taking the constant help of **c=1 and n0=1 onwards**, the **Big-O** notation is working.

> So for some value of **c and n0**, **omega** notation is working. So for some value of **c and n0**, **Big-O** notation is working.

* **c=1 and n0=1 onwards**, the **Big-O** notation is working.
* **c=1/2 and n0=5 onwards**, the **omega** notation is working.

![image](https://user-images.githubusercontent.com/54589605/231907332-afeff6b4-7834-4a0a-81c5-23fc03167a96.png)

> To eliminate the confusion of two **c** values we have taken **c1** for **omega** and **c2** for **Big-O**.

> So we can see that we have **c1=1/2 and c2=1** and **n0=5 and n0=1** respectively. As for **n0** values they are overlapping from **n0=5** which is the **common point**, so we will use **n0=5** as both **Big-O and omega** are working fro **n0=5** onwards.

> Hence, we can say that **c1=1/2 and n0=5**, we can say that **omega** is working and for **c2=1 and n0=5**, we can say that **Big-O** is working. So **Big-O and omega** both are possible.

> Then, we can say that **n = Theta(n+5)**, as we have proved that between **two people** both **Big-O and omega** are possible for some **c1=1/2** value, **c2=1** value and **n0=5** value. Then we can say **Theta** possible.

![image](https://user-images.githubusercontent.com/54589605/231908749-7dbb24e7-1b8e-42cb-bbaa-5e8b7cbb6cad.png)

## Theta Notation

> **Theta** notation is very simple, please prove **Big-O and omega** notation possible. **Both** should satisfy, if **one** fails then we cannot say guranteed.

![image](https://user-images.githubusercontent.com/54589605/231909143-6bff60a8-1480-423e-9c01-21b5b3c9c45e.png)

> In the **first point**, we have to find **c1** value where **omega** notation is working and along with it find the **n0** value which onwards **omega** is working.

> In the **second point**, we have to find **c2** value where **Big-O** notation is working and along with it find the **n0** value which onwards **Big-O** is working.

> After finding **c1 and c2** value we have to find the **common point** in **n0** where both **omega and Big-O** are working. If we find **n0=1 and n0=5**, then the **common point** would be from **n0=5**.

![image](https://user-images.githubusercontent.com/54589605/231909695-adb07659-96c4-4080-8c16-e53a7b34e66d.png)
![image](https://user-images.githubusercontent.com/54589605/231909842-004ac36d-b124-41a8-bca6-7f9ff2c5f03a.png)
![image](https://user-images.githubusercontent.com/54589605/231910556-498bf20d-e046-4174-87ce-123145dc95a4.png)

> To say **Theta**, **omega and Big-O** are possible. It is an **AND** operator, **both**, should be possible.

![image](https://user-images.githubusercontent.com/54589605/231911077-d1d2050e-8e64-4b2a-a598-0f654d7bf282.png)
![image](https://user-images.githubusercontent.com/54589605/231911887-b2670ce7-48fa-4d15-a67f-65dbe2c8bcc6.png)

> Sometimes **c1 and c2** maybe **same**.

![image](https://user-images.githubusercontent.com/54589605/231913041-0aed30fc-934e-406e-a49f-6eaf9b51cdbe.png)

> If any one of the them(Big-O and omega) fails, then **theta** also fails/not possible. That's the reason for **AND(&&)** operator.

![image](https://user-images.githubusercontent.com/54589605/231913216-f3b3510e-85aa-48c9-aa35-e44ed43d3040.png)

> If one fails, then **stop**. If **both pass**, then only **theta** is possible.

> **Theta** means **<= and >=** both should be possible because of **AND operator**, which means they should be **equal**. **<= and >=** both are satisfied which means they are **equal**. 

> But in the above question, **n** and **n^2** were not **equal**, that's why they failed.

![image](https://user-images.githubusercontent.com/54589605/231913579-50460486-4973-43e0-8b16-84aea672c22e.png)

> **Theta** means **equal**. But, **n** and **n^2** were not **equal**, that's why they failed or **theta** failed for them.

> If asked to find **theta** among **two** people, then we don't need to do/find **Big-O and omega** between them. We just need to verify that **both are equal** or not. 

> We don't need to do definitions also. **Theta** means **equal**. We just need to verify that **both are equal** or not. If they are **not equal**, then **theta** fails.

![image](https://user-images.githubusercontent.com/54589605/231913929-91ce6c26-52ac-4343-8b78-0b985fc86f97.png)
![image](https://user-images.githubusercontent.com/54589605/231914330-825936ff-08e7-4dfe-b171-cee62b4bcdfa.png)

> Here, in **both sides**, we have **n** which means both are **equal**. As they are **equal**, hence, **theta** is possible.

![image](https://user-images.githubusercontent.com/54589605/231914597-c0fa94ea-4c17-4064-ba14-eacc30ee28f7.png)
![image](https://user-images.githubusercontent.com/54589605/231915919-af202874-40a1-473c-a09b-5dbb875c3269.png)

> In this case, we have to see the **bigger values** which is **n^2**. As **n^2**, is present on both sides, hence both of them are **equal**. So, **theta** is possible.

> We have to compare the **bigger values**. **Smaller** values will be taken care of by the **constant(c)**. Just compare the **bigger values**. **Theta** possible means **Big-O and omega** both are possible. 

> These **two** are **equal** because we are neglecting the **Smaller** values. They are **mathematically not equal** but they are **asymptotically equal**. By neglecting the **Smaller** values/terms, **bigger** values are **equal**.

![image](https://user-images.githubusercontent.com/54589605/231916402-575910bf-9b98-46e1-91ce-f7a301d529e8.png)

> **Theta** means **asymptotically equal**, which means by neglecting the **Smaller** values/terms, **bigger** values are **equal**.

![image](https://user-images.githubusercontent.com/54589605/231916565-0024fafc-33aa-4b17-8a95-3d8275ab4a7e.png)

> In the above question, they are **mathematically equal** as well as **asymptotically equal** also. **Mathematically equal** means they will be **asymptotically equal** also but **asymptotically equal** doesn't mean they are **mathematically equal**.

![image](https://user-images.githubusercontent.com/54589605/231916941-be779ec7-2e6d-4b8a-a6da-ee529ad07b53.png)

> Both the sides are not **exactly or mathematically equal** but they are **asymptotically equal**, as **bigger** person is **same** for **both the sides**.

## Trick to find **Theta** notation [**IMPORTANT**]

> We have to check the **bigger** values/function on **both sides**. If the **bigger** values/function on **both sides** are **equal**, then **theta** is **asymptotically equal** and possible. 

![image](https://user-images.githubusercontent.com/54589605/231917675-9418171e-03b6-4c8a-86a3-177199316781.png)
![image](https://user-images.githubusercontent.com/54589605/231917733-9f8119c4-a9a6-4ad1-87f6-31d7a482142e.png)

> If without any **constant help**, **both sides** are **equal**, then **c1=1 and c2=1**. No need of any help. This is **mathematically equal**, so it is **asymptotically equal** also.

> If **theta** is possible which means that both **Omega and Big-O** are also possible. [**IMPORTANT**]

![image](https://user-images.githubusercontent.com/54589605/231918510-6b64bf8a-2b04-4c3b-b97d-622fe602392a.png)

>  As it is **Big-O**, the **right side**, is **bigger or equal too** left side. So, **g(n)** is **bigger** after taking **constant(c)** help.  **g(n)** is **bigger** after some **n0** point. From **n0**, after comparing **f(n) and g(n)**,  **g(n)** is **bigger** after taking **constant(c)** help.

> We have started from **1** and not from **0** because **n0 >= 1**. Some **minimum** input is required.

* The line with **Blue color** is **g(n)** function.
* The line with **Red color** is **f(n)** function.

![image](https://user-images.githubusercontent.com/54589605/231919498-07cc6598-4f19-43e2-889c-5c40e7676d4f.png)
![image](https://user-images.githubusercontent.com/54589605/231919612-e0e4dd56-2afb-4f42-9f24-3051c90ed1d3.png)

> It keeps on **changing**, we cannot tell for sure which is **greater**. Sometimes **g(n)** function is **greater**. Sometimes **f(n)** function is **greater**. We cannot tell for **sure**. We are unable to express which is **smaller** and which is **greater**. 

![image](https://user-images.githubusercontent.com/54589605/231920156-8a76f1ad-5388-45fb-8c62-d6a5b4b04aff.png)

> After a certain point, **g(n)** function is clearly **greater** after taking some **constant help(c)**.

> The **certain point**, is called as **n0** and the value of **n0=4** onwards,  **g(n)** function is **greater**.

> This is called as **Big-O** notation.

![image](https://user-images.githubusercontent.com/54589605/231920433-351fdc82-d030-4051-b069-caf5d6da8e94.png)

> Before **n0**, we cannot say for sure what is the **relation**. We have some **doubts**. From **n0** onwards, we can clearly say that **g(n)** function is **greater** after taking some **constant help(c)**.

![image](https://user-images.githubusercontent.com/54589605/231920492-cbaf0649-a19f-4381-8e4a-3412183a014f.png)
![image](https://user-images.githubusercontent.com/54589605/231920585-fc19618e-8855-41db-8e53-80f0af773261.png)

> In **diagram 2**, **f(n)** is **bigger**.

> We can directly say that after comparing **f(n) and g(n)**, we can say that **g(n)** is **smaller or equal too** after taking some **constant help(c)**. Which means **f(n)** is **bigger**. 

> Always talk about **right side**. Right side means **g(n)**. To whoem we are keeping **constant(c)**, we have to talk about them. As **c** is on the **right side** so we are taking about **g(n)**. So, **g(n)** is **smaller** after taking some **constant help(c)**.

![image](https://user-images.githubusercontent.com/54589605/231921461-28f703f3-dfe9-433b-b830-989e365f4a41.png)

> From **n0** point onwards we can say that **g(n)** is **smaller** after taking some **constant help(c)**.

> We have to keep **c** for **g(n)** only and not for **f(n)**.

![image](https://user-images.githubusercontent.com/54589605/231922367-e0941fe5-e87e-4c1a-9af0-cf193aa166d0.png)

> For some **constant(c1)**, **f(n)** is **bigger**, so it is **omega** notation.

> For some **constant(c2)**, **g(n)** is **bigger**, so it is **Big-O** notation.

![image](https://user-images.githubusercontent.com/54589605/231927546-c3b7cfee-f178-4ad2-80cb-8e2bfb69a821.png)

> For some constant, **f(n)** is **bigger** and for some constant, **g(n)** is **bigger**. Difference is **only constant**. Otherwise how is it possible. If **difference** is function, by changing **constants**, how someone becomes **smaller** and someone becomes **bigger**. 

> This means, difference is only **constant**. Bigger functions are **same**.

![image](https://user-images.githubusercontent.com/54589605/231928043-1b70ae1f-e23a-4818-9fa4-910371012065.png)

> If **g(n) = n + 5** and **f(n)= n**. Then, **theta** is possible as **difference is only constant**. One person is **n+5** and another person is **n**, **difference is only constant** and the difference will be taken care of by **c1 and c2** constants.

> By changing only constant, sometime **g(n)** is **bigger** and sometime, **g(n)** is **smaller**. This means that, **difference is only constant**. That's the **meaning of theta**.

> **Theta** is nothing but sandwitching **f(n)** between **two g(n)s**. Therefore, by **constants**. This is called as **theta**.

> These two, **f(n)** and **g(n)** are working from **n0** onwards only. Before, **n0** anything can happen. After **n0**, we got clarity what is **happening/going on**.

![image](https://user-images.githubusercontent.com/54589605/231929265-173ab310-b5f7-4b61-b949-38d8efbbee2f.png)


## Doubts

![image](https://user-images.githubusercontent.com/54589605/231929742-73ea385a-c446-4bd8-beac-ba1dd0d27ab2.png)
![image](https://user-images.githubusercontent.com/54589605/231930173-e99b2a32-c17f-4b01-a9c1-2c54443501f5.png)

* RIC -> PYQs.

> RIC then PYQs.

![image](https://user-images.githubusercontent.com/54589605/231930669-ebfac401-a2ec-408c-a4ac-17b1653a0cdb.png)
![image](https://user-images.githubusercontent.com/54589605/231930684-3d7f47b4-b26b-4667-92b0-f389b81e3b7f.png)

> Do the above ones, it is sufficient.

![image](https://user-images.githubusercontent.com/54589605/232482124-76d15d55-fe5e-4519-92fd-265cff2d30b6.png)
![image](https://user-images.githubusercontent.com/54589605/232482146-e7340cf4-6f29-4ea3-ba7f-43d3e69623ae.png)
![image](https://user-images.githubusercontent.com/54589605/232482176-db9c2d38-04ff-433c-b824-addda28a5bbf.png)
![image](https://user-images.githubusercontent.com/54589605/232482193-f85e4e01-3d95-4f22-a07a-6ecea39c9499.png)
![image](https://user-images.githubusercontent.com/54589605/232482218-2e49e577-a5c8-4e79-bc19-367bd3a90577.png)
![image](https://user-images.githubusercontent.com/54589605/232482239-9a35e270-b354-4c69-956f-7adae611b1fe.png)
![image](https://user-images.githubusercontent.com/54589605/232482263-d64cc02c-df1a-49a0-8e5f-692e44690e85.png)
![image](https://user-images.githubusercontent.com/54589605/232482281-c88c73c4-03fe-435e-9ae8-1fe83cc78065.png)





## DAC-PART-I (8) [17th April 2023]

## Big-O Notation(O, <=)

> **Big-O** means **right side**, should be **bigger or equal too**.

> Equal and greater poeple are **OK**. Smaller people are **not OK**.

![image](https://user-images.githubusercontent.com/54589605/232393589-25f43e3d-e83a-4b61-b912-08f6d02c0fb9.png)

> In **Big-O** notation, on the **right side**, how are allowed?

> **Bigger and equal** people. They are called as **Upper bounds**.

![image](https://user-images.githubusercontent.com/54589605/232394064-a5268f2f-555f-4188-b0e2-d064e4585396.png)

> Big-O means right side will be **more or equal too** left side. Big-O will give **upper bounds**.

![image](https://user-images.githubusercontent.com/54589605/232394637-d100f173-1995-4130-aa3d-1be589c18b7f.png)

* n^2 = O(n^3) -> Upper Bound
* n^2 = O(n^2) -> Tighest Upper Bound(TUB) 

> When both the sides are **equal**.

![image](https://user-images.githubusercontent.com/54589605/232395269-f917fd94-1700-4a12-9a3f-1b1db407eb36.png)

> In case of **Big-O**, we are giving **upper bound**. Upper bound means **equal or more**.

* A=O(B)

> **A** is the **actual** here. **Left side person** is always **actual**. That's why we don't talk about the **left side** as it is anyways **actual** only. We will always talk about **right side** person only. **B** is **upper bound**. The **upper bound** maybe be **tight upper bound(n^2)** or maybe not **tight upper bound(n^3,N^4,n^10)**.

![image](https://user-images.githubusercontent.com/54589605/232398069-a7549496-f3fe-4580-80fc-364c192ee0f2.png)

> All of them are **upper bounds**. **Equal(n^2= O(n^2) )** is called as the **tightest upper bound**. **Not equal** is know as **not tightest upper bound**.

![image](https://user-images.githubusercontent.com/54589605/232400104-9ccc1f6d-32bb-468f-bd3b-6e6083f90332.png)

* A=O(B)

> **B** is the **upper bound**, which may or may not be **tightest upper bound**. **Dilemma is there**.

![image](https://user-images.githubusercontent.com/54589605/232402122-75fb4aec-1e75-45e0-8f88-0da529b75a20.png)

> In **small o**, there is only **less than** and **no equal too**. That's why only the **not tightest upper bound** are there. 

> **Small o** means **strictly bigger**.

> In **small o**, the **not tightest upper bound** are there on the **right side**.

> In **Big-O**, all are there but in **small o**, the **not tightest upper bound** are there only. So, in **Big-O**, there is some **dilemma**, whether it is **equal** or **more**. But in **small o**, there is **no dilemma**, as only the **not tightest upper bound** are there only.

* If the time complexity of some algorithm is **small o of n^3 or o(n^3)**. This is the **right side**. What will be the actual **time complexity** on the **left side**?

> The **left side** should be **strictly smaller** as we are using **small o** instead of **Big-O**. The left side person should be **n^2 or n or log n etc**.

* **Small o** means **strictly bigger**.
* **Big-O** means **bigger or equal too**.

![image](https://user-images.githubusercontent.com/54589605/232404276-6095d6ac-ad89-428b-8da5-4f6241dab656.png)

* A=o(B) [Small o]

> **B** is **not tightest upper bound**. **No dilemma**.

> **Big-O** has dilemma which is maybe **tightest upper bound** or not. To remove it then we should go with **small o** as it has **no dilemma**.

> If we have **dilemmas**, then we can use **upper as well as lower bounds**.

![image](https://user-images.githubusercontent.com/54589605/232406025-b0e1feee-bfa0-466e-b63d-164f3f817f10.png)

* **Big-O** having **two** operators,**< and =**.
* **small-o** having **one** operator,**<**.

* If **small-o** is satisfied then the **Big-O** will automatically be satisfied.

* If **Big-O** is satisfied then the **small-o** may or may not be satisfied.

![image](https://user-images.githubusercontent.com/54589605/232409630-3dcc6900-e7dd-46f0-9b52-6efbe904b959.png)

## Omega Notation(>=)

* Lower Bound 

> **Omega** means **right side**, should be **smaller or equal too**.

> In **lower bound**, some are **tighest lower bound** and some are **not tighest lower bound**.

* A= Omega(B)

> It means **B** is **lower bound** but it is ambigious/in dilemma that **B** is either **tighest lower bound** or  **not tighest lower bound**.

![image](https://user-images.githubusercontent.com/54589605/232413597-a8b4edc7-bde5-4692-a0c5-3032b10ce356.png)

> **Equal** person(n^4= Omega(n^4)) is allowed because of the **Equal too**. But it brings the **ambigious/ dilemma**.

> We can remove the **dilemma** by using the **small omega(w)**.

## Small Omega(w, >)

![image](https://user-images.githubusercontent.com/54589605/232414475-741dbb99-677b-4193-b831-3c5d50cfdc84.png)

* If **small-omega(w)** is satisfied then the **Omega** will automatically be satisfied.

* If **Omega** is satisfied then the **small-omega(w)** may or may not be satisfied.

> **small-omega(w)** is the **subset** of **Omega**.

![image](https://user-images.githubusercontent.com/54589605/232414954-07e046e9-a62b-4a20-be58-85edb047e2f5.png)

> It is **minimum**, which means **lower bound**.

* n^4 = Omega(n)

> **Omega(n)** means that the **left side** is **more or equal too than n**.

![image](https://user-images.githubusercontent.com/54589605/232415508-40bf956c-5be1-4fdc-ac3b-bed7697a4330.png)
![image](https://user-images.githubusercontent.com/54589605/232415854-ef4fe1fe-ba03-47c1-a4f0-c6767403b44b.png)

* = Omega(6)

> If we say **Omega(6)**, then the **left side** should be **more or equal too 6**, which is **6,7,8....etc**.

> **Omega(6)** means that, we want to say that it is **6 or more than 6**, anytime.

* = w(6)

> If we say **small omega or w(6)**, then the **left side** should be **more than 6**, which is **7,8,9....etc**.

> **Small omega or w(6)** means that, we want to say that it is **after 6, at anytime**.

![image](https://user-images.githubusercontent.com/54589605/232416740-966bcfdb-3b77-4db3-8ebd-f8a66c4cc362.png)

* **Omega** is from **6 and onwards**.
* **Small omega or w**, **7 onwards**.

![image](https://user-images.githubusercontent.com/54589605/232418968-8a2cd0b2-de52-4f60-b904-e348d604c217.png)
![image](https://user-images.githubusercontent.com/54589605/232420262-31a3212a-dacd-4672-8dac-43dec9bb3f6b.png)

## Summary

* Strictly less than 7 or Before 7 -> **Small o**.
* 7 or less than 7 -> **Big-O**, as it is **upper bound**.
* 7 or after 7 -> **Omega**, as it is **lower bound**.
* Definitely after 7 only -> **small omega w**.
* Guranteed less than 9 -> **small o**.

![image](https://user-images.githubusercontent.com/54589605/232421937-485961a4-74b8-4824-8223-df51935959db.png)

> **Tighest upper or lower bound** are not possible in **small o or small omega**, as they don't have the **equal too** operator. 

> **Tighest upper or lower bound** are possible only in **Big O and Omega(Big Omega)**.

![image](https://user-images.githubusercontent.com/54589605/232422565-ad834736-2dc6-427a-82e8-9fe4e9dfe47d.png)

* Tightest Upper bound

## Theta Notation

> If between **two** people, **Big-O and Omega** are possible, then **theta** is also possible.

* A = Theta(B)

> **Theta(B)** means it is the **tightest upper bound** as well as the **tightest lower bound**.

> Theta possible means **Big-O and Omega** are possible.

![image](https://user-images.githubusercontent.com/54589605/232423668-0d864f95-51f0-4b4b-90f3-de2ba1f3c239.png)

> If **left and right** side are **not equal**, then **theta** is not possible.

![image](https://user-images.githubusercontent.com/54589605/232424058-689883c7-2be1-4137-93f8-0695180b2e09.png)

> It is **not possible**, if **left and right** side are **not equal**. One of the **sides** is **True** and one of the sides is **False**.

> If **both** are **equal**, then only possible.

> If between **two** people, **Big-O and Omega** are possible, then **theta** is also possible. If **theta** is possible which means that there is no doubt at all that they both are **equal**. **Equal** means **tightest upper bound** as well as the **tightest lower bound**

## Summary

* Want upper bound may or may not be tight -> Go for **Big-O**.
* Want upper bound which is not tight -> Go for **small-o**.
* Want all lower bounds -> Go for **Omega**.
* Want not tighest lower bound -> Go for **small-omega(w)**.
* Want tighest upper bound and tightest lower bound -> **Theta**.

> On all of them **left side** is the **actual** side.

![image](https://user-images.githubusercontent.com/54589605/232426300-0e8fadc8-519e-44ca-96fb-17ea02e26daa.png)

* As it doesn't go more than **n^2**

> Which means it is **upper bound**, so it is **Big-O(n^2) or O(n^2)**.

* As it doesn't go less than **n^2**

> Which means it is **upper bound**, so it is **small-o(n^2) or o(n^2)**.

![image](https://user-images.githubusercontent.com/54589605/232427466-12f5f406-4572-431b-9e04-8bb551d8bdc1.png)

## DAC-II (9) [17th April 2023]

## Complexity Classes

> **Constant** cannot change.

> When we say **Theta(1)**, it is not Theta(1), the **actual one(1)** is on the **left hand side**.

> Any constant can be written as **Theta(1)**.

![image](https://user-images.githubusercontent.com/54589605/232486492-3be678d6-dd48-417d-901d-95756899e404.png)

> Whichever takes **less time** is **better**.

* In terms of **time complexity**, **constant or Theta(1)** is better.
* In terms of **growth**, **log or logaredmic** is better.

* Bigger algorithm -> Worst algorithm
* Smaller algorithm -> Best algorithm

![image](https://user-images.githubusercontent.com/54589605/232492430-a92d37bb-6fc2-405d-a376-79693e46f195.png)

> As of now, **linear or Theta(n)**, is the **Bigger algorithm** and hence the **Worst algorithm**.

![image](https://user-images.githubusercontent.com/54589605/232492932-e2bc5ae4-dfa2-4cfb-b83f-bc53af8ce1b5.png)

> As of now, **exponential or Theta(2^n)**, is the **Bigger algorithm** and hence the **Worst algorithm**.

> As of now, **constant or Theta(1)**, is the **smaller algorithm** and hence the **best algorithm**.

* Whichever will take **less time** is **better**.
* Whichever will take **less space** is **better**.

![image](https://user-images.githubusercontent.com/54589605/232494980-be58eb49-f007-4b3f-af57-3e38f36b2a55.png)

> Definition of **polynomial** is **n^c**, where **c** is some **constant** and **c>0**, we cannot take any **negatives**. No integers, nothing, **fractions are allowed**.

* n^1 -> polynomial
* n^2, n^3 -> polynomial
* n^100 -> polynomial
* n^(1.414) -> polynomial
* n^(1.5) -> polynomial [1.5, is a constant and greater than zero(0)]
* n^0 -> Not polynomial [As, c should be greater than zero(0)]
* n^(0.5) -> polynomial

![image](https://user-images.githubusercontent.com/54589605/232496667-d829191c-e59c-4bef-9eac-568c88237155.png)

> The main ones are **constant, log, polynomial, exponential**.

> Inside **polynomial**, we have **n^1, n^2, n^3,....**, which are **linear, quadratic, cubic,....** respectively.

![image](https://user-images.githubusercontent.com/54589605/232497942-c77b56de-c50c-430e-93bf-545441d21f59.png)

> Definition of **exponential** is **c^n**, where **c** is some **constant** and **c>1**. They are **2^n, 3^n,4^n...**.

* (1.1)^n -> exponential
* 5^n -> exponential
* (51)^n -> exponential
* (1.01)^n -> exponential

![image](https://user-images.githubusercontent.com/54589605/232499031-085607f5-6d33-4afb-8014-be491e89f0f7.png)

> The **smallest function** is **constant**.

> The **smallest function** is from **constant, log, polynomial(linear, quad, cubic), exponential**. **Exponential** is the **biggest** function.

![image](https://user-images.githubusercontent.com/54589605/232499775-effeeeff-a702-4aa8-84f7-a873fb44d2e0.png)

> **linear, quad, cubic** are polynomials only but **special type** of polynomials, as they have **names** also.

![image](https://user-images.githubusercontent.com/54589605/232507821-63eb4795-15ab-4854-ad71-2dae69da038a.png)

* If asked, if less than **constant** possible?

> **YES**, possible. They are called as **decreasing functions**.

> Examples of **decreasing functions** are **1/n, 1/(2 * n)**.

> The **smallest/minimum**, time complexity of any algo is **constant or Theta(1)**. If no. of inputs increasing then the time is decreasing, how is that possible, atleast it should be **constant**, how time decreases. Less than **constant** time, how possible.

![image](https://user-images.githubusercontent.com/54589605/232527621-ff1650d7-9663-4267-a64a-c9a88c534db3.png)

> They are used for **all**.

> Time complexity or space complexity **decreasing**, possible? **NO**. **Minimum** is **constant**. No meaning of **decreasing**. Just remember it is **one of the functions**.

* Decreasing function < constant < log < (linear < quad < cubic) [Polynomial] < exponential.

![image](https://user-images.githubusercontent.com/54589605/232532909-06d35433-1c2c-430d-a495-4347810b4a79.png)

* n^n is **bigger**
* n! is **bigger**.

![image](https://user-images.githubusercontent.com/54589605/232536065-ffec6245-094b-4a91-ba53-4b0c131db639.png)

> Out of **n^n and n!**, **n^n** is **bigger**.

![image](https://user-images.githubusercontent.com/54589605/232536454-80cbe5af-77d4-43c5-a526-1c4986e576bc.png)
![image](https://user-images.githubusercontent.com/54589605/232536754-3024dca1-7aa5-4c6d-925a-c3e171950193.png)

> **2n** is **bigger** and it is **bigger** by a **constant**.

![image](https://user-images.githubusercontent.com/54589605/232536857-7cd9ff35-578f-4f75-a4c8-41e57d60890f.png)

> As **n!** is **bigger** by a **function** then **theta** not possible. So it is only **2^n= O(n!)**, Big-O. It is **bigger** by **function**. If it was **bigger** by **constant**, then **theta** possible.

![image](https://user-images.githubusercontent.com/54589605/232537758-4b7f378e-61e3-4f56-9991-a58db8f6312d.png)

> As **n^n** is **bigger** by a **function** then **theta** not possible. So it is only **n!= O(n^n)**, Big-O. It is **bigger** by **function**. If it was **bigger** by **constant**, then **theta** possible.

* n^n = Omega(n!)

> Whenever **Big-O** is there, by **reversing** the functions, we can write **omega**.

![image](https://user-images.githubusercontent.com/54589605/232539643-1d91b955-388e-4b33-8719-a6938da22bc5.png)

> We can **reverse** them and then we can use **omega** notation. If we reverse the **function**, then we can **reverse** the symbols also.

![image](https://user-images.githubusercontent.com/54589605/232540967-baf3b309-5b23-4b0d-8e4a-784df029fb88.png)
![image](https://user-images.githubusercontent.com/54589605/232541014-0118ebf6-00a2-476e-a15e-8a0fd741ad81.png)
![image](https://user-images.githubusercontent.com/54589605/232542330-12c33d89-dfd9-4d6e-82b3-8aa7d6422f62.png)

> As **omega** is not possible, that's why **theta** is also not possible. **Big-O** is only possible. 

> **Big-O and omega** possible means, **difference** is **constant**, then **theta** possible.

> In the **above** ones, difference is **not constant**, it is **function** that's why **theta** not possible.

![image](https://user-images.githubusercontent.com/54589605/232541701-2b434c9b-a1bb-4d53-ac5d-5b7e350f85f5.png)
![image](https://user-images.githubusercontent.com/54589605/232541786-0b3db813-e4b5-491d-a6f0-39c8b306ab1b.png)

* constant difference.

![image](https://user-images.githubusercontent.com/54589605/232541986-0a1dd5ca-9756-447f-986c-6d34aed4d66d.png)

![image](https://user-images.githubusercontent.com/54589605/232542423-4056974b-b8ab-4ef1-8c49-1592774948fc.png)

> **n^n** is **bigger** than **2^n**.

> Both **n^n and 2^n** have **powers** and they look **complex**. So, whenever complex functions are given and  we have to find which is **bigger** and which is **smaller**. Apply **log** on both the sides.

![image](https://user-images.githubusercontent.com/54589605/232543082-d02af8c6-9ae0-480a-bc21-5c95eb9c6d81.png)

> After taking **log** on both sides, we got **log n : 1** and **log n** is **bigger** so, **n^n** is **bigger**.

![image](https://user-images.githubusercontent.com/54589605/232543527-e18162b7-f1ec-4fc2-92aa-7a6087cb344d.png)

> **n^3** is **bigger**. Don't apply **log** there **easy questions**. 

> If we apply **log**, then we get **1 : 1**, which is **wrong**.

* Do not apply **log bliendly**. **YES**.

> Apply **log** to complex problems only.

![image](https://user-images.githubusercontent.com/54589605/232548364-7d83dd0d-55c4-49e5-be2f-733441a2dffa.png)

## Doubt_Clearning_Session (10) [18th April 2023]

> Base is **bigger**, **small** value.

> Base is **smaller**, **bigger** value.

> So **log n base 2** is **bigger** compared to **log n base 3**.

[**IMPORTANT**]

![image](https://user-images.githubusercontent.com/54589605/232773731-2236ee93-110f-43bb-800d-1fc09b043167.png)
![image](https://user-images.githubusercontent.com/54589605/232773796-ea3633bb-31ce-464f-b369-399dd2feaa90.png)

> **c** is **some common** base.

* log a base b -> log a base c/ log b base c

![image](https://user-images.githubusercontent.com/54589605/232774203-10d95547-ddd4-418a-9aa3-ff1fb22f8efa.png)

* log 64 base 4 -> log 4^3 base 4 -> 3
* log 64 base 2/ log 4 base 2 -> log 2^6 base 2/ log 2^2 base 2 -> 6/2 -> 3

> Between **two** people, if the difference is only **constant**, then we can write **theta**.

> If two people differ by only **base** which is nothing but **constant** only and not functions.

> Bases are only **constants** means, the **difference** is also **constant** only. Rest is **same** only. Only **base** differ and they are **constants** only, so **difference** is **constant** only. So, we can write, **theta**.

![image](https://user-images.githubusercontent.com/54589605/232777461-6bcb896a-4e99-4f75-b62c-8d0c6f00fdc9.png)

* If in a loop, **i** is incremented by ** i * 2**. How many **times**, the loop is repeating?

> **log n base 2**.

* If in a loop, **i** is incremented by ** i / 3**. How many **times**, the loop is repeating?

> **log n base 3**.

> One program's time complexity is **log n base 2** and another's is **log n base 3**. Asymptotically those **two** algorithms are **same**. They **differ** by **constants** but logic-wise they both are **same**.

> In a question, they asked for **time complexity** and the answer is **log n base 2**. In the options there was **log n base 2** and we **selected** that.

> If **log n base 2**, not there in the **options**, but **O(log n base 3)** is there in the **options**. Then we have to select **O(log n base 3)** as the **correct option** as **log n base 2** not there. Because the **difference**, is only **constant**.

> If **theta** is there, then **Big-O and omega** possible.

> Whatever is there in terms of **log** in the options just select that, because **base** are **constants** and don't worry much about them.

> If the answer was **log n base 2** and the options only had **log n**, then we should select that as the **correct option**, as **bases** are **constants** only.

> **log n base 20** and **log n base 30** are **asymptotically same** but **mathematically not same**.

![image](https://user-images.githubusercontent.com/54589605/232781758-6b94e57c-04a2-4233-8d5c-38f33ab8c84e.png)
![image](https://user-images.githubusercontent.com/54589605/232782175-fdccfd30-4383-49d9-bea7-9e4fea63e054.png)

> If two people are **log n**, therefore, **Big-O, omega and theta** are possible.

![image](https://user-images.githubusercontent.com/54589605/232783559-12834096-3f7f-4d11-8467-dbfe183ebc4a.png)
![image](https://user-images.githubusercontent.com/54589605/232784111-e4a13e1a-4943-4908-a6b0-3b54a069df45.png)

> **3^n** is **bigger**. But it is not bigger by **constants** but is is bigger by **exponential function** which is **(1.5)^n**.

* 2^n = O(3^n) [YES]
* 2^n = Omega(3^n) [NO]
* 2^n = Theta(3^n) [NO]

> **Omega** is not possible because **right side** is **bigger** by **fuction** and not **constant**.

> Remember, **3^n** is **bigger** by some **function** and not **constant**.

![image](https://user-images.githubusercontent.com/54589605/232787036-262db8ba-4fc1-4c49-aeb5-1c7d0dc0c616.png)

> Don't apply **log** in GATE exam. It is a **trap**. [**IMPORTANT**]

> **Worst case**, If applying **log** anyways, then remove/cancel the **common things**.

> **Common** means **writing one interms of another**.

### strling of n!

![image](https://user-images.githubusercontent.com/54589605/232790512-583716f1-59fc-4933-aa5c-43a06e12a930.png)
![image](https://user-images.githubusercontent.com/54589605/232790534-b81fd7c7-6055-47d6-b9f6-452bc7f5e41f.png)
![image](https://user-images.githubusercontent.com/54589605/232790722-1643ba7a-0556-4166-b2d7-4d1e124add8a.png)

> **n^n** is **bigger** but with **function** difference and not with **constant** difference. So, **Big-O** is only possible. **Omega and theta** are not possible.

![image](https://user-images.githubusercontent.com/54589605/232791210-747e7ea4-aa23-4ccb-94b1-1f9a56c44cb0.png)
![image](https://user-images.githubusercontent.com/54589605/232791552-ef4c476e-bad1-4ba6-8890-991b29f26acf.png)

> **n^n** is **bigger** but with **function** difference and not with **constant** difference. So, **Big-O** is only possible. **Omega and theta** are not possible.

![image](https://user-images.githubusercontent.com/54589605/232792535-a101ed9e-39c2-45de-98c6-00a2e167d8fc.png)

> **Before** applying **log**, **theta** is not possible.

![image](https://user-images.githubusercontent.com/54589605/232792592-8d90a77b-7e65-4328-8dea-48cbd79773f7.png)
![image](https://user-images.githubusercontent.com/54589605/232793182-51774b85-846e-41cf-a64a-7514357be8df.png)

> **After**, applying **log**, on both sides, which are **n! and n^n**. We got **n log n** on both the sides. As they are **same**, hence **theta** is possible.

> **Before** applying **log**, **theta** is not possible, but **After**, applying **log** **theta** is possible. This is because of **strling's approximation**.

> This is only for **n!**. Not applicable for others.

> On **6th point's**, part **1**, there is no **n!** there. So, **strling** will not **come**.

> On **6th point's**, part **2**, there is **n!** there. But **before** applying **log**, they both are **not equal**. Only **Big-O** possible. **Theta** is not possible.

> On **6th point's**, part **3**, there is **n!** there. But **before** applying **log**, they both are not **equal**. But **after** applying **log**, they both are **equal**. **Theta** is possible.

![image](https://user-images.githubusercontent.com/54589605/232795488-e7597a42-2149-4c48-b917-adee7365aa09.png)

> There are **two** people, **before** applying **log**, **theta** is not possible. **After** applying **log**, **theta** is possible, because of **strling approximation**. 

> **Strling** keyword will come whenever **factorial or n!** is given. [**IMPORTANT**]

> According to **Strling**, **n!** is not equal to **n^n**. **n^n** is **bigger**, **theta** not possible. But **after** applying **log**, they(n! and n^n) both are **equal**. **After** applying **log**, **left side**, became **n log n** and **right side** also became **n log n**. They both are **equal**, because of **strling**.

![image](https://user-images.githubusercontent.com/54589605/232801649-63a50cc0-5c4b-474f-b2d3-e609743528ec.png)

> On the **3rd last step**, from **1/2 log(2 * pie * n)**, we took **log n** and from **n logn - nloge**, we took, **n logn**, because **n logn** is **bigger**.

> In the **2nd last step**, **log n + nlog n**, we took, **nlog n** because it is **bigger** than **log n**.

![image](https://user-images.githubusercontent.com/54589605/232803378-7b13c256-d55e-41b9-99ec-d115ade9870d.png)

> **Before** applying **log**, left side which is **n!** is **n^n/e^n** and the right side is **n^n**. **Right side** is **bigger**, it is **bigger** by **e^n or exponential** times.

> **After** applying **log**, both are asymptotically **equal**, because of **strling**.

![image](https://user-images.githubusercontent.com/54589605/232804248-9e06855b-75dd-4027-9d3e-1f568501cf79.png)
![image](https://user-images.githubusercontent.com/54589605/232804880-d0878aad-e6f3-4f8c-8ba9-3a54d910f5fc.png)

> **Before** applying **log**, **theta** is not possible. Only **Big-O** is possible.

> **After** applying **log**, **theta** is possible. They both became **equal**.

![image](https://user-images.githubusercontent.com/54589605/232805131-a9a252a3-f037-42b2-b509-4321ef7d1498.png)
![image](https://user-images.githubusercontent.com/54589605/232805274-5ea618be-179f-42a2-89ce-fdc882863121.png)

* If asked to see if **theta** is possible or not? What is the relationship between these two people?

> **We will not apply log** and give answer.

> Before log, theta is not possible.

> After log, theta is possible.

> They are asking without applying log, if both are **equal** or not. **SAY NOT**. They are **not equal**.

> After applying log they are equal.

> After applying log, sometimes they are **equal**. Please avoid applying **log**. Until and unless they are **complex** people/questions, don't apply **log**.

> Before and after applying log sometimes behaviour changing or not. Because of behaviour changing, don't apply log.

![image](https://user-images.githubusercontent.com/54589605/232809398-3f78a340-0850-4e51-a9e8-35ca8b6e17b2.png)

> Before log, theta not possible. But after log, **maybe sometimes**, theta is possible.

* A= Theata(B)

> Don't blindly apply log.

![image](https://user-images.githubusercontent.com/54589605/232810217-5dbbf0ec-e328-4a3a-8cc2-d4c2b237a557.png)

* n^2 = n^3
* n^2 = (n^2 * n) [Cancelling/removing the common things/terms]
* 1= n [Now, applying log]
* log 1 = log n
* 0 = log n 

> We can see that after **careful** application of **log**, **theta** is not possible.

![image](https://user-images.githubusercontent.com/54589605/232812614-7e05900b-e39b-4de8-b6c2-3249b57b0c7b.png)

> Behaviour changing asymptotically. Mathematically nothing changes.

> If A < B. After applying **log** also, it is **A < B** only.

* A < B -> Mathematics. No constant, c.

> If we take some constant help, c, then it is asymptotic.

![image](https://user-images.githubusercontent.com/54589605/232814205-15c25737-3f53-4411-8c36-27e1393ece04.png)
![image](https://user-images.githubusercontent.com/54589605/232814483-e837b271-c61c-4e5d-bd25-fd302e02ac8b.png)
![image](https://user-images.githubusercontent.com/54589605/232815080-639cbbcf-aa18-44a8-a700-e3dd9ead3117.png)
![image](https://user-images.githubusercontent.com/54589605/232817842-c85b3d3d-867c-4c62-a0cb-1405c9cd27ea.png)

> After applying **log** carefully, **theta** is not possible.

![image](https://user-images.githubusercontent.com/54589605/232824974-4ac668f7-9b96-448a-a4a7-bd3028f000e3.png)
![image](https://user-images.githubusercontent.com/54589605/232826389-34bc2c4c-4b52-4408-93a3-5586088012e6.png)
![image](https://user-images.githubusercontent.com/54589605/232826558-0a8872cf-9bd6-4ff3-b484-bef36f9b3a34.png)
![image](https://user-images.githubusercontent.com/54589605/232841118-b628ea74-68a1-4fe1-a80f-b777158f56b0.png)
 
> **n * root(n)** means **n * n^(1/2)**.
 
![image](https://user-images.githubusercontent.com/54589605/232840835-5be58d22-2233-410d-8d20-e19e6669471a.png)

* n * sqrt(n) -> n * n^(1/2) -> n^1 * n^(1/2) -> n^(3/2) -> n^(1.5)

![image](https://user-images.githubusercontent.com/54589605/232842426-1912d987-f21b-49d9-be4b-759637b8b2a6.png)

> In **powers**, **constants** matters. We cannot ignore them. In the **power**, everything matters, we cannot ignore everything.

![image](https://user-images.githubusercontent.com/54589605/232843484-156580f5-4904-4210-b568-f06568241362.png)
![image](https://user-images.githubusercontent.com/54589605/232844455-2049318d-3c8c-418d-81ef-8cc0a21bda71.png)
![image](https://user-images.githubusercontent.com/54589605/232844489-3f1a77ca-4c1d-4c91-a02e-57b37f3b3609.png)

> In the **power**, anything is fine, cannot be ignored.

![image](https://user-images.githubusercontent.com/54589605/232844911-84b7a7f8-acbc-4ea8-bfee-043555e4e1e0.png)

> **Exponential** is **bigger** than **polynomial**.

![image](https://user-images.githubusercontent.com/54589605/232845199-b1d37e82-c2fb-43b1-9717-ca9ac97ac774.png)

> **D** is saying that **2^n** is not equal to **n^x**, which is **correct**.

![image](https://user-images.githubusercontent.com/54589605/232845526-2371c2b5-5be3-437d-842e-fac2de384dae.png)
![image](https://user-images.githubusercontent.com/54589605/232846052-6158ea33-a2f8-4d2c-9701-9636b52c0107.png)

[**IMPORTANT**]

![image](https://user-images.githubusercontent.com/54589605/232846175-aef3acaf-e801-4646-8807-a116cba393e7.png)

* a^(log b base c) = b^(log a base c)  [**IMPORTANT FORMULAE**]

> In the **power**, **log** is there, apply the above formulae.

* 64^(log n base 2) -> n^(log 64 base 2) -> n^(log 2^6 base 2) -> n^(6 * 1) ->n^6

![image](https://user-images.githubusercontent.com/54589605/232846940-5934a42f-4de3-48ef-8d61-903fc76a3600.png)
![image](https://user-images.githubusercontent.com/54589605/232847268-d1a708ce-d662-4a48-a892-8d86e00c1ec6.png)
![image](https://user-images.githubusercontent.com/54589605/232847441-698621c5-bbfd-4a9a-bb6f-1367fbc5417a.png)

> If **theta** is possible, then **small-o and small-omega(w)** has no meaning or are not possible.

# Practice Questions

* Link -> https://unacademy.com/course/complete-course-on-algorithms-gate/K8EKOMCE

> Every video has **5** practice questions. Do them **regularly**.

* Video 1 -> None given
* Video 2 -> Done [19th April 2023]
* Video 3 -> Done [19th April 2023]

# Doubts

## 1

![1](https://user-images.githubusercontent.com/54589605/233017636-36e65fe8-d0c0-4ef0-948e-d8f9645f247b.png)


## 2

> We are using **log N base 2**, and **base 2**, because we are representing the no. in **binary** form or in **bits** form as asked in the question, they are the **same** thing.

> For representing **15**, in **bits or binary** form, we have to do **log N base 2 -> log 15 base 2**, where **N=15**.

* Link -> https://unacademy.com/goal/gate-cs-it/NVLIA/doubts-and-solutions/doubt/4E9F25BC81

![2](https://user-images.githubusercontent.com/54589605/233017799-52346147-d5a1-432c-bfaa-8ddfbd134477.png)
![image](https://user-images.githubusercontent.com/54589605/233018553-b142659f-ee7c-45b2-b0bd-8b007928fc56.png)

## 3

![3](https://user-images.githubusercontent.com/54589605/233019898-38cf80a1-b44e-48e8-a794-312ff2a60fcc.png)

* Link -> https://unacademy.com/goal/gate-cs-it/NVLIA/doubts-and-solutions/doubt/E6B3684ACC

> First remove the **common things** then do **log**.

![image](https://user-images.githubusercontent.com/54589605/233023669-91b3d808-5d12-4f28-b7e8-6331db6c93c1.png)


## 4

* a^(log b base a) = b [**IMPORTANT FORMULAE**]

![image](https://user-images.githubusercontent.com/54589605/233021203-b25194ef-9fa5-435f-846b-935fc93733b8.png)

* Link -> https://unacademy.com/goal/gate-cs-it/NVLIA/doubts-and-solutions/doubt/3F80718DC8
* Solution -> https://unacademy.com/goal/gate-cs-it/NVLIA/practice/PQQFK?topic_type=2&topic_group=PQQFK&type=4&quiz_uid=NXB8YCHZX9&educator_name=Subbarao+Lingamgunta&source=Course

![image](https://user-images.githubusercontent.com/54589605/233022141-167e45cd-7b2e-471e-aef3-5ed97a89ad96.png)
![image](https://user-images.githubusercontent.com/54589605/233022187-04dbc2c1-67b2-48a6-92cb-7483728d2784.png)

* In Review


















