# Algorithms

## Course Link

* Link -> https://unacademy.com/course/complete-course-on-algorithm-768/MKL1PBOY

## Syllabus

![image](https://user-images.githubusercontent.com/54589605/229165900-6a29602a-d898-4e24-ba8c-b402cc2fe2bc.png)


## Time Complexity (1) [31st March 2023]

![image](https://user-images.githubusercontent.com/54589605/229171932-718dbe68-e46e-4d3a-9207-ba295985e033.png)
![image](https://user-images.githubusercontent.com/54589605/229172682-b9f36d76-c52d-48e8-94b1-b39b77cc24c7.png)

> Algorithm is a combination of sequence of finite steps to solve a problem.

> Combination of some(finite) statements.

> Algorithms is a generic programming language. From one language to another language, syntax will change a little bit.

![image](https://user-images.githubusercontent.com/54589605/229176423-2a904b6d-7ac9-4198-b545-c33c994860a3.png)
![image](https://user-images.githubusercontent.com/54589605/229176605-da580b3a-d2b3-4a93-8594-a39d3d26a44d.png)

> After writing the **algorithm**, we can write it in some **programming language** also.

> Algorithm is for **humans**. If we write the algorithm in some **programming language** then the computer will understand.

> We will first write **algorithm** then we will write **program**.

> We have an **algorithm** and we want to convert it into a **programming language**, the programming language we will **choose/prefer** depends on the **use case or what problem it is solving**.

![image](https://user-images.githubusercontent.com/54589605/229180078-515d676f-6e4f-4bee-bcda-7331c2708762.png)

## Programming of Algorithm

> Finite steps doesn't mean finite time.

![image](https://user-images.githubusercontent.com/54589605/229281293-38ed4065-ceb0-4780-93d2-c3050eceb2c7.png)

> It is a program but not an algorithm. Every algorithm is a **program** but every program is not an **algorithm**. Program may halt and may not halt. Program is a **turing machine**. For a problem, algorithm is possible which means **HTM or halt turing machine** is possible.

![image](https://user-images.githubusercontent.com/54589605/229282357-a3fe704d-1501-4054-a8a5-254fd4513ed8.png)

> Algorithm possible means program possible. Program possible doesn't mean algorithm possible. Program contains **infinite loop**.

* Difference between algo and program?

> Program may stop and may not stop. It may go to **infinite loop**. Algorithm has to **stop**. So, algorithm is a **HTM or halt turing machine**.

* Algorithm -> **HTM or halt turing machine** -> It will terminate after finite time.
* Program -> **Turing machine**

![image](https://user-images.githubusercontent.com/54589605/229284887-1973e0f8-56bf-4df2-b297-536a21c086c0.png)
![image](https://user-images.githubusercontent.com/54589605/229286759-629bf52e-d197-41e0-8ddb-e82cd7dc30e7.png)
![image](https://user-images.githubusercontent.com/54589605/229286825-a414e8e6-9eb8-436c-b6cd-b730b3a01259.png)
![image](https://user-images.githubusercontent.com/54589605/229286830-527b2280-b8a7-4520-92f7-6accfcf33014.png)

1) It should terminate after finite time
2) It should provide atleast one output
3) It should be deterministic
4) Every statement in algo should be effective
5) It is independent of **programming language**.

## Time Complexity-II (2) [1st April 2023]

## Steps to design algorithm for given problem

> With them procedures if we construct an algorithm then the properties are satisfied.

![image](https://user-images.githubusercontent.com/54589605/229287724-0cedcdd3-bb21-4f89-9a5e-5ae8ce210566.png)

1) Problem Definition
2) Select designing technique
3) Draw Flowchart
4) Testing
5) Implementation means coding
6) Analysis

> We have **3** designing technique in the syllabus, **Divide and conquor, Greedy and Dynamic programming**. There are **2** more which are not in syllabus, **Backtracking, branch and bound**.

![image](https://user-images.githubusercontent.com/54589605/229289909-51c4fa62-338b-41e4-bb61-454b75f7b46d.png)
![image](https://user-images.githubusercontent.com/54589605/229290767-b5f3187d-8d0f-46c9-bfe2-e51685df4a36.png)
![image](https://user-images.githubusercontent.com/54589605/229290775-9caa7490-667e-4aca-bc7d-b4e93a659269.png)

## Analysis

1) Finding Time and space complexity
2) 

![image](https://user-images.githubusercontent.com/54589605/229291429-c0f0a728-8db9-4a84-87ba-539ac61b0edb.png)

> Better solution will be provided by **analysis**. If **time complexity** is **same** then go for **space complexity**.

![image](https://user-images.githubusercontent.com/54589605/229291609-9b22ec38-09b3-483a-84f6-66f9a3004250.png)

> If the question, simply asks for **which is better**?

* Then give chance to **time** first.

> If the problem having more than one algo?

* Then, the **best one** is decided based on **time complexity(CPU time)** and **space complexity(Main memory)**. 

![image](https://user-images.githubusercontent.com/54589605/229291954-08421313-1964-4260-a96b-fe371dbd3b86.png)
![image](https://user-images.githubusercontent.com/54589605/229292024-04f749de-c1bc-4f97-ad92-571dde3894fb.png)

## Time Complexity

* 'p' is a program 
* Time complexity or T(p) = Compile time or C(p) + Running time or R(p).

![image](https://user-images.githubusercontent.com/54589605/229299347-0bf03c23-4020-44b1-95ef-9d4adfd22510.png)

> **Time complexity of a program** is **based/dependent** on the **language of the compiler and type of processor**.

## Types of Analysis

1) **Aposteriori analysis** -> **Based/Dependent** on the **language of the compiler and type of processor**. Exact answer. Computer-computer time complexity changes.
2) **Apriori analysis** -> **Independent** of the **language of the compiler and type of processor**. Appropriate answer. Same answer in every computer.

![image](https://user-images.githubusercontent.com/54589605/229301833-7e8fddfa-f9a4-426e-a75c-dfffb02db141.png)
![image](https://user-images.githubusercontent.com/54589605/229302215-e54baa48-232c-4b3c-84ba-cde47fabf1c9.png)

> According to **Apriori analysis**, everyone cannot buy **super computer** but everyone can write **super algorithm** because god gave **same  brain** to all.

![image](https://user-images.githubusercontent.com/54589605/229303214-bb14f85c-420c-432f-b7ea-29822503ed5d.png)

> Some poeple use it effictively and some not. Some people believe in themselves and some not.

## Apriori analysis

> Instead of saying **best logic**, they are saying it in some other way like **employee of the month**.

> It is a determination of order of magnitude of a statement.

> It is **indirectly** talking about **logic**.


> While running, the statement will run only **once or one time only**. This **once or one time** is called as **order of magnitude**.

> **Order of magnitude** of a statement means that while running **the statement will be executed by the processor for how many times**. So add **theta** to it  and it will be like **theta(1)** then it is called as the **time complexity**.
 
 > The **order of magnitude** with **theta symbol** is called as **time complexity**.
 
![image](https://user-images.githubusercontent.com/54589605/229303840-d1c8f434-032c-4829-b799-61ffe5cbcd41.png)
![image](https://user-images.githubusercontent.com/54589605/229303934-0a4124ee-a413-45e5-9932-7f79a6c79c4e.png)

> Every **constant** can be represented as **theta(1)**.
 
![image](https://user-images.githubusercontent.com/54589605/229304161-b151ec85-0e26-4aff-9e02-a7c369d48fde.png)
![image](https://user-images.githubusercontent.com/54589605/229304170-fc834516-18d4-46fe-96e8-2cbcfe57f76c.png)

> **1** will be **executed** once only.

![image](https://user-images.githubusercontent.com/54589605/229304857-4f848126-5396-4993-9cb7-376c255bbd16.png)

> So, time complexity is **theta(n)**. We are ignoring the  **small constant**. **Small constant** are nothing but **processor's speed**.

![image](https://user-images.githubusercontent.com/54589605/229305044-dbc08dca-7151-44b0-8db3-708cc2368385.png)

> We don't need to go **inside**. It still gives the **same analysis**.

## Time Complexity-III (3) [2nd April 2023]

> We have **3** statements here

> We are doing **approximate** analysis. Small things(constants) don't matter. Functions matter.

> Inner for loops are nothing but **product rule**.

* Inner loops -> Multiply
* Outer loops -> Add

![image](https://user-images.githubusercontent.com/54589605/229334747-af798f6b-fe13-4adc-9eb5-9478430d40dc.png)

> **Theta** means we can write **Omega and big O**. But **big O** doesn't mean **theta** and **Omega** doesn't mean **theta**.

> **Theta** work means **Omega and big O** will work also. We are not saying **reverse** is possible.

![image](https://user-images.githubusercontent.com/54589605/229334991-150870f6-5a3d-4d4e-b26d-9c6c079dacbd.png)

> According to **Apriori** analysis, **time complexity** is nothing but **finding loops only but also larger loops as well**.

> **Time complexity** is finding **where the cpu is spending the more time**.

> If **no loops** is there in the program **O(1) or constant**

> If **one loop** is there in the program **O(n) or linear**.

* What is kept in the cache memory?

> It doesn't have much storage, so we keep the **valuable content** in it.

* What is the **valuable content**?

> **bigger loops**, because it is the place where CPU spending a lot of time.

![image](https://user-images.githubusercontent.com/54589605/229339523-88dcd9f7-f142-4b1a-8da1-cb5e543d624d.png)
![image](https://user-images.githubusercontent.com/54589605/229339552-ff559af1-fc12-427d-ae30-04325d873e20.png)
![image](https://user-images.githubusercontent.com/54589605/229339577-2e4ad668-2cc8-4bb6-8b86-bd778f8658ad.png)

> In the first loop, condition is **True** for **'n' times**.

> In the fourth loop, condition is **True** for **'n^(1/2) or sqrt(n)' times**.

![image](https://user-images.githubusercontent.com/54589605/229339992-99d7aece-35f9-4103-b075-fd5a84499c44.png)
![image](https://user-images.githubusercontent.com/54589605/229340135-0bb65e07-ec0e-4ef4-8f00-adfb0ebee439.png)
![image](https://user-images.githubusercontent.com/54589605/229340464-e42a3e51-ed88-4ef3-83df-82afe298a2ad.png)

* pf -> printf();

![image](https://user-images.githubusercontent.com/54589605/229340590-0b238405-e873-4e9a-954d-59c4b5d0aac2.png)
![image](https://user-images.githubusercontent.com/54589605/229341332-cfe9cc2f-fcb4-4440-8da6-ae243454325a.png)

> First loop is going on for **k** times where **k=n^(27/5)**. So, that both the sides are **equal**.

![image](https://user-images.githubusercontent.com/54589605/229341399-281e7842-e9fb-4eef-a435-35210423cdb7.png)
![image](https://user-images.githubusercontent.com/54589605/229341576-4cf83bca-6d01-4dad-a118-7a56a7ac876c.png)

> Third loop is going on for **k** times where **k=n^(6/14)**. So, that both the sides are **equal**.

![image](https://user-images.githubusercontent.com/54589605/229341656-b154adc5-2b75-4a1c-821a-4c8b88fa1b16.png)

> **n^7** is bigger as **27/5 -> 5.4** and **6/14 -> 0.4** both are **smaller**.

> Loop is how many time.

![image](https://user-images.githubusercontent.com/54589605/229342051-bdcbb4f5-9752-423c-a75c-4496ef582d5a.png)

> **Recursion** is loop.

![image](https://user-images.githubusercontent.com/54589605/229342062-0bbcec3e-a01a-4477-be62-7118d3852da1.png)

![image](https://user-images.githubusercontent.com/54589605/229342416-7006c3b2-ff8e-4b94-8eef-5fc624e32d80.png)
![image](https://user-images.githubusercontent.com/54589605/229342547-04bad110-ecf7-4be8-8252-668c792219d3.png)
![image](https://user-images.githubusercontent.com/54589605/229342558-909f4fff-12bc-4fe0-af46-7e9f090b3362.png)
![image](https://user-images.githubusercontent.com/54589605/229342563-3a771f6e-9790-4d95-8d2f-d9190639063e.png)
![image](https://user-images.githubusercontent.com/54589605/229342571-ad2faa59-27b0-44e1-846f-4f5458fd4d8a.png)

> **2** loops. **n/5** since **i** is getting **incremented by 5**.

> Always whenever there is an incrementation, then **divide by that incrementation** to get the **time complexity**. In the above question, **i** was incremented by **5** so, the time complexity was **n/5**. If **i** was incremented by **50** then the time complexity will be **n/50**

![image](https://user-images.githubusercontent.com/54589605/229342585-ce510fa1-bdb5-4e0f-82c5-f33496042959.png)
![image](https://user-images.githubusercontent.com/54589605/229342662-61bd79fc-0364-426d-854d-33944558b575.png)
![image](https://user-images.githubusercontent.com/54589605/229342706-08e28d9d-610f-46ee-bcc5-323243b2266b.png)
![image](https://user-images.githubusercontent.com/54589605/229342782-ee653ff3-5fe1-46bc-8e1e-8241b12bb1d5.png)

> Whatever is the **power of n**, just put it in the **time complexity** and the **incrementation** stays the **same**. 

> In the **second while loop**, **i=n** and **i value is increasing**. It is an **infinite** loop. It will not stop. So, **it is not an algorithm** as it is not stopping. It is a program and the time complexity of the program is **infinite**.

![image](https://user-images.githubusercontent.com/54589605/229343139-4045f163-dd95-4ff8-ad7b-40a0a1331abf.png)

> In the first question we started from **big number** as **i=n**, so we have to **decrement or go in decreaseing order**.

> If we started from **small number** like **i=0 or i=1**, then we have to **increment or go in increasing order**.

![image](https://user-images.githubusercontent.com/54589605/229343228-06526dd6-dc6c-4e48-955b-eef4e2e5fa91.png)

> In the **second while loop**, the time complexity is **n**.

![image](https://user-images.githubusercontent.com/54589605/229343274-da5dc060-f3ce-4843-a9ac-a2eb562aaaf2.png)

> In the **second while loop**, the loops runs for **once or one time only**.

![image](https://user-images.githubusercontent.com/54589605/229343421-bb48e8aa-7df9-4cfd-ae9d-3ebec7fc5cc5.png)
![image](https://user-images.githubusercontent.com/54589605/229343426-268ceb68-1c4c-419b-a4b0-3dc38936e79f.png)

* Yes

![image](https://user-images.githubusercontent.com/54589605/229343433-c4efddaa-8586-4fb6-a655-4555a5e490c6.png)
![image](https://user-images.githubusercontent.com/54589605/229343478-8d416473-76f1-429c-a656-d4b337cd4307.png)

> Same only whether **addition or increment** and **substraction or decrement**.

![image](https://user-images.githubusercontent.com/54589605/229343552-f3bde92c-b923-4c18-acf9-eb4b885c725c.png)

> Overall is substraction means the program started with a **big number** i.e **i=n**.

![image](https://user-images.githubusercontent.com/54589605/229343597-837ef707-1b54-4b93-aa25-85fb4bfebe91.png)

> Overall is addition means the program started with a **small number** i.e **i=1 or i=0**.

![image](https://user-images.githubusercontent.com/54589605/229343718-d6a77cea-00ef-4da4-a562-ad8b12996483.png)

> So it is **i=i-50** and **time complexity** is **n/50**. See the overall effect and it is still overall **substraction**, so the program started with a **big number** i.e **i=n**.

![image](https://user-images.githubusercontent.com/54589605/229343796-84e8e8be-64d5-4dc2-9b41-ad3953c0c92f.png)

> So it is **i=i+90** and **time complexity** is **n/90**. See the overall effect and it is still overall **addition**, so the program started with a **small number** i.e **i=1 or i=0**.

> Otherwise for **both** addition and substraction it will case problems of **infinite loops**.

![image](https://user-images.githubusercontent.com/54589605/229343975-2b7c769c-2113-4112-b5e4-fd3b996f385b.png)
![image](https://user-images.githubusercontent.com/54589605/229344013-73f1c7c5-933d-450a-b09c-568f5c50f835.png)

> If the program started with a **big number** i.e **i=n** and we did **i= i+1000** in the **first while loop** then the loop will be **infinite** loop.

![image](https://user-images.githubusercontent.com/54589605/229344177-8acf7b96-a426-4edf-9c02-98f7a013427f.png)

## Doubt Clearing Session (4) [2nd April 2023]

![image](https://user-images.githubusercontent.com/54589605/229349862-73b2a70e-6345-4fc6-a4a7-06a0f10ce3cc.png)
![image](https://user-images.githubusercontent.com/54589605/229349870-1d8e505c-9c32-4385-93b5-276e711caf20.png)

> First for loop is **increasing** and the second for loop is **decreasing**. One is **increasing** and one is **decreasing** but both are taking the **same time**.

> After **K times**, we got **2^K=n**, which is the last iteration of the **first for** loop. So, after applying **log** on both the sides, we got **K= log n base 2**. So, the **time complexity** for the **first for** loop is **O(log n base 2)**.

![image](https://user-images.githubusercontent.com/54589605/229350276-a7762caf-8950-4e42-bea4-58086221325c.png)
![image](https://user-images.githubusercontent.com/54589605/229350290-e4eec45f-df14-4ce8-a0d6-f17caab10565.png)

> Everytime, **i** is **increasing by double**, then the time complexity is **O(log n base 2)**.

![image](https://user-images.githubusercontent.com/54589605/229351964-f76521c9-f06a-4c52-933b-0209f75b8f93.png)
![image](https://user-images.githubusercontent.com/54589605/229352028-9ec44231-d60d-4da0-8211-43f15bb3a7e9.png)
![image](https://user-images.githubusercontent.com/54589605/229352197-e49c3b0d-5bd4-4ee3-841d-1f7d21f3f4f5.png)

> If we **divide by 2 or multiply by 2**, the value of **i** when incrementing the value of **i**, then the **time complexity** will be **O(log n base 2)**.

> If we **divide by x or multiply by x**, the value of **i** when incrementing the value of **i**, then the **time complexity** will be **O(log n base x)**.

![image](https://user-images.githubusercontent.com/54589605/229352430-a212e56c-4125-4f70-b31a-97af79c87eab.png)

> **i=5 * i and i=12 * 1**, we wrote together, then the **i** value is **incremented** by **i= 60 * i**. Then the **time complexity** is **O(log n base 60)**.  

![image](https://user-images.githubusercontent.com/54589605/229352593-76da8a14-da18-4045-a3f3-715a046bbb1d.png)
![image](https://user-images.githubusercontent.com/54589605/229352717-07dc02b0-a0d7-4e0f-89d1-97695a4517b8.png)
![image](https://user-images.githubusercontent.com/54589605/229352818-45696cfa-6bf3-4d31-8e1d-892258d6766c.png)
![image](https://user-images.githubusercontent.com/54589605/229352948-2cc2ba3b-42bd-4bb1-b644-53ab5a5ae2d6.png)
![image](https://user-images.githubusercontent.com/54589605/229353768-9cecc04f-d127-4e07-a8aa-f432fc142c29.png)

> **log n base 2** is bigger. Whichever base is **small**, we will take that.

![image](https://user-images.githubusercontent.com/54589605/229353802-b930c798-068b-4998-b7fc-d61dce895be8.png)
![image](https://user-images.githubusercontent.com/54589605/229353807-3bc17e59-dd76-4574-9e2c-e51b06178815.png)
![image](https://user-images.githubusercontent.com/54589605/229353886-12398664-8899-4b9b-ae87-e7060ef5de00.png)
![image](https://user-images.githubusercontent.com/54589605/229355507-22d62859-86f3-4d52-9f45-215b225027c6.png)
![image](https://user-images.githubusercontent.com/54589605/229355571-2ac9850f-87d9-4df9-bfc4-00e347821c51.png)
![image](https://user-images.githubusercontent.com/54589605/229355617-faaede82-e486-4f95-a3cb-5ff50566476b.png)
![image](https://user-images.githubusercontent.com/54589605/229355673-97455b13-01f0-41f5-9a2b-dab0439cc142.png)
![image](https://user-images.githubusercontent.com/54589605/229355727-8e9d3755-47fe-4e10-9a08-8ed24f0649ac.png)

> For the first loop, it is **incrementing** as it has started from **smaller value** ie **i=1**.

> For the second loop, it is **decrementing** as it has started from **bigger value** ie **j=n**.

> What is the **overall effect** we have to check.

* **Add and sub** -> n/2 or n/5 etc. -> These loops are **bigger** than the **log** loops below.
* **Div and Mul** -> log n base 2 or log n base 20 etc. -> These loops are **smaller** but **faster** than above loops.

> For multiplication, multiply the **numbers** only and for **division**, divide the **numbers** only.

> **Less time complexity**, loop is repeating **less**, the **better**. So **log** is better than **Add and sub** -> n/2 or n/5**.

> Loop should repeat **minimum** time as possible.

![image](https://user-images.githubusercontent.com/54589605/229356272-5fe38aba-dc13-4fa8-93e6-ac19c717653e.png)

* O(log n base 35) [Ans]

![image](https://user-images.githubusercontent.com/54589605/229356507-ba125e31-6ab7-432b-b6ed-d1395bbc487d.png)

> As starting value of **i=5** and it will not affect that much as **5** is a **constant** value, we can ignore it.

> For **multiplication**, the **reverse** is **division** and vice-versa.

> For **addition**, the **reverse** is **substraction** and vice-versa.

> If we do **multiplication and addition** togerther then we get **7007** which is closer to **multiplication** and it gave **7000**. For the **addition**, we got **1007**. So,  **multiplication and addition** togerther is approximately equal to **multiplication**. Exactly not possible.

![image](https://user-images.githubusercontent.com/54589605/229357155-9466c0e2-4fc6-4c01-9515-4cf03176d88e.png)
![image](https://user-images.githubusercontent.com/54589605/229357239-d6743186-915a-4b1c-9ad4-910dfd2e815a.png)

> So **multiplication** is faster than **addition**, that's why it is affecting more and for **addition**, it is affecting in **constant** values.

![image](https://user-images.githubusercontent.com/54589605/229357689-4c9500e2-72a2-40de-a193-c632f8e118bc.png)
![image](https://user-images.githubusercontent.com/54589605/229357956-e58bff4c-5dd1-49bc-b664-cdcefdb45802.png)

[**IMPORTANT**]

* i + 2 -> n/2
* i * 2 -> log n base 2
* i * i or i^2 -> log(log n)

![image](https://user-images.githubusercontent.com/54589605/229358415-4b380b13-4c16-4a0e-a484-0ea122ea6aee.png)
![image](https://user-images.githubusercontent.com/54589605/229358602-865544b6-6614-462f-a331-44849290a8e0.png)
![image](https://user-images.githubusercontent.com/54589605/229358750-549d09b4-028a-48db-b3a7-1332c5e325a9.png)

![image](https://user-images.githubusercontent.com/54589605/229359090-e9f13bdd-7796-48e4-8596-205a4cf96039.png)

> The **time complexity** is **log(log n base 2) base 10**. 

> Because the **initial value** of **i** is **i=2**, so the **inner base** is **2** as it has come **before/earlier**. At the end the **power** of **i** is **i^10**, so the **outer base** is **10** as it has come **after/later**.

> This is how we got the **time complexity** of **log(log n base 2) base 10**. 

![image](https://user-images.githubusercontent.com/54589605/229359259-d856333b-c5e8-4bd5-ae05-2092c4c079f3.png)
![image](https://user-images.githubusercontent.com/54589605/229359296-a63b614a-ba6d-489c-abd9-8109f750df01.png)

> The **time complexity** is **log(log n base 2) base 30**. Even if we add **i= i =7** in the for loop, it has very small effect which is **some constant**. So, the result remains **same** still. It is **baccha** only.

![image](https://user-images.githubusercontent.com/54589605/229359399-249e129c-0a6a-489b-a1d2-95912b6d29e9.png)

> If we also include **i= i * 7**, then also the result remains the **same** as it has very small effect which is **some constant**. It is **baccha** only

![image](https://user-images.githubusercontent.com/54589605/229359506-85a8a026-06e9-41f6-9e9a-cd956c337594.png)
![image](https://user-images.githubusercontent.com/54589605/229359522-a014b913-19d9-4b63-b6d4-20779aaaab8a.png)

> **log(log n)** is faster compared to **n/2 or log n**. So **log(log n)** is dominating the **time complexity** value compared to them. Every oen is **participating** but **log(log n)** is dominating. So, **overall**, **time complexity** remains the **same** which is **log(log n base 2) base 30**.

> **Constants** doesn't have much effects.

* 9 * 6 * 5/(9) -> 6 * 5 -> 30 
* log(log n base 1500) base 30

> So, we got **log(log n base 1500) base 30** as the **time complexity** value.

> Because the **initial value** of **i** is **i=1500**, so the **inner base** is **1500** as it has come **before/earlier**. At the end the **power** of **i** is **i^30**, so the **outer base** is **30** as it has come **after/later**.

> This is how we got the **time complexity** of **log(log n base 1500) base 30**. 

![image](https://user-images.githubusercontent.com/54589605/229360322-f893ef84-4f51-4192-beff-e6a088cab979.png)
![image](https://user-images.githubusercontent.com/54589605/229360445-870e27a9-188d-49a7-b948-9fb67861ba25.png)

> Answer will be **same** only even if we remove **less than equal to** to **less than** only. As **i^9 or i^6 or i^(1/9)** have the **highest power** compared to **add, mul and divide** that why they are dominating here. We have **ignored** the **rest**.

## Asymptotic Notation-I (5) [3rd April 2023]

> As **i** is starting from a **larger no.**, **i=n**, hence the **overall** effect should be **decreasing or decrement**.

* 5 * 4 / 3 * 15 * 25 -> 4/ 9 * 25 -> 4/225
* log(log n base 2) base 4/225

![image](https://user-images.githubusercontent.com/54589605/229436098-855e308e-58d4-4fd2-bffa-aa5598aa3b09.png)

> So, we got **log(log n base 2) base 4/225** as the **time complexity** value.

> Because the **initial value** of **i** is **i=n**, so it has a **greater value**, so now we have to check the **initial value** where the **condition** ends, which is **i >=2**. So the **inner base** is **2** as it has come **before/earlier**. At the end the **power** of **i** is **i^(4/225)**, so the **outer base** is **4/225** as it has come **after/later**.

> This is how we got the **time complexity** of **log(log n base 2) base 4/225**. 

> This is also **wrong** because of the **below proof**.

![image](https://user-images.githubusercontent.com/54589605/229445145-f47c35d0-3c16-4869-9553-a0a4822a08f1.png)
![image](https://user-images.githubusercontent.com/54589605/229446072-049a5c25-8c90-4c6c-bf62-8f3f146ecc24.png)
![image](https://user-images.githubusercontent.com/54589605/229446245-bf099211-58f3-44f9-abb7-cd1f5aac3adf.png)
![image](https://user-images.githubusercontent.com/54589605/229451172-5cb10e53-0796-4fed-8c8e-cd47d89ff4fb.png)

> So, the **time complexity** is  **O(log(log n base 2) base 255/4)**.


![image](https://user-images.githubusercontent.com/54589605/229436734-f0c42dd7-a885-4b66-8281-5b86b20d82cd.png)

> If we got final value of **i** as **i^(1/2)**. Then, the **time complexity** is **O(log(log n base 2) base 1/2**.

> But **sir** is saying it should be **O(log(log n base 2) base 2**. Let's see his **proof** for these solution.

![image](https://user-images.githubusercontent.com/54589605/229438172-40197edc-20df-4d56-b7fc-1ea12be76696.png)
![image](https://user-images.githubusercontent.com/54589605/229451172-5cb10e53-0796-4fed-8c8e-cd47d89ff4fb.png)

> Here is the **proof** why we are getting **base 2** in **outer** base even though **i^(1/2)**. So, remember when we get **1/2** as the **power** then put **2** as the base. In the proof we got **O(log(log n base 2) base 2**, so for **i^(1/2)** we got **time complexity** as **O(log(log n base 2) base 2** and not **O(log(log n base 2) base 1/2**, which we thought **initially**. 

> If it is **i^(1/2)** then it is **ulta/opposite** i.e **base 2** as the **outer base**.

![image](https://user-images.githubusercontent.com/54589605/229447306-8acf58ba-a21c-46ea-bac2-7b69ab6f6815.png)

> For **square**, reverse is **root**. They(square and root) both are the **same**. So, **i^(1/2)** is **root** only.

> Initially **i=n** and after **k times**, it is **n^(1/2^k) = 2**, which is the **termination** condition for the loop. We want the **k** value as it has looped for **k times**. So after applying **log**, we get **1/(2^k) * log n base 2=1**. So, **log n base 2 = 2^k** and after applying another **log**, we got **k = log(log n base 2) base 2**.

![image](https://user-images.githubusercontent.com/54589605/229451172-5cb10e53-0796-4fed-8c8e-cd47d89ff4fb.png)
![image](https://user-images.githubusercontent.com/54589605/229448219-3d9d39f6-5d57-47b9-8358-5f46bd4f9598.png)

> Initially **i=n** and after **k times**, it is **n^(4/255)^k = 2**, which is the **termination** condition for the loop. We want the **k** value as it has looped for **k times**. So after applying **log**, we get **(4/255)^k * log n base 2=1**. So, **log n base 2 = (255/4)^k** and after applying another **log**, we got **k = log(log n base 2) base 255/4**.

![image](https://user-images.githubusercontent.com/54589605/229450647-f70a7f71-4b00-4dd4-8d88-2fd6be134bbd.png)
![image](https://user-images.githubusercontent.com/54589605/229449100-7c669f9a-baf4-43e0-807c-e740f6f2681e.png)

> So, when we are doing **i^20** and the **initial value** is **i=2**, the time complexity is **log(log n base 2) base 20**.

> So, when we are doing **i^65** and the **initial value** is **i=2**, the time complexity is **log(log n base 2) base 65**.

> It is similar for **root** also. So, when we are doing **i^(1/2)** and the **initial value** for the **termination** condition for the loop is **i=2**, the time complexity is **log(log n base 2) base 2**. So, **reverse** is happening.

![image](https://user-images.githubusercontent.com/54589605/229454189-cfd8032b-7ca6-4f4e-8041-4ee4b8c58a7a.png)

> If we add **i= i + 75**, then also the **result** remains the **same** as  it has **very small effect**. If we add **i= i * 75**, then also the **result** remains the **same** as  it has **very small effect**.

![image](https://user-images.githubusercontent.com/54589605/229454633-edbc6237-8d4f-4db1-8dab-e56c1877d019.png)

> So, if the  **initial value** for the **termination** condition for the loop is **i=23**, then we get **n^(4/225)^k = 23**. Hence, the value of **k= log(log n base 23) base 255/4)**. So, the **time complexity** is **O(log(log n base 23) base 255/4)**.

> Try to understand what is **happening**. **Time complexity** means **how many times the loop is running and what is happening within the loop**.

## GATE Questions

* Find **time complexity** and **value of q**.

> For the first loop, the **time complexity** is **log n base 2** and **p** value is **incrementing everytime**. The loop is repeating **log n base 2** time and **p** is **incrementing everytime**. So, **p** value is **p= log n base 2** only. So, how many times the loop is repeating that many times only **p** is incremented.

> After the end of the first loop, **p= log n**.

> For the second for loop, the **time complexity** is **log p base 2 -> log(log n base 2) base 2**. The second loop is **log p** time and not **log n** times as **j <=p** is the condition.

> As from the first for loop, we gathered whatever is the **time complexity**, that value is the value of **p**. So, here in the second for loop as well, whatever is the **time complexity**, that value is the value of **q** which is **q= log(log n base 2) base 2**.

![image](https://user-images.githubusercontent.com/54589605/229472063-cd52d5b5-b7f4-4acb-9bcd-3553238a8382.png)
![image](https://user-images.githubusercontent.com/54589605/229484717-2e29daf4-7aff-4e5c-b8d4-47f9372e097b.png)
![image](https://user-images.githubusercontent.com/54589605/229488396-fec7b740-17de-42ce-86c1-38250c7cccb5.png)
![image](https://user-images.githubusercontent.com/54589605/229488623-74c42aee-b4d5-401a-9084-479fccb4ec2e.png)

> This is for when we have many values within **one** loop only. If we have **add and mul** within one loop then **mul** will be **faster** than **add**, so it will have much more effect than **add**. That's why we ignored **add** in that case and took the **faster value**.

> When finding **time complexity**, then we have to take the larger value like **log n > log(log n)** in the above example as if **n=16**, then **log 16 -> 4** and **log(log 16) -> log 4 -> 2**. As **4 > 2** which means **log n > log(log n)**. Hence we took **log n** as the **time complexity** in the above question.

[**IMPORTANT**]

> They are **two** different loops and they are **outer** loops, when **outer** loops, take the **larger one**.

![image](https://user-images.githubusercontent.com/54589605/229489833-b7094cbd-6aa4-491f-9e0b-85eba2b46e68.png)
![image](https://user-images.githubusercontent.com/54589605/229491861-8bd6410e-4516-4b4c-a3f5-b48bfabcd48a.png)

> Time complexity is **O(nlog n)** because the time complexity between the inner for loops is **log n** but the outer for loop is running for **n times**. So, it is **O(nlog n)**. The **q** value remains the same because every in the outer for loop, **p and q** are initialized by 0 only.

* return -> Get out of the function.
* exit -> Get out of the entire program or stop the program.

![image](https://user-images.githubusercontent.com/54589605/229493160-63908197-026f-4d08-a8a0-99c5c291754f.png)
![image](https://user-images.githubusercontent.com/54589605/229498658-742e3bc2-fa3f-45f9-810f-bd4a613428e1.png)
![image](https://user-images.githubusercontent.com/54589605/229499000-3e3da2fb-eaac-42a5-916a-1dffa2725d37.png)

> If **q=0** was within the first for loop like **p=0**, then the **q** value would have been **q= log n**, as after every loop, q value would have been initialized with **q=0** only.

* break -> outside loop or out of the loop.
* return -> outside the function(same as above), just different wording.
* exit -> program stops

![image](https://user-images.githubusercontent.com/54589605/229500169-d964c9f0-4f2e-4d42-83e5-4f6cc08b0848.png)

> For the first loop, time complexity is **log n^2 base 7** as the termination condition for the loop is **i <= n^2** that why.

> For the second loop, time complexity is **log n^2 base 7** as the termination condition for the loop is **i <= n^2** that why.

![image](https://user-images.githubusercontent.com/54589605/229502823-f7f097b7-0546-41d8-ac04-33e012c59105.png)
![image](https://user-images.githubusercontent.com/54589605/229503671-6dbfb9a4-7dae-4fee-ad9c-5ed7fdce71e4.png)

> Both are correct if we ignore the **constants**. Check which is given in the **options** of the question. Choose that one.

![image](https://user-images.githubusercontent.com/54589605/229505160-0a9114d3-7db8-4966-a2fe-94414755cf50.png)

> For the **value of x**, as the **inner loop** is repeating **log n** times and every time **n** is getting added so **n log n** but the **outer loop** is also there which is **log n** times. So, value of **x = log n * nlogn -> n * (log n)^2**.

![image](https://user-images.githubusercontent.com/54589605/229505864-77653c1c-7b46-4776-8359-026cf1ded495.png)
![image](https://user-images.githubusercontent.com/54589605/229506380-2c667974-8038-47a7-b56c-ee41add96fe9.png)

> If we have replaced the variable **n** in **x= x + n** with **x=x+1**, then the **value of x** is **log n * log n -> (log n)^2**. As the inner loop runs for **log n** times and the outer loop also runs for **log n** times.

> By replacing **n** with **1**, the **value** is changing only. The **time complexity** is **same** only. Time complexity will only change when loops are **increasing or decreasing**.

![image](https://user-images.githubusercontent.com/54589605/229507869-3706aefb-48c6-478e-961e-9066f9677571.png)

> Even if we put **0**, then also only the **value** changes. The **time complexity** remains **same** only.

> In **power**, constants matter, don't ignore them there.

![image](https://user-images.githubusercontent.com/54589605/229513967-e69ba091-bc02-4051-b9b2-f326e8cae36b.png)
![image](https://user-images.githubusercontent.com/54589605/229516312-1b66d5e2-7d55-4c94-812d-9252496a1841.png)
![image](https://user-images.githubusercontent.com/54589605/229516249-abe8a073-a836-4692-b8fe-199d8467ff15.png)
![image](https://user-images.githubusercontent.com/54589605/229516472-ecd2a386-997a-4998-b6a4-a7f951ad85c5.png)
![image](https://user-images.githubusercontent.com/54589605/229516823-dd337e48-f32b-45e3-bfc0-cf7bc2aaf8f7.png)

> If both the loops have **n** complexity then the value of **x** will be **n^(n^2)**. As **j** loop has run **n** times and each time **n** is multiplied to **x** then the value of **x** after whole of **j** loop is **n * n -> n^2**. So, **n * n -> n^2** will be for each loop of **i**, so for **n** loops of **i**, we get **n^(n^2)**.

![image](https://user-images.githubusercontent.com/54589605/229517864-ec76b7f1-355f-474e-b50b-339c380ea928.png)
![image](https://user-images.githubusercontent.com/54589605/229518106-566ea1c0-95dd-4296-a20f-3781f41d598d.png)

> So multiply **n^(1.57) * log n^7 base 8** and that is the **answer** for the given question.

![image](https://user-images.githubusercontent.com/54589605/229521532-a59fcc11-2c5d-4a57-a2f7-3aea51a22d12.png)
![image](https://user-images.githubusercontent.com/54589605/229521845-0e5338df-6e86-4b3a-b21d-5a71d2a0d21c.png)

> If **x=0**, then **0 * anything -> 0**. So, the value of **x** will be **0** only.

> There are **2** loops in the program. They are **inner** loops as **j** has come before **i** has completely stopped. AS they are **inner**, so we have to **multiply**.

> As **n** is a **prime no**, it has **only two factors** i.e **1 and itself**. So, for all the values of **i**, only **two** values will enter the **j** loop.

![image](https://user-images.githubusercontent.com/54589605/229525351-ff33b8a5-6dd6-41ee-bbef-a6f69111cc9b.png)
![image](https://user-images.githubusercontent.com/54589605/229525731-040aacb7-feb2-44be-b5c6-80d8d319ce75.png)
![image](https://user-images.githubusercontent.com/54589605/229525849-0890ab9c-f0e7-44d9-9b18-11c4d9d74a46.png)

> Even though there are **two** loops and they are **inner** loops. We only got **time complexity** as **O(n)** as there is an **if** condition which is stopping most of the **i** iterations to go to **j** loop. Everyone not allowed into **j** loop. Because of **n** being **prime number**, only **two** values can go into **j** loop.

![image](https://user-images.githubusercontent.com/54589605/229526008-c669800a-d873-4aac-b86f-e4a726abf724.png)

> If we remove the **condition** then the **time complexity** as **O(n^2)*.

![image](https://user-images.githubusercontent.com/54589605/229610057-63d39edf-fc3e-4f3f-a04c-444b937b3a20.png)
![image](https://user-images.githubusercontent.com/54589605/229610083-5ed96e12-f13e-4771-a543-08de173875e7.png)
![image](https://user-images.githubusercontent.com/54589605/229610117-fa09f375-4011-419e-94f8-78919579c1e2.png)
![image](https://user-images.githubusercontent.com/54589605/229610141-f21463be-d26d-4661-bec2-2d524e5a91cf.png)
![image](https://user-images.githubusercontent.com/54589605/229610164-75e7104b-2869-4289-9ef0-39b018acd540.png)
![image](https://user-images.githubusercontent.com/54589605/229610188-cb14c423-f0bd-4327-b9d6-0d282bf3ea82.png)
![image](https://user-images.githubusercontent.com/54589605/229610201-9735d2e5-c655-43d4-a010-b63421294136.png)



## Asymptotic Notation-II (6) [3rd April 2023]

### Time Complexity Questions continued

> There are **two** loops and they are **inner** loops. In **j** loop, it is dependent on **i**. Without mentioning **i**, we cannot define **j**. As **j** is dependent on **i**, or when **one** is dependent on **another** then we can't write them individually. We have to write them **combinedly** only.

> Based on the **dependency**, we cannot **divide**. Based on **i**, **j** will come. **j** is how many times? **i** times. Whenever there is a  **dependency**, we cannot **separate** them. We have to take **both** of them into consideration.

![image](https://user-images.githubusercontent.com/54589605/229578017-d9cf42fd-595f-4dac-a768-e6fe24d3e71d.png)

> If **n terms** are there then **each term** is **one loop**. We are getting the **terms** because of the **combination of i and j**. **i** will say how many loops. **j** will say every loop how many time.

![image](https://user-images.githubusercontent.com/54589605/229582397-11aa207b-9eb5-49a1-82e5-74d4f01e91f2.png)
![image](https://user-images.githubusercontent.com/54589605/229582500-1649aff7-3fc2-4944-aa2d-eb9e7deee18f.png)

> So, the **time complexity** will be **O(n^2)**.

> If **i=1**, then **j** loops  **one** time only.

![image](https://user-images.githubusercontent.com/54589605/229582790-576b0543-4ea8-4511-bcdf-a951bbc99c86.png)

> Instead of **i**, we have put **n** in the **j** loop, then also we would get **O(n^2)** as the **time complexity** which is the **same** as before. But in the **above question**, the actual answer is **n(n+1)/2** but we are simply ignoring the **constants**. So we get **O(n^2)**.

> For the **2nd question** we get **O(n^2) or n * n**, which is the actual correct solution. So they are not the same solutions.

> So the symbol we write on the right hand side which is the **Theta**, are simply **approximation**. But before **Theta**, whatever we write that's the **actual** solution.

> We are **approximating** because the **actual values** differ from system to system, if the system is **slower** then we could get **n(n+1)/2^t** or if the system is **faster** then we could get **n(n+1)/1.2**. So the **actual** answer is varrying with **constant** values. That's why we use **approximations**.

> So the **actual value**, **n(n+1)/2** will change from system to system. It could be **n(n+1)/20** or **n(n+1)/200** or **n(n+1)/2000000**. They keep on **changing**, but in every system one thing is **common** that is **n^2**. **Constant factor** will only **change**. This is the **meaning** of **Theta(n^2)**. From system to system in the **actual answers**, the **constant** factor can **change**. But one thing is **common** in every system which is **n^2**. Some constant factor **n^2**.

![image](https://user-images.githubusercontent.com/54589605/229583693-5e948183-2cc2-43d7-98a6-29e60a59197b.png)

* 1 + 4 + 9 + ........ + n^2 -> Series

* Above series explaination -> https://math.stackexchange.com/questions/1544526/the-sum-of-the-first-n-squares-1-4-9-cdots-n2-is-fracnn12

![image](https://user-images.githubusercontent.com/54589605/229589693-8d7753ca-fa17-402d-bc97-4385e90ca287.png)

> So it givens **n^3**. Hence the time complexity is **Theta(n^3)**. So, in every system **n^3** is **common**.

![image](https://user-images.githubusercontent.com/54589605/229590344-6a20a21d-ba93-4b54-960f-b69ba8ee783d.png)

> The loop is **dependent** on **s**. **s** is always incremented by **i**, but **i** is always incremented by **1**. After doing **k times**, the total sum is equal to **n**.

![image](https://user-images.githubusercontent.com/54589605/229593178-08f36cd9-065c-4bc8-8513-bfe952a97276.png)

> If **s** is incrementing by **s= s + i^2**. Then, the **time complexity** will be **Theta(cube(n)) -> Theta(n^(1/3)**.

![image](https://user-images.githubusercontent.com/54589605/229594030-c427c7bf-1497-45d5-a63a-11f8c22b6ff1.png)

> **j** is based on **i** loop. **YES**. If a for loop **j** is incremeneted by **3** then **time complexity** is **n/3**. If a for loop **j** is incremeneted by **10** then **time complexity** is **n/10**. If a for loop **j** is incremeneted by **20** then **time complexity** is **n/20**.

> So, in the below question **j** is incremented by **i** then **time complexity** is **n/i**. There is **dependency**. So, if **i=1**, then the **j** loop will repeat, **n/i -> n/1 -> n** time.  So, if **i=5**, then the **j** loop will repeat, **n/i -> n/5** time.  So, if **i=n**, then the **j** loop will repeat, **n/i -> n/n -> 1** time. The **series** we got is by considering **both, i and j**.

![image](https://user-images.githubusercontent.com/54589605/229597235-984ca85c-a5e0-4f3a-bf99-41612ef02c8c.png)

* n/1 + n/2 + n/3 ............. + n/n -> n[1/1 + 1/2 + 1/3 + ........ 1/n] 

> This is a **logarithmetic series**. So we get **n * log n -> n(log n)**. The **constant factor**, **[1/1 + 1/2 + 1/3 + ........ 1/n]** is equal to **log n**.

* [1/1 + 1/2 + 1/3 + ........ 1/n] -> log n

> As **1/n** is there so **log n**.

* [1/1 + 1/2 + 1/3 + ........ 1/log n] -> log(log n)

> As **1/log n** is there so **log(log n)**.

> So, whatever is there at the end **1/whatever**, then we do **log** of it so, **log(whatever)**. That's the **logic**.

> They are **inner** loops. They are **dependent** on each other. They are based on **one variable**.

> **int i** means **i** is declared and **memory** is allocated for it.

![image](https://user-images.githubusercontent.com/54589605/229601850-49e40c3c-e57e-4f38-b368-cf247af0f3d5.png)
![image](https://user-images.githubusercontent.com/54589605/229601964-cf7df09f-3a5e-4761-91fd-a92d019d5906.png)
![image](https://user-images.githubusercontent.com/54589605/229602095-6ee91b9e-d3ea-4703-8fdd-180f86e0ca94.png)

> We got **n^3** from the inner most loop and in the next iteration it was **n^3 + 1** which is greater than **n^3**, so the condition of the loop fails and we go to the **second loop**. We check the condition that **n^3 + 1** is less than **n^2** and it is **false**, so we go to the **first/outer** loop. We check condition that **n^3 + 1** less than **n** and it is **false**. So, we get out of all the loops. We got **1** itiration in **first loop**, then **1** itiration in **second loop** and **n^3** iteration in the **third/last** loop. So the **time complexity** is **O(1 * 1 * n^3) -> O(n^3)**.

![image](https://user-images.githubusercontent.com/54589605/229602918-0417a5b8-c2be-4139-959f-2e828b68f631.png)

> If we do like that then **each i** value is localized to their respective **for loop** blocks only. So, they are **different** now. Now, there are **two** declarations. First loop has it's own declaration and the **second and third** loops have their own declaration.

![image](https://user-images.githubusercontent.com/54589605/229603089-a59164c5-9196-43fd-831e-d5845205c438.png)
![image](https://user-images.githubusercontent.com/54589605/229603054-cc0bc2ad-df4f-4e60-89ef-66f854c750b4.png)

> If we write **int i** in every for loop, then there are **three** declaration and each and every loop is **different**. It is like **i, j and k**. It is like **three** different variables. One person don't see the **other person**. Everyone is individual. Their scope is **inside** their respective **for loop** blocks.

![image](https://user-images.githubusercontent.com/54589605/229603558-0ec35f2e-78d6-4f94-a8cc-881e366f4db6.png)
![image](https://user-images.githubusercontent.com/54589605/229604245-288c988d-fa18-4bab-a0ac-2cb00b7f7c48.png)

> Now, there is only **one i**.

![image](https://user-images.githubusercontent.com/54589605/229604504-ea0d11a5-8166-4cf2-a294-48ed0cc1bc22.png)
![image](https://user-images.githubusercontent.com/54589605/229605386-2b910a46-f155-448b-a652-5a1ffba17d48.png)
![image](https://user-images.githubusercontent.com/54589605/229605859-6267f4da-66bd-4286-abec-17cd32c2679c.png)

> It is forming an **infinite loop**. So, it is not an **algorithm**. It is a **program** which is going to  **infinite loop**.

![image](https://user-images.githubusercontent.com/54589605/229606268-a822465d-caac-47ea-9a83-c2b59e5c8a2d.png)

> Inner loops affecting outer loops.

![image](https://user-images.githubusercontent.com/54589605/229610287-aecda8f1-f14b-4c88-a8a1-23693cb27b8f.png)
![image](https://user-images.githubusercontent.com/54589605/229610310-03c68713-57d0-409f-8ca4-eae1d1b5a897.png)
![image](https://user-images.githubusercontent.com/54589605/229610337-e9fde60f-c3c2-4ae7-bf2e-a165a911d2a6.png)
![image](https://user-images.githubusercontent.com/54589605/229610357-63d12144-f145-4051-b844-201b1395b768.png)
![image](https://user-images.githubusercontent.com/54589605/229610373-5b502678-b0f8-4708-bd7e-d910a2b9d58f.png)


[**IMPORTANT**]
> **Practice** all of the questions. Before starting the new topic. Do some **practice** questions and revise them again.

## Asymptotic Notations

> Start from **1hr 30mins**.























































