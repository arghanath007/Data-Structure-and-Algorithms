# Machine Learning

* Link -> https://unacademy.com/course/course-on-machine-learning/53AX3KFZ

## introduction-to-machine-learning (1)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/340c019c-efee-4571-8d3a-e33ff7365beb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0018ff2c-5297-4773-a52e-2d39dca8e48f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1b5be1c0-6952-4298-8d0c-93f8fc7aecd5)

* Machine Learning
* We will give some **input** to the **ML model** and we will get some **output**. The **output** will be based on the **previously trained model** and the **type of input** that is given to the **model**.
* We need to design a **model** and the model will be created based on different type of learnings. The model is created based on the analysis of the **data**.
* We have given **data** to the model and sometimes we send **output** with the **input** sometimes only the **input** is given to the model and the model is made to **predict** on the **input**.
* Finally the aim is to **design the model**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/61bd0336-5c20-4681-92c1-623f33e3a4ef)

* Types.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/384ec7b7-f061-47ab-9a55-a58c20c3bbca)

* Supervised and Unsupervised learning.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac54a626-befd-48fc-a2ef-ca1b191f543b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/831540dd-526d-4820-b506-8027cc263756)

* Application of ML.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee6702ae-09cf-436f-af17-2a08a33ec72b)

* Algo.
* Statistical -> Mathematics.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ce848092-ca6a-41d9-8790-ce884e6adf39)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b61aae7c-586e-4952-89d6-abd4a7f512fd)

* Model.
* It has **data collection -> Training -> Testing**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c1a4744-2498-4f98-9d8d-738bb562a4bb)

* The **variables** used to predict the **output** are called as **predictor variables**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/395eb206-497a-4042-a537-e2ae5a8b004e)

* The **parameters/variables** on which the **outputs** are based on are called as **response variables**.
* The **data** used while **training the model** is called as the **training data**.
* The **data** used for **testing the model** is called as the **testing data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c51627ad-58a1-4839-a9fa-a4ea8e650d2f)

* ML Process.

## Supervised Learning

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ef8ac95d-e7f4-4f17-9a6a-053363ffa2d5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5a1e4a47-5f5b-42df-8798-edd5235b14ec)

* **Labeled dataset** -> For all of the corresponding **inputs**, we have all of their corresponding **outputs** along with them. For the **specific input**, we have it's **specific output**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/07316df8-58a9-4317-add9-a39f73cc92c3)

* We have trained a model on the **labeled dataset**.
* We are applying a **new input** to the model which is the **testing dataset**. The model will give us the **ouputs** of the **testing dataset**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8c6bc4a7-3d1d-4674-bd2e-8f043d1ce328)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/da15be4d-4d3f-483d-b003-a4528c95b227)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed2d4921-3c6c-4f61-85f3-f647606738e7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fa9cc8d1-9a5c-4b0b-836d-48875879484d)

* Types of **Supervised learning**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b2792fd5-6ad2-4826-90b3-95cbfcfa6eb1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1b8d36fc-2ce6-43e5-a920-dbd09fff7fbe)

* Unsupervised learning.
* **Unlabeled data** -> We are not sending the corresponding **output** with the corresponding **input**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/946674e6-9179-4643-a9ac-eebb05fcba84)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f5f245b4-5cb1-4b6e-8244-4aea73deac20)

* **Supervised learning**.
* Learning algo.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d5c003e1-573b-49ee-b697-50ef4c5e7f67)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b107e36-c65f-4c71-81f9-21db4fdb9885)

* **Unsupervised learning**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/aaab6f14-765f-4d57-b196-f377a42aa9c8)

* **Unsupervised learning**. [Example]
* We will get **training data** on **supervised learning**.
* We will **not** get **training data** on **unsupervised learning**. We cannot separate the data. We just analyze the data and design a **cluster/group**.
* In **classification** the **output** will be **discreet**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3db053e7-145e-4845-8e9a-111c581cc977)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/021fc06b-3dae-4029-bf5a-868e55b96635)

* Supervised VS Unsupervised.
* Regression:-

1) Linear
2) Rigge
3) Lasso

* Classification:-

1) Logistic Regression
2) Naive Bayes
3) LDA (Linear discriminant analysis)

* Common algos between **Regression and Classification**:-

1) Random Forest
2) SVM (Suport Vector Machine)
3) KNN (K-nearest neighbor)
4) NN (Neural Network)

* Unsupervised:-

1) PCA (Principal component analysis)
2) K-means

## Reinforcement Learning

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6b01729e-f858-45d3-b7af-8a56fd397b9f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/846b5da3-b7dc-438d-862f-fed4d7b3c777)

* It provides **feedback** to the model. [**VERY IMPORTANT**] 
* In **Unsupervised learning** we are **not teaching** much to the **model**, it is **learning itself** only by doing **analysis**. It is using it's own **analysis** and it's own **brain** to do the **predictions**. [**VERY IMPORTANT**] 
* In **supervised learning** we are **teaching** most or everything to the **model** and it is **not learning itself**. It is not using it **brain**. It is using the things that it has **learned** via **training** on the **training data**. [**VERY IMPORTANT**]
* **Semi-supervised** learning it contains mixture/combination of both the **labeled and unlabeled** data.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8924f42d-f4e8-4db9-ab18-7a3bb5dfbc4a)

* Regression.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/43125abe-ebb5-4b55-8f1a-e44ef5a1c07e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4caf3fd1-6a2a-4702-832a-87f15d128d41)

* Option **A**. [Classification] [Question]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/51f9ac32-648e-4743-9640-fd9a23e44fff)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2419312a-a561-4e42-a433-aec689d7fc19)

* Option **C**. [Question]
* Same work is getting repeated again and again.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/819761af-efd7-49c1-aaf3-89ad9103d8d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3f7154fd-ba08-45cd-a5eb-855091e24636)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/49291adc-cf06-490f-929f-e97b4af867df)

* Option **A and B**. [Question]
* Unsupervised -> Clusters/Clustering.

## Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/00a19c4d-aeeb-4810-968a-3bcab2ae0f4f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/691a1cfd-6987-4d0f-abc5-a1b0ca17d360)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b5be30e1-8f6a-4307-bba0-9a458705f2b9)

* Relationship between two variables which are the **dependent and independent** varaibles.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3f616924-fe50-440d-a7d7-0b18b81c9b34)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/640f34af-4340-4eaf-b14e-2037cc33a739)

* **Dependent and Independent** varaibles.
* We are predicting the **salary** based on the **experience**. [Example]
* **Input** -> Experience -> Independent Variable/parameter.
* **Output** -> Salary -> Dependent varaible/parameter.
* **Dependent variable** will always be **one(1)** which is the **output/prediction**. [**IMPORTANT**]
* **Independent variable** can be **more than one(1)** which is the **input**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3e844ee4-6021-45d0-886f-79fc25615d18)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/19f0c29f-d6fa-43f5-8009-91e4b8991378)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7c259a31-0079-4421-a898-3a42b44abbfb)

* **Regression** Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2488b03-3cf0-455b-83c7-cb972f575d17)

* To show the **relationship** between the **Dependent and Independent** varaibles we use **regression**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9569521f-42b3-474c-921d-1934f7066b49)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1fd13514-9e6d-4d3d-ab28-5eaaa673510f)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f465194e-a7e8-463e-bd87-1410f891bce0)

* observations.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/53c53624-644c-4441-aedf-63db002cb9f5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e0bd8277-1bde-44cc-92be-05279f5a3a3c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c85ab828-4b47-47cc-bdb2-28303685908f)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1b0c116f-d5fb-438b-8901-452337904750)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c0a826e3-a81a-41a0-b2d9-f2e54a84223c)

* Why **regression**?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f206d761-9694-4997-8ac4-bb4af2712c35)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8a98ea5d-a297-4691-91a9-dbf56a0e7f58)

* Types of **Linear Regression**.

## Simple Linear Regression

* Next Class.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83418ee4-d93c-4b8d-b457-5e4445d8b73f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed064955-6dd7-4b71-81d9-1b80aff1ce48)

* **AI** Doubt.
* BFS -> Complete.
* DFS -> Not Complete.
* **No**, it will not be **complete**. [1]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8512de61-a48d-4483-9bfa-cf74874c9436)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8ec5d80f-00e0-48df-8bdb-b8bdd114c58b)

* 2.
* **Time and space complexity** same for **uniform cost search**.

## regression-classification (2)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/be76e787-942e-45f9-9463-655963be2703)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a8d83e19-dd22-4df6-8257-44e7081e183f)

* **Simple** linear regression -> **Independent and dependent** variables are exactly **one(1)** only.
* **Multiple** linear regression -> If **Independent** variables are **more than one(1)** and **dependent** variables are exactly **one(1)** only.

## Simple Linear Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7e193b10-727f-4582-bf78-9267a64e1833)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c371c79-a58d-47f8-8cbf-736916bf7ff3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/454adc58-8307-4cf9-9920-cf79f95abbc0)

* **Independent variable** is on the **X-axis**
* **Dependent variable** is on the **Y-axis**

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8cad00c1-3ff3-4cff-9c92-8e0f0da4f61a)

* Fitting line to the data.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5bd54dcd-be52-4b3c-ba0f-0db4a6e31266)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f3b1073b-2bd7-4d9b-98bd-4074549f0caf)

* Option **A**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1a0b8f4f-d9f9-4394-bdd9-b98b498dff8e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/42774cda-3f54-4331-a95e-20881670a18f)

* y -> Dependent variable
* x -> independent variable
* m -> slop of line (How much change in **y** for unit change in **x**0
* b -> intercept. (When **x** is zero(0) then what is the value of **y**?)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b793f72-135d-4c85-a90a-5c6a2481861e)

* **y** -> dependent.
* **x** -> independent.
* Types of Questions:- [**IMPORTANT**]

1) Find **m and b** value.
2) Graphs are given in the options and we have to find the correct graph for the given data in the tables.
3) Design the equation. Equations will be given in the options.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/436c116b-14b2-4dbc-8e81-dc979f3a7e8a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cffb96bd-3da8-41dd-8be1-f1c88ee2964e)

* The main aim of **simple linear equation** is that the line should be the **best fit** line. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9314af66-145a-42ba-89c6-a0ec5b3cce48)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/779f8b5d-4703-4917-ad76-0695bbc60779)

* What would be the value of **y** for **x = 1.5**? [x = 1.5 -> Testing data]
* The **main role** is that we have to make the **line** in such a way that **min. no. of errors** come. **Errors** will come but we want to **minimize the errors**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/841ef30c-3a65-4705-b79c-6fb6741942ee)

* **Actual value and predictor** are to be identified here. What is the **difference** we are getting.
* y' -> Predictor
* y -> actual

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/429f0a85-852c-4ee5-8f02-fe04a792f704)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/48656ff8-d4c7-40c4-85b5-4c1297dd7c93)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6045a03c-c1bf-49a4-8138-a7f92a9f47cd)

* Hypothesis.
* **y** is a **linear function** of **x**.
* **ho(x)** is a **linear equation** of **x**.
* Find the ** slope(m) and intercept(b) value.
* **Mean** means the **product of 'x' and 'y'** and their **sum**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/85b660c4-07e5-46ce-aa47-e02648ecd438)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c47b42bb-14b0-4795-8adf-9acc86bbe5c7)

* Value of **x and y** column are given in the quetion.
* We are finding the **summation of 'x' and 'y'** and also we are finding the **summation of (x ^ 2)** and we are finding the **product of (x * Y)**. [**IMPORTANT**]
* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e7b5e6a1-9b81-4bc1-a57b-dfb1ddbdbae9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/81324504-999f-4a63-8c5b-5c453071f17d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ce5687a8-2461-4b37-8688-3c2e10ce43d7)

* Formula [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e8dc5064-e1e6-4544-b93b-bc45e6435a74)

* x' -> mean of **x**.
* y' -> mean of **y**.
* (x ^ 2)' -> mean of **(x ^ 2)**.
* (x * y)' -> mean of **x * y**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c27b25b5-1eaa-45f8-a5b1-2e85fb2436dc)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/55984f5c-5557-4682-85e7-88630ed36a13)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3042af6d-65ce-4394-b1de-b805db61a98e)

* Solution. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/baed0669-3192-486c-94b5-c3b43a22d2d6)

* For some value of **x**, what will be the value of **y**? [Expected question]

> **x = 30**, so the value of **y** is **43**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c370a9aa-fa8e-4702-b829-cea9d6554cc3)

* y = (1.5 * x) - 2 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47165e5a-1c2b-4ad9-8709-c848320dc029)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83ee2628-f586-49f0-ad7f-51bef84b2a11)

* **Graph** for the **above question**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d578ab25-a1f2-4451-92b2-41185962a2cc)

* Question
* Find slop.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ee7297f-572b-4ad9-8758-46b8a0929206)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/839237f4-f96f-4f80-947a-fb873f38850d)

* **y** is intersecting at **40**. we can see it from the point of **(0, 40)**. From these only we can say that the value of **b** will be **40** only. [**VERY IMPORTANT**]
* According to **intercept** concept, if **x= 0** then **y = b** which means that **b = 40**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8fa54a96-05e1-4dd1-81b0-211fde2ac23a)

* Solution. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/71fc4c2b-13be-45bb-be91-e01bedbdab9c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2234fbf4-1d57-4c30-aa05-9d1d70bd8c8a)

* n -> No. of test data [Formula] [**VERY IMPORTANT**]
* m -> Slope data. Equation of slope.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47b88d9a-1bc6-45cc-b7b3-fc4d87df3773)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b6400f8-9a61-4079-9684-799fcc6cb168)

* Question [**VERY IMPORTANT**]
* n -> No. of elements -> 8.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/80a02742-dfe5-4a22-a0fe-8d304fd967fc)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/65920570-bc55-45f7-9ac2-1d8254858ca4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cf850b45-1274-48b2-bbae-e9339a840d98)

* Option **C**  [**VERY IMPORTANT**].

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7425fe9c-b239-4b92-853c-a25033b9b774)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/945ea577-b2db-487b-a3c6-d5faee568964)

* slope(m).
* We are calculating **directly**.
* This **example** will prove that we will get the **wrong answer/equation**.
* For the above reason we have to use the **formulas**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/75c1e29c-56be-47bd-ab64-8aef1f7e6da6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6d3d3f19-3090-4a1f-8463-aaabb8108a7e)

* We can clearly see that **b** is **-15**.
* We got the **mx + b** equation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4152ccfa-ba24-435e-96cb-3ea673e03945)

* When we put the value of the **equation** we will get an **error**.
* We got the **equation** directly.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1fa94f9b-70aa-49f2-b4bb-50dd3854a145)

* This is the **equation** when we use the **formula**. [**IMPORTANT**]
* We use the **list square regression technique**.
* Use the **mean** formula.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a23b2ae4-5f88-46fe-aeca-8fd6f2d4c793)

* Formulas [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/90c31882-96c6-478d-aa20-b1565bded5a1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5af60a94-6135-4aac-97e2-040236a46dc3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1a2a283a-f263-4411-b66c-c0e41e71f00e)

* x -> independent variable
* y -> dependent variable
* Find the **mean square error(MSE)**?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/153c08d8-fe22-41d2-9655-aeae6c4e3507)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9d4ba194-e4d4-48d2-b7e4-6a83a2a1dc47)

* Estimated, **y'**.
* Actual, **y**.
* To calculate the **error** = y - y'.
* Never take **difference** in **negative**. We have to take **positive difference** only. So we will square the error which is **(y - y') ^ 2**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/474e669f-cbb6-42b2-87ae-1cdc97343375)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/36865b92-9108-43b1-a930-d534fbb280d7)

* **n** is the no. of datasets.
* Estimated, **y'**.
* Actual, **y**.
* **Mean square error(MSE)** -> (1/n) * (Summation of ((y - y') ^ 2)) [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/329f956a-76ad-4eb0-8b4c-0c751692245c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/71d10480-d8b5-46ff-aa22-3201b338bfd0)

* Solution [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/427d5189-ec75-4418-9bac-4e3f43e17fe1)

* The **min.** is the **Mean square error(MSE)** value the better it is. It tells how much **accurate** our predictions/output are.
* The **min. MSE** means the **better or more efficient** is the **solution**.
* **MSE** should never be **zero(0)** which means that the **predictions/outputs** are **100%** correct. If it is so then the model is doing **overfitting** which is a **problem** of **linear regression**.

## regression-classification-part-ii (3)

* The **error** calculated should be **minimum**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a762b641-720e-4f79-9e63-53b122330d44)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e2d98bb0-fa9e-4bf1-8d0d-1ac75dfe0bff)

* Cost function. [**IMPORTANT**]
* Theta0 = b
* Theta1 = m
* They are just representation. Someplaces **b** is written someplaces **theta0** is written.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a67e6676-447d-4b0d-9645-63dc787c91f6)

* We are checking if it is the **best fit line**. All of the **data points** coming in the future in this **problem** will give the **best error** or not.
* For every new **data point** plotted in te graph we will calculate the **error/difference** of the point and see if it is the **best fit line** or not.
* We are doing the **above calculation** using the **cost function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/beb53feb-42ca-41bb-b1b0-474479399a1b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/79c93dfb-1e17-41c8-929b-b89325ca94c6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1f909fc6-74cb-44b0-90db-761e99153810)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b409fa6-603e-4e08-bf0b-cca462d45b3d)

* Cost Function.
* We are trying to find the **exact** of **Theta0 and theta1** or **slope(m) and intercept(b)**. which will be the **best slope(m) and intercept(b)** so that we get the **best fit line** which we can **calculate**. For that we are using the **cost function**.

* x1 = 1, x2 = 2
* y1 = 1, y2= 2 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bafa5bb7-879c-4632-b293-8e70e3f99bd0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/85d18793-2547-41c9-a48f-f6ab71121b8f)

* When **theta1** is **1** then **theta0** is **0**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4669a89d-da48-4b6f-9c23-04e9faddb2c2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/68dbc709-61a1-4979-b23c-eb1f538bd2f0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1cbdf740-6e2e-44b4-82ff-8c57e02317d4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e82f0e0b-9c3e-4d77-813b-4d240969584c)

* Slope.
* The point is called as the **global minima**.
* Till we find the **global minima** we will continue **finding it**.
* The value of **Q1** at **global minima** that will be the **best value** and the line created from it will be the **best line**.
* The **graph** is called as **gradient descent**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/04ea6cd9-0610-444c-a15f-701c91455da8)

* Goal is to **minimize the cost function**. Till it is **reduced** we have to continue doing it.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09c9e696-1a28-4223-a81e-7f606e7479a5)

* What is the meaning of **gradient descent** and why we are using it? [Potential Questions] [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cc63e5ab-032b-4a2b-b00b-dbfed3e5be2b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e24637c0-236a-4f03-89fb-b9404251145a)

* Cost function [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/476328b9-d65b-4b65-8808-b694f303a821)

* Alpha -> Learning rate or hyperparameter.
* Best learning rate(alpha) is **0.01**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05ebdba2-9791-482b-9162-0979de0f4a98)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3aa5f9a6-aee1-4497-b567-3f9dd012ea0f)

* **Learning rate** is saying at what rate the **value of alpha** is going down.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4d7d2474-ce64-492b-a682-45ea69cb2252)

* MSE [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6ca60f42-151e-4468-9cef-f638a77c13af)

* Because of the **Squaring** the units can change for that reason we can use **absolute mean error**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ef0fac58-80dd-4278-b2d8-f398d7d0a650)

* Absolute Mean Error(AME) -> (1/n) * (summation of (mod(y' - y))). [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c7c23316-8e42-4e96-8c78-eb5925f87df6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/58f281ca-14ef-438a-8011-b9640b03d2ad)

* Root Mean Square Error(RMSE) -> sqrt(MSE). [Formula] [**VERY IMPORTANT**]
* Which **error** will be used will be **mentioned in the question**, if it is not mentioned in the question then use the **MSE** to calculate the **error**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3021a075-3a48-433e-9680-dc2d806bb1d8)

* Find the **Mean Squared error**? [Question]
* y -> Actual
* predicted -> f(x) or y'

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/98fc2e01-c711-4c8a-9017-791666ea2ad4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/913a8d44-1a75-4892-9d5c-5ef6271975f2)

* Solution [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56137110-2664-4ee8-8f3d-092b8f97b674)

* Absolute error would have given the **same error** value as well.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8f59959b-92e7-4f9a-907b-230e03ef0dc1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a07a939d-4cb0-40d6-b429-255314476c47)

* **(8, 45)** is an **outlier**.
* From the **testing data/values**, the **data points** that are **moving very differently** those are called as **outliers**.
* It is creating a **large difference** and hence creating a **large error** from the **best fit line**. [**IMPORTANT**]
* They are out of the **normal pattern of the data points**.
* **Linear regression** suffers from **outliers**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5dd1b0cf-3ef1-4df2-bdb6-638a678e6eeb)

* Multiple Linear Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/101f3163-c937-4cee-89c0-34236f98c26c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/35ae8243-f42a-4d6d-8416-fa0307d79707)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/416cf9e6-9bea-4577-a83f-076d127875c8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09277a14-837a-49d8-9615-ed784dc8f9af)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/570119bc-3ad3-449c-b12c-28550b4f1c92)

* **x1, x2 and x3** are three **independent variables** and **y** is the **dependent variable**.
* **Q0** is the **intercept**.
* **Q1, Q2 and Q3** are the **co-efficients** of **x**.
* **x** terms are always **independent variables** and the **y** terms are the **dependent variable**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/329ab8cb-c8e4-496a-a0bf-415bb16f6417)

* What is the equation?
* What will be the equation?
* Formula?
* Equation? [Expected Questions]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/34bdcff8-a040-4e55-bd40-b7cd684077bf)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/adb0dd5a-45ca-4596-82ac-09eb03827914)

* We always put **1** in the **1st column**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/18c58577-e755-48d8-853b-ba9f8acd32d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/69e65b2a-eaf6-46e7-837d-d70007ad4fa7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0c6b96a5-3f49-4b86-949c-bd1d38fd5fc9)

* We have to find both **co-efficient(slope) and intercept**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d513771a-31cc-4047-9b5b-17370b4a45d0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0abc80cb-bdcd-45d7-a868-aa21f1b8bbb2)

* Multiple linear regression. [Formula] [**VERY IMPORTANT**] [Theory type Questions]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/84414a60-665c-40be-ae57-df84f9f16fc2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/981a049c-c454-4652-8f48-a9bb9b2217ba)

* Underfit and Overfit. [**IMPORTANT**]
* Variance and bias. [**IMPORTANT**]
* **Underfit** -> In both the **training and the test** datasets it is not giving the **best results/outputs**. [**IMPORTANT**]
* **Overfit** -> The model has **trained** very well or too well on the **training set** but it is not able to perform **better** on the **test dataset**. [**IMPORTANT**]
* The **model** should never be either **underfit** or **overfit**. [**IMPORTANT**]
* **Good fit/Robust** -> The **datapoints** should be **near** the **line**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/93023bbc-f8ce-481b-ab2f-60f122839ed2)

* [**VERY IMPORTANT**] [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e6b7dbe4-868f-4164-a791-f429a4e65fac)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/36caa95a-afc7-4285-8732-cf1e9a57ac08)

* Overfitting [Example]
* The model is just **remembering** the **training dataset** instead of **learning** from the **training dataset**. [Example]
* The model has trained too well on the **training dataset** but it is not able to perform on the **test dataset**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee8af129-b195-4abf-b69d-d7f89064e916)

* In **Overfitting** we will get the problem of **high variance** which means that the model is failing on the **test dataset**. [**IMPORTANT**]
* In **Overfitting**, the **bias** will be **low bias**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7687aece-bbab-4955-9afa-b60e157df7ae)

* Underfitting [Example]
* The model is either performing on the **training or the test** dataset. [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8d56317d-dc31-4e0e-84ab-3f3b4cd5af46)

* In **Underfitting** we will get the problem of **high bias** which means that the model is failing on the **training  dataset**. [**IMPORTANT**]
* In **Underfitting**, the **variance** will be **high variance** most probably because as it is failing on the **training  dataset**, the model will definitely fail on the **test dataset** as well. [**IMPORTANT**]

### Bias

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7f8075f7-c97b-46ca-9b38-3ec50502d0e1)

* We will use the **bias** word when we are talking about **training dataset**. [**VERY IMPORTANT**]

### Variance 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fba6839b-34cb-4c20-a995-4c0518736a62)

* We will use the **variance** word when we are talking about **testing dataset**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4cf506ab-72bb-46fb-ab12-99d6ae543f37)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09ac86d8-7eb9-4ec9-a6a3-446782205280)

* Bias and Variance. [Overfit and Underfit] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05e9710d-db5e-44f8-9eab-ef8ed716d1b7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0ac8a61d-e05a-4865-87dc-835b8eb3eff9)

* For the **Good Ft/Robust** we will have **low bias** and it also has **low variance** as well. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a0bb6a8c-42fc-4513-aaa1-4f81ff96a027)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/45fe1e48-59dd-4d83-97a3-d23843132a71)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac4fdeaf-8077-4c8f-92a7-c08f93da045c)

* Option **D**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5e3ac8b3-b756-4d19-90e9-b9140ab55c22)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5f370763-b147-4ba3-b0b1-135724c4c8bb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47dae788-f46f-4ab9-9f05-8a9851380200)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/505f7b98-fe2b-4320-b2af-57b299aae1d8)

* Option **B**.
* Depends on the **slope(a)**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dca222c7-2f64-4fe2-977a-99ebe9a7c2cd)

* Question
* The model is doing **Underfitting**.
* **Higher number** means **better results**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b0f33fcf-6bf7-4dc5-be6f-6ab5d5cb86a2)

* Question
* The model is doing **Overfitting**. [**IMPORTANT**]
* It is because we are getting **more accuracy** in the **training dataset** and we are getting **significantly less accuracy** in the **test dataset** which is the sign of **Overfitting**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3657eeb2-9741-4eae-8c64-851fdd288a6e)

* Question
* The model is doing **underfitting**. [**IMPORTANT**]
* It is beacuse the **training and the test** error percentages are too **high** for the model to be any usuable.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b143343e-689e-4a5d-ae92-976bdae9af7e)

* Question
* The model is doing **Good fit/robust**. [**IMPORTANT**]
* It is beacuse the **training and the test** error percentage are almost identical which is **less than 1%** difference in between them and the percentage of error overall is less than **5%** which is very impressive.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ff74fb2e-2198-4ba3-9eb2-90aade355be6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4e96a253-068f-421b-ad5a-6f73256d5098)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b2418635-bcd0-42f8-a171-25fe28c83430)

* Example. [**VERY IMPORTANT**]
* As there are based on **error %** so we choose the **lower number** being **better**. [**IMPORTANT**]
* If they were given based on **accuracy %** then we choose the **hgher number** being **better**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f1eab0cf-89db-4b60-aa8b-2537366fd655)

* Example.

## regression-classification-part-iii (4)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2878900e-f064-4639-821c-399ec1c38140)

* In **underfitting** we focus on **high bias** more than the **high variance**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fe5936d4-5899-4c5d-b727-e619a22eb5af)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/82e0c812-bda6-4323-80fc-8026c10ef3b5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/43da1641-b94e-4119-b924-267445629543)

* Outlier [Examples]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1ca70cb9-e3e8-44e7-af58-7a29a08ccc8b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/18f1b2eb-e837-43fc-92c2-d1f51e587141)

* Multicollinearity.
* The more no. of **features or variables** there in the **data points**, the **accuracy** of the model will be **less only**. If the **complexity** of the model is **high** then the **model accuracy** will be **low/less only**.
* If the **complexity** of the model is **less/low/simpler model** then the **model accuracy** will be **high/higher only**.
* If we **reduce** the **features or variables** then the **model accuracy** will be **high/higher only**.
* The **less** is the no. of **features or variables** then better is the **model accuracy** only.
* We can detect the **duplcate features** and **delete them**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d38f67ec-98a5-435c-b737-de3e3cd1c721)

* Co-related features. [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bc82f6c3-fce3-48f8-829c-491b3b78ea14)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1de2809c-a7fb-401f-a032-3f361fbe09fd)

* Correlaton Coefficient.
* Pearson's Correlaton Coefficient [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bca884eb-956a-4926-8b59-0846eb5262ca)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/30213b02-26ab-4325-acd6-6403ed3cec46)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/32bb553b-86ef-464e-a5d4-e845e060c467)

* Correlation. [**VERY IMPORTANT**]
* The model wants to see out of all the **features** which **features are correlated**.
* The model can easily identify the **highly correlation** features.
* To find the **correlation** values then we have to use a **formula** for that.
* **0.6** closes to **1** so it is **highly positive correlated**.
* **0.4** closes to **0** so it is **highly negative correlated**.
* **0.5** will be considered in **low positive correlated**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e6398c7d-13b0-4c8e-8d59-557f2f698bf3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d39d9c82-0443-4ed2-af76-e511e3543850)

*  Pearson's Coefficient Correlaton(r) -> This **formula** is used to find the **correlation** values** we studied **above** [Formula] [**VERY IMPORTANT**]
*  **n** is the **no. of data/values**.
*  To calculate the **Pearson's Coefficient Correlaton(r)**, use the **above formula** than the **below formula**. Below one is **time consuming**. Still **Learn both**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c37d57d4-c30e-40c9-9484-2667f272556a)

* Cov -> Covarience [Formula] [**VERY IMPORTANT**]
* Var -> Variance.
* **n** is the no. of elements/data/dataset.
*  Correlaton Coefficient(r)
*  Standard Division(Sigma) from **maths**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/50c79e2f-02f3-4826-aa8a-1398d3b054f1)

* Question [**VERY IMPORTANT**] [MSQ]
* We have to use the **above formula** which is **Pearson's Coefficient Correlaton(r)** for this **question**. [**IMPORTANT**]
* We have to apply the **formula two times**, so it will be **time consuming**. So trying to do with the **graphs**. [**IMPORTANT**]
* If exact value was asked then we had to **compulsorily** apply the **formula** and find the **values**. [**IMPORTANT**]
* As **exact value** is not asked in the question, so we can use **graphs** and try to find out the **answers** of the question. [**IMPORTANT**]
* The **correlation** between **X and Y** is **0.9** which is **high positive correlation**.
* The **correlation** between **X and Z** is **-0.5** which is **low negative correlation**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b7869f7f-7a10-43e1-965c-83d17baeaf54)

* **X-Y** correlation.
* The **graph** clearly shows that it is a **high positive correlation**.
* Option **A** [Correct]
* When we are making between **X-Z**, in the **Z** column the values are **decreasing** as we go down the **'Z' column**. The values are **decreasing** so it is **negative**.
* So we will look at option **C and D**.
* Option **C** is **incorrect** as we already know that **Z** is **decreasing** which means it is **negative** and not **positive**. So,

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e9ae74fb-f2d8-43e6-a550-1946133958a3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7338a4b-5cdb-4b8b-80eb-9c92328dd587)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/817977f9-c829-4fdd-b369-43f4e006ccc2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7af236c-5e04-4648-8a81-499a24196113)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c3e53e43-8060-44b3-a8b5-f9c84ddd9b4d)

* Option **D** [Correct]
* Option **A and D** [Answer] [**VERY IMPORTANT**] [Practice it again]

## Regularization

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f6c91ee6-7cd5-4d0f-8897-758ed357b0b2)

* **Regularization** is a technique which is used to **overcome** the problem of **overfitting** and **feature selecton**. [**VERY IMPORTANT**]
* **Feature selecton** indirectly reduces **underfitting**. [**VERY IMPORTANT**]
* **Feature selecton** is removing **redundant features**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a0d398d2-8c88-4e30-86b5-116bb9e55c56)

* **Lasso** regularization is also called as **L1 regularization**. [**VERY IMPORTANT**]
* **Ridge** regularization is also called as **L2 regularization**. [**VERY IMPORTANT**]
* **Elastic Net Regularization** is also called as **L1 and L2 regularization**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/96bf3669-8b0c-45d5-9878-eb2deabde735)

* Outlier [Example]

## Lasso Regularization(L1)

* Lasso -> Least Absolute Shrinkage and Selection Operator.
* slop(m)
* n -> No. of datapoints/values/data.
* m -> No. of features(independent variables).
* Lambda -> Hyperparameter.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2729e918-5592-4b04-92d4-62993c2e18d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7fa1140e-841f-4f82-8fe3-21b89eb575b5)

* **Lasso** is used for **regularization and feature selection**. [Formula] [**VERY IMPORTANT**]
* The **formula** is the **addition of slope**.

## Ridge Regression(L2)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/46758f03-5133-4c31-8616-ae5a6e6020ad)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b3e2c954-629e-47a2-8c1e-21b6a02073fc)

* In this we add squared magnitude of the **feature/independent variable co-efficient** in the **cost function**.
* Cost Function -> ((1/(2 * n)) + lambda * (summation of (ai) ^ 2))
* The **formula** is the **multiplication of slope**. [Formula] [**VERY IMPORTANT**]
* With the **Ridge Regression** the problem of **overfitting** wll be **reduced**. [Formula] [**VERY IMPORTANT**]

## Elastic Net Regularization (L1 and L2)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/68a209ad-4b72-4530-8e45-16ab0928f25f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/196aa556-e3ad-4287-9b4a-d279d7232dff)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a198f8e8-7c72-428d-b92b-2699c5972060)

* Cost Function [Formula] [**VERY IMPORTANT**]
* Helps in reducing **overfitting** and also helps in **feature selection**. [**IMPORTANT**]

## Logistic Regression(Classification)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/651ea12e-8b97-4fd9-82a7-ff0c57b2da0e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4d78254b-3c30-4545-b51c-62545fbcb1f7)

* It is a **classification** algorithm.
* It will be like **boolean values** either **True or False** or **Yes or No**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1da91099-8b01-4c73-adb8-076c3fd3dfef)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/02a69560-78a5-4914-ae71-3f10b7d96f65)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/88570037-0d4c-41f1-8647-4ff7d5fe5444)

* Types.
* Classification means **class**. We have to find how many **classes** are there. How many different **class** are there or are made.
* Binary -> Two classes -> **True or False** or **Yes or No**.
* Binary -> Two classes -> Pass Or Fail.
* **Output** is **fixed** either it is **Pass Or Fail**.
* **Logistic Regression** works/based on **probability**. It cannot go out of the range of **probability**.
* We cannot use **linear regression** on a **classification** problem. The range cannot go beyong the **linear**. [**IMPORTANT**]
* In **probability** the **max** value is **1** and **min** value is **0**. The **output** should lie between **0 and 1**. It shouldn't go beyond that.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b2899b6-ce94-4dc4-bb92-4e443723b37a)

* Example

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d9ee3614-ab6e-45da-bbc7-4a217db0dd39)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4fb3fa28-3e9b-45b4-9e24-a7e61e1e2501)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/31e474be-65cb-4a38-88d8-9c69c211655e)

* Using **sigmoid** function we implement the **logistic regression**.
* **Binary,ternary** these type of **classifications** use **logistic regression**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed26c44a-b84d-4b7e-9fa3-0d3ab62271f4)

* Sigmoid function or logistic function.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c7761e9-2c51-4dbb-b62d-a52932a7742a)

* Sigmoid function [Formula] [**VERY IMPORTANT**]
* With the help of the **Sigmoid function** the output is between **0 and 1** only.
* We are making **probabilistic model** for that we need **Sigmoid function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8ffa21d7-3f62-4ade-a567-542232e8963e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8c405def-2c86-4c59-8479-0c62479dd38a)

* **y** -> Dependent variable.
* **x** -> independent variable.
* Theta0 -> Intercept.
* Theta1 -> Slop.
* **Theta0 and Theta1** value will already be mentioned in the **question**.
* Logistic Regression [Formula] [**VERY IMPORTANT**]
* **Logistic Regression** will tell either **one of the classes**, it will never go out of the **classes**. [**IMPORTANT**]
* **Linear regression** can throw us outside of the **class** as well.  [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7fbae368-04f5-4865-86d6-d8a46b27e1f1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b459f87-7424-4148-af03-f0b28920afc8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/043f5956-fd3a-4e42-a711-a977b8c358f5)

* Example.
* The name is **logistic regression** but it is working for **classification** problems. [**IMPORTANT**]
* To solve **classification** problems we cannot use **linear regression** algo. It is never possible. We have to use **logistic regression**. [**IMPORTANT**]
* The **sigmoid** function value is always between **0 and 1**. [**IMPORTANT**]
* The **outlier** problem will be fixed/removed using **sigmoid** function. [**IMPORTANT**]

## regression-classification-part-iv (5)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f05fd552-6db3-4f36-a5d5-a28b6a8ab522)

* Formula.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/abe81402-e169-431c-af97-9053ac45c8d1)

* What is the probability of pass for the student who studied for **33hrs**?

> It is obviously **one(1)**/

* Study hours(x) is the **independent variable**.
* **Pass/Fail(y) is the **dependent variable**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/96052f17-d60f-4208-b928-18a5f3043b05)

* Solution [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cc8f006a-986d-4dfd-a6c0-b77663cfc2b8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6361664e-e759-4d23-b8db-e0520d6f3810)

* The probability of chance that the **student** will pass with **33hrs** is **0.88 or 88%**.
* Answer -> 0.8 or 88%,

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0fa4e6ba-b441-4a11-9550-267937baa442)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5ae30908-ea9c-4b36-b36c-69a0d2af13e7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/28dd21eb-d473-43c5-86a9-446e862afacc)

* Solution [**VERY IMPORTANT**]
* hours -> 33.47hrs.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1ba696f5-d5d9-4fc7-b86c-0e40dd1300f5)

* Logistic Regression [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4f04d136-16c0-466c-9aa4-28985162a99f)

* Cost Functon of Logistic Regression [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/749781ae-26dd-4c93-9581-a678760a2331)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6d0321ba-31bf-4ca7-a079-6792f117585b)

* We will not get **global minimas** we will get a lot of **local minimas**.
* The reason we don't use the **above formula** which is the **cost function of linear regression** because we get **multiple local minima**.
* To remove the **above problem** we use the **Cost Functon of Logistic Regression** formula.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6c3bbdc-e17c-4b7d-b915-80f42cc49037)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fdd56780-4b15-4628-bfc9-98331d9a961e)

* ln [Example] [**IMPORTANT**]

## KNN

* K-nearest neighbour.
* It is both a **classification and regression** algo.

### KNN classification

* classification -> classes.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4b63db97-42f3-401c-a32f-da94a0d31505)

* **x1 and x2** are the **features**.
* dot(.) -> Class 1
* plus(+) -> Class 0.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ed30cde-9f74-41c5-945a-b69aa5f0b0fd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb700c2f-d2a2-40f6-be3e-99ca94fd12c8)

* **New data** has been given and we have to find out with the help of the **data** what will be the **class** of the **new data? We have to identfy it. It is not given. [**VERY IMPORTANT**]

> Let say we have **k = 4** neighbors which means around the **new data** it will take the **4 nearest neighbors** from it. It will identify the **classes** of the **4 nearest neighbors**. Let's say that the **1st neighbor class is '0'** then the **2nd neighbor class is '1'** then the **3rd neighbor class is '1'** then the **4th neighbor class is '1'**. The **class** which is **coming come in-terms of count** then we will just consider that partcular **class** as the **class** of the **New data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/12dcc7ec-ad10-4a74-a675-e80081da1102)

* To calculate the **distance** we will use the **Eucledian distance**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/33c695b5-cc59-4541-a556-a2072aa036e9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/477accc2-2d42-43ed-b7e3-988bb72a48ac)

* **Eucledian distance** [Formula] [**VERY IMPORTANT**]
* **Distance** between **P and Q**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/46bf35bf-8cc9-445f-97ff-0ada62208c40)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1cbfab33-d238-4ba1-82c2-c94206243c49)

* As **K = 3** so the **3 nearest neighbors** are **2.5, 3.04 and 1.11** and their **class** are **0, 0 and 1**. So the **class** of the **new data** is **class 0**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cbb574d-b747-4a99-b75e-a513fb3e96ca)

* Answer -> Class **0**. [**IMPORTANT**]

### KNN regression

*  In which we 1st find the **K-nearest neighbor** and then find the **average** of their **output feature/parameter**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f419daa8-d4b9-46ea-af11-29781eadcea1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/10bbe3b5-ae69-4fba-83d1-be76e9f78813)

* We have to find the **average** in **regression**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fed23a5c-9c52-47c6-adf6-22afecca7ee3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/13639a84-ab14-4324-b11c-152b0b64baca)

* Example.
* **Distance** can be **same** because the distance can be mentioned equi-distant from each other.

## Performance Matrix

* Normally used in **classification**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0edf0b8d-2414-4ea7-b504-5141b60fdaa1)

1) Confusion Matrix -> We will calculate **accuracy, precision**.

* 1 -> Yes
* 0 -> No.
* We are counting how many times we have actually gotten **Actual '1' and predicted '1'** as well. **3** times.
* We are counting how many times we have actually gotten **Actual '0' and predicted '1'** as well. **2** times.
* We are counting how many times we have actually gotten **Actual '1' and predicted '0'** as well. **1** time.
* We are counting how many times we have actually gotten **Actual '0' and predicted '0'** as well. **1** time.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3ffe248a-3949-47c7-be92-5a00926c1d21)

* The **Actual '1' and predicted '1'** and the **Actual '0' and predicted '0'** are the **cases** where we should get exactly **correct** answers which means whatever **class** was there and the model was able to **predict** that class.
* Correct Prediction -> 3 + 1 -> 4
* Total Cases -> 3 + 2 + 1 + 1 -> 7.
* Accuracy -> Correct Prediction / Total Cases -> 4/7 -> 0.57 -> 57% [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c71b09c-e4f9-41b7-a1f2-875afb26cf70)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b7a3fbc-be26-4688-9644-15ea310a7310)

* Calculated the **accuracy** parameter. [Example]
* Only with the **accuracy** parameter we cannot analyze any **model**. Maybe some data is **wrong**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/de58966d-2697-40e7-a6cd-81f26fc327eb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/691660b1-5073-4171-bf87-b5ee76948c77)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b980e907-06d9-4ec7-ae34-ba4b83e3d38a)

* **Point 2 and 3** are the **predictions** which we want.
* We will try to reduce the **false positive(FP)** where the mail is **not a spam** but the model predicts it as a **spam emal**. [We will try to reduce these case]

* Spam = 1 -> Positive
* Not Spam = 0 -> Negative.
* TP -> True Positive
* FP -> false positive
* FN -> false Negative
* TN -> True Negative

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/39167ad1-5268-4f67-b317-10cca20d167a)

* We want to reduce the **cases** where the mail is **not a spam** but the model predicts it as a **spam emal** which is called as **false positive(FP)**.
* We want the **false positive(FP)** to be at the **minimum**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/72e3d3ef-7c5f-4ef8-8c90-a52243ab0141)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9359d9b0-9410-4b07-a49e-3463f1ad36c5)

1) **Precision** -> TP/(TP + FP) [Formula] [**VERY IMPORTANT**]
2) **Recall** -> TP/(TP + FN) [Formula] [**VERY IMPORTANT**]

* We have to focus on which value has to be the **minimum**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/03d22345-778a-49fd-9668-fc3333c0f9e5)

* Example.
* In the **medical field** there should be **no False negatives(FN)**.  [**IMPORTANT**]
* It will vary from **one field/area**.
* In someplaces **FN** would be more important and in someplaces **FP** would be more important. [**IMPORTANT**]
* Maybe in some fields both the **FN and FP** are  more important.  [**IMPORTANT**]

### F-Beta Score

* We want to focus on both the **FN and FP** as they are more important in a **particular field/area**. [Both of them should be **minimum**]
* In that case we will use **F-Beta Score**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/28688c72-2047-4359-962e-779f2d804042)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/141a5554-bcec-47e8-b241-cdc498d9050d)

1) If both the **FN and FP** are **more important** then **Beta = 1**:-

* F-Beta Score = (2 * (Precision * Recall))/(Precision + Recall) [Formula] [**VERY IMPORTANT**]

2) If **FP** is more important than **FN** then **Beta = 0.5**:-

* F-Beta Score = ((1 + (0.5) ^ 2) * (Precision * Recall))/(0.5 ^ 2) * (Precision + Recall) [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/55895ded-e3a3-4f73-a46f-7b87413523d7)

3) If **FN** is more important than **FP** then **Beta = 2**:-

* F-Beta Score = ((1 + 2 ^ 2) * (Precision * Recall))/(2 ^ 2) * (Precision + Recall) [Formula] [**VERY IMPORTANT**]

* We are trying to **minimize** the problems.
* **TP and TN** are the **good** cases.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/62c0324f-acf0-4ec5-b198-3060fac701e1)

* Actual
* Predicted. [**IMPORTANT**]

## Naive Bayes Classifier

* It is on **classification** problems.
* x1, x2, x3 -> Independent variables/event
* y -> dependent variables/event.
* c1, c2 -> Different classes.
* **Event** because we have **probability**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/52ed0cfa-5ef6-4be0-a374-6fe9219cda03)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/376d3a63-84d9-4d1c-af2e-7a860f27f5ab)

* Next class.

## cross-validation-part-1 (6)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d659948d-9c0f-4f13-83d0-8a006c9b4ef2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/475ce4ad-353a-4ee6-b010-f70901c29fe9)

* Classification Algo
* Category -> Class.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f69dbb4f-7cc3-4178-86dc-23cec817e191)

* Applications.

## Naive Bayes Classification

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/70e11ddd-f3cf-4204-8819-9043238ddeff)

* Naive Bayes Classification
* It works on **probability** of an object.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5b000ee6-576c-4c57-a140-7c90d0806b82)

* Why?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d7f5c6ea-f5d2-4521-babe-cc1917d85c09)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5e30d5e5-33b2-49f1-a41e-9c07847311be)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2577b6f4-dd57-4614-9989-ba06c2f7712f)

* Bayes Theorem Probability. [Formula] [**VERY IMPORTANT**]
* P(A|B) -> Probability of **A** given **B**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0bc66590-5740-47fa-862e-8136bd5f5bd3)

* Working.
* **x1, x2 and x3** are **independent variables/events**.
* **y** is the **dependent variables/events**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/00532104-29c2-4dda-95fe-b2a1911fd1db)

* The **output** is classified either it will go to the **Yes** class or the **No** clas. There are **two** different classes.
* No. of Class -> 2 (Yes, No)
* No. of feature -> 3 (x1, x2, x3)
* Datapoints are now **4**.
* No. of value of each feature -> 2

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac3e32d9-630d-4fc4-a0db-c6ac1e5c9943)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/346338e0-2b69-48b0-b59d-f315d3535094)

* The **no. of classes** we have that many we have to **calculate**.
* VDK + K
* V -> Samples
* D -> Value of that Feature.
* K -> Class

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bcce578e-bbf1-4b35-9318-d462f2b19166)

* Total cases -> 12 + 2 -> 14.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ab1b2915-bd24-4d2e-b583-dde5d8badaf3)

* Formula [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e446e49d-5b8f-433e-ac94-1b0a82787994)

* For every separate feature there is a **table** for it.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/97f321ac-54d2-4a42-8301-f4a140cf82c4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6ee8dc5b-3fbf-4486-896f-d064e79140c7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/edd228a4-7479-4bdf-a7f6-51ea24ba64de)

* We have to predict the value of dependent variables.
* Probability of **y**, P(y | Sunny, Hot)
* We will solve by **removing** the denominator because **denominator** is the **common part** and it will get **eliminated** eventually and we want to calculate both the conditions.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7c506fbc-c884-4bcc-921f-38813f061108)

* The total probability of **Yes(Y) and No(N)** doesn't add upto **1**. It should be **1**. For these reason we have to calculate for **Yes(Y) and No(N)**. Those are not **normalized** value. We are doing **Normalization**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bcb44e5a-9079-4bb8-ba0e-665121463bda)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47b2878f-e240-4cff-832f-7e5780c98569)

* Now **Yes(Y) and No(N)** add upto **1**.
* We will go to the **No(N)** class because it has **higher chances/probability**. [**VERY IMPORTANT**]
* We are using it to predict the **classes**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/75c46a47-b89b-46b3-8b42-7140d8c615e0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b26a6026-8147-41aa-b722-34cab50fc4d6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2182ce82-e8ef-42cd-b329-27556fbe4cb9)

* **5** places have **Sunny** and the total no. of places is **14**.
* P(Sunny) = 5/14.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/41ad9a96-910e-47e9-8e37-8a78f8893aec)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cce5b71a-3a6e-4f0e-b6fe-c7691309372f)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/22a94a9f-6fb2-45c2-9e24-1c2aaa51f94f)

* f1 -> 6
* f2 -> 6
* 6 + 6 -> 12
* We also have to find out the **P(C1), P(C2) and P(C3)** which is **3**.
* Final is **6 + 6 + 3 -> 15**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/879017b2-e7f4-464b-a514-cc085c5ed06b)

* For the values of **D = 2, V = 2 and K = 3** we are getting **15** as the **answer**.
* Now check which option is giving **15** by inserting the values of **D, V and K**.
* D = 2, V = 2 and K = 3
* (V ^ D) * K -> (2 ^ 2) * 3 -> 12 [Incorrect]
* (k ^ V) ^ D -> (2 ^ 2) ^ 3 -> 4 ^ 3 -> 64 [Incorrect]
* V * D * K + K -> 2 * 2 * 3 + 3 -> 15 [Correct]
* K * (V + D) -> 3 * (2 + 2) -> 12 [Incorrect]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7930410-2044-4d62-84e4-a5783c44516a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee26108e-0de1-478b-9417-2cd6daac8dce)

* Option **C** [Answer] [**VERY IMPORTANT**] [Practice Paper Question]
* We didn't take **K = 2** then option **D** would have given **8**, we wouldn't be able to **eliminate** the options. That's why took **K = 3**.
* We will **reject** the others.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6a510f8a-1f68-4f86-8bea-57a5099035d2)

* Take an **example** and try to solve the **question**.

## SVM

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/268e1d0b-15b9-4b37-9d65-63d3b6bc46fd)

## SVM Classification

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7d5fa103-c329-49f7-bf9d-9caafc10d0a1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05e67e14-3491-42cd-917d-2bc5814ab863)

* The **line** is called as the **hyperplane**.
* The **points** are the **vectors**.
* We have to draw the **line** in such a way that the points/vectors get **max. margin**. That **line** we have to draw.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/86a28a03-d923-4355-aa57-177f3fd05419)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/647d346f-3715-4c0b-98be-e371d9304f4d)

* We have **two lines**. Which line is the best?

> The line which is properly dividing the vectors then that line is the **best line**.

* To select the **best hyperplane** we have to find the **max. distance** between the nearest data points on either side of the **hyperplane**. The distance should be **max** then that **hyperplane** is the **best hyperplane**.
* Between the two lines which line is the **best** and for that reason we are looking at **margins**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/954fcb79-e4c4-4fe8-813e-04eb5c51d8c0)

* The inbetween distance among the **margins** should be **max.**.
* Distance between margins should be maximum.
* Marginal Line.
* Maximum margin from nearest data point.
* If we have drawn the **best hyperplane** and the **vectors** helped in making the **best hyperplane** are called as **support vectors**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/67d85eab-803f-416b-bb78-e7ca482c0c6a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a030210d-e4eb-49d8-9da5-8b69b76d1dbe)

* The data points are called as **support vectors** through which the **margin lines** are passing.
* **Support vectors** are those **data points** which helped in making the **margin lines**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a2a68030-2bad-4b08-9f0a-f84765f0cc5b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cfebbd0a-d101-47a2-ad5f-3b76bc884c68)

* **G1 and G2** are **Two margins**.
* **B and D** are the **hyperplane**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9236e739-8d10-4a65-92c3-736d17dd999d)

* Which hyperplane is better **B or D**? [**IMPORTANT**]

> We can see that the **Max. margin(M1)** in **'B' hyperplane** is **more/greater** than the **Max. margin(M2)** in **'D' hyperplane** which is **M1 > M2**.

* We have to consider the **noise/errors**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fe0f033d-8d37-44f1-b393-40f5ad9cfe02)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb6daf35-bde1-4648-b38f-b471055f11dc)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b06d599-4452-4afb-ab4b-2950ae69d716)

* Soft and Hard Margins.
* Hard Margin -> No errors we can tolerate and the **margin** should be **maximum**. [Not Practical]
* Soft Margin -> Some errors we would tolerate but the **margin** should be **maximum**. [Practical]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6b114003-f52d-42f3-95d0-c2ff7974a756)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/765c8a74-519f-4a32-a8e0-c86569ff0326)

* Support Vectors.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/de5fd71a-7a7f-45f0-8463-65b5940bf1d4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/92879a98-224f-400f-a682-6cbcdd98fa83)

* Hyperplane

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ccf26713-b640-41d3-865d-df4124db3438)

* Comparisons.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/59711f7b-3eb1-4ba1-bffd-dd362a584a93)

* Degree of tolerance.

## cross-validation-part-2 (7)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6934661-c0e4-4c36-9774-c6e13541a93f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/80220033-b5e7-45b3-bcf8-8c421397f6cb)

* Hyperplane [Formula] [**VERY IMPORTANT**]
* W1 and W2 are **slope**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5cbda122-0a49-40a2-b8d7-113098e7b143)

* Degree of Tolerance.
* * **C** is a **hyper-parameter** and the value of **C** represents the **count of misclassified points** we are allowing .
* We cannot allow/take more than the value of **C**.
* If it is more than the value of **C** then the model is not perfect for that particular data.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9c9d15c6-a9e9-4cb7-bf10-57764a8edcc8)

* According to the hyperparameter(C), we will allow that many **misclassified points** as is the **count/value of 'C'**.
* If **C = 50** then we can allow **50 misclassified points**.
* The **greater** is the value of **C** the higher is the penalty for the **SVM** when a **misclassified points** comes.
* Degree of Tolerance -> How many **misclassified points** we will allow in the **SVM**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9a4c1281-d4ce-423e-b639-0815174dae74)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7776fbd2-83e1-4ff8-ab5c-461e3131b588)

* The line we are making for the **margin**, there is a **positive and a negative side**.
* The points on the **hyperplane** are on the **positive side** then they are in **one class say 'C1'**.
* The points on the **hyperplane** are on the **negative side** then they are in **one class say 'C2'**.
* It is a **binary classification**.
* We ar considering the points on **positive and negative side**.
* Some vectors/points are given directly and we are asked to create a **hypeplane**?

> We will say that some points lie on **positive side** and some lie on the **negative side**. Between the **positive and negative side**, the **hypeplane** is created.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1075687e-ff65-4bba-972b-8bea7d2c5ddd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/943594d9-6024-4990-968a-e42d7a1c9850)

* Explainations.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0f13b5ce-ffbc-4779-a33e-08d5b458e97e)

* We want the **max. margin** between these **two lines**.
* The difference between the **two lines** should be **max**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/66c6e076-9554-42b4-85c0-d09ae33d3656)

* W ^ T -> Transpose Value.
* **k** is any **positive integer**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9210869f-f7ec-4054-806e-df10756b24a0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9049212a-5f4f-444e-aaa5-1e6abcb2ebb3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/385f20f0-2dd0-41bf-abb2-69be06df86e6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac837fbd-92c6-42d1-bf38-09a21e144f96)

* The difference between the **two lines** is **2/(|W|)**. We want to **maximize** the **difference** which is **2/(|W|)**.
* **2/(|W|)** will be **maximized** when **|W|** is **minimum**.
* The distance between the **marginal plane** is **2/(|W|)**. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cf32bb56-3a3f-48d1-b65f-2aa08d9ed1f1)

* Cost function [Formula] [**VERY IMPORTANT**]
* We want to **maximize** the **2/(|W|)**. In terms of **cost function** we want the equation to be **minimized**.
* So we need to **minimize the **(|W|)/2**.
* We always want the **Cost function** to be **less**.
* We can say that it is a **perfect line** and we are not creating any **misclassified points**.
* We have some **misclassified points** and have to calculate the distance of them from their **margins**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ae67b18a-e4ca-4bb7-bec5-6161ba4c959c)

* Explaination.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c7e63f78-a0e7-48c2-95eb-b1aeaf306055)

* Maximize and minimize.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ee3da0d-fc5a-4443-b6cd-bcaf23fe5e2f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/88bdd9ce-c881-438e-bb7f-4d08d312d004)

* We have to calculate the distance of all the misclassified points.
* C -> No. of misclassified points.
* Eta -> Distance of each misclassified points from **margin**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bbcafec1-7250-458b-8021-38af650a0b27)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/483642d7-6cbe-4f33-acc8-bf3b4c7058d1)

* We want to **minimize** the **cost function** equation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e12a6228-6836-431f-83e6-74a7b8bacb24)

* Which is the **best line**? Which one is to be considered? [Example] 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/35d92780-61ae-4258-8de7-67f49b5fe642)

* Hyperplane -> a1 = 2, a2 = 5
* Hyperplane -> a1 = 20, a2 = 50
* With the help of the **coefficients** we have calculated the **value**.
* **H1 and H2** are nothing but **|W|** only. H1 = H2 = |W|

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7b85fb18-51f5-448c-b917-c198c5e6519e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fb4fda21-c1b5-4e8a-ad80-2cb565f011f7)

* **0.37** is the **distance**.
* We need to take **H1** as the **best line**. [Solution] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fc41b475-0e4a-4d94-8762-13eb2c233cce)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dc18de42-78bf-4ca7-adfa-73dc12b0a6d9)

* Example
* **Positive Class** means that the **points** are **ahead/above** the **hyperplane**.
* **Negative Class** means that the **points** are **behind/below** the **hyperplan**.
* We can get the **Positive and Negative Class** as well.
* We have to identify the **support vectors** in both of the **classes**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d077689d-d423-4ac2-8c1b-86c7ef889d7f)

* We are plotting the points on the graph.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/61951885-9201-41b3-baa4-c6c987aca2ab)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/78375333-5985-4fc1-87b3-64e803349432)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c05e31d6-6835-496f-a5c5-060705c18e39)

* We found **three support vectors**.
* We need to find the **hyperplane equation**. We need those **three support vectors** to find the **hyperplane equation**..

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d806d5e5-7c38-4fe3-b9e2-1abe58d87339)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/af356f86-c206-4686-9d20-81f231cd48d1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/02609925-5d88-483c-bf0f-357c38803798)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/886860b9-34a0-4093-ab09-16120d77bc2b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2508ea6-4d20-4728-b3c0-4bda1ba2fd3e)

* We **biased(bias)** the vector. We added **1** at the end of each vector.
* We added **1** at the end of each vector because we want to find the **intercept(C)** also.
* As we have **three vectors** so we will have **three equations**.
* We have to solve those **three equations** to calculate the **co-efficients**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e2dffa08-958f-4466-876f-0e47ce58ea67)

* The value of **a1,a2 and a3** will tell us at the end what will be the **line**.
* **a1,a2** -> Slop
* **a3** -> Intercept.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac8a637d-668e-4465-adf3-8991c3948294)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1d5466b9-9c5d-4039-9752-58b7f5da453a)

* y = (W ^ T) * x + b
* (W ^ T) -> a1, a2 [Slop]
* b -> a3 [Intercept]

* We are talking about the **1st vector** which is **S1' -> 1, 0, 1**. In all of three vectors we will multiply with **S1'**. As it is **1, 0, 1 -> 1,0**, it belongs to the **negative class(C2)**. As it is from the **negative class(C2)** so we will write **-1** on the right side of **equal to(=)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2841b542-29bf-4081-bb9a-706d7626272e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cd0a477-0dfb-4aa5-97fd-6f6ce541fd1c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ed67f86-db15-4b31-b796-dd48f867b4a1)

* We are now calculating for **S1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3485274c-2611-4171-a0ea-c6eb48682b6f)

* Vector multiplication. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/44bbeea6-a6a7-4347-b628-eab830be4d5a)

* For **three variables** we will get **3 equations**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/74b48faf-c173-4306-9f58-b11d530ff348)

* We are now calculating for **S2**.
* We are talking about the **2nd vector** which is **S2' -> 3, 1, 1**. In all of three vectors we will multiply with **S2'**. As it is **3, 1, 1 -> 3, 1**, it belongs to the **positive class(C1)**. As it is from the **positive class(C1)** so we will write **+1 or 1** on the right side of **equal to(=)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3eb8c7f4-587a-49f5-aaa7-783e113f70d0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/66af7552-3ed9-4754-b465-0f65df833753)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/64109fa8-49e4-4580-b164-daf0e22ec36d)

* We are now calculating for **S3**.
* We are talking about the **3rd vector** which is **S3' -> 3, -1, 1**. In all of three vectors we will multiply with **S3'**. As it is **3, -1, 1 -> 3, -1**, it belongs to the **positive class(C1)**. As it is from the **positive class(C1)** so we will write **+1 or 1** on the right side of **equal to(=)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/78f583b5-7197-4b12-b58c-f8340856ac11)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5cc76688-5230-4f47-8d69-9804d29a5f15)

* Equation **III** is correct only.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2cc4ee31-ebd5-40b9-b709-7069c1b5df8f)

* Equation 1.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7dacaa8c-7b9f-4c75-aa71-6f09e13f2af5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/74e24d5d-ce1f-47b9-9449-2cd82b966a0e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f7ccffa8-7fa7-486f-8cbe-916b6e484351)

* We got the values of **a1, a2 and a3**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c8e1bff-dd0c-4927-8c04-086f71ba0069)

* Original vector was of **two points** only and we added the **bias** for the **intercept**. So the Original **two points** are the **slop**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/be1e0e53-f963-4e77-8a72-abf21d7534c7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bb75f9c7-88fe-40e4-8486-aa386c06fc60)

* x = 1, y=0.
* As it is **x,y -> 1,0** so the **line** will be parallel to the **y-axis**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1f4849bd-da27-486d-9716-162dca5114ea)

* **-2** is the **distance**.
* b = -2

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cdb1e6d-6fa7-47f5-85a9-3070e1d96996)

* It means that we have to take the **line** at a **distance of '2'**.
* The line is parallel to the **y-axis**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a78af763-71a6-4886-a46a-78f9dd57d0f7)

* Found the **hyperplane**. [Solution] [**VERY IMPORTANT**] [Numerical] [Practice it again]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8be67ff7-12ef-495a-b118-74f454cb2072)

* Representation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/887dae2d-d657-422f-833d-09978419c44d)

* To solve the equation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/35a378fb-c60a-440a-9fe6-de2a19a1068d)

* This is the **generalized equation**, we have to use it everytime for any vector. [Formula] [**VERY IMPORTANT**]

## Decision Tree

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e10c4712-6ac3-4c7d-9cf1-05157d5468d6)

* Decision Tree

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cadaaa85-bc65-4184-b174-d02cd8af3d3b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/58e56276-0e54-4983-bac9-ee0253fc7554)

* **Leaf node** is telling/showing the **output/dependent variable** which means that it is showing which **class** it is belonging to.
* **Internal node** is telling/showing the **feature/independent variables**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a05cd20b-ca5c-458d-a9b8-3394ac386f36)

* Algos.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/16cf79f4-2af2-42a4-9567-bd9cb76e0b6d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4f46e8a3-e39f-4c94-ac4e-b28f429e3191)

* Example.
* On **every node** in **every level** we have to take a **decision** whether we have to go to the **left side or the right side**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09a92b7b-a7ed-464b-8a12-1ccfe34c9199)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/82a48886-23f1-4cab-acb7-67ad2a8d0e50)

* Example.
* Class ended abruptly.

## artificial-neural-network-part-1 (8)

## Decision Tree (Classification)

* **x1 and x2** -> independent variables.
* **y** -> dependent variables.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c5bfd4a6-9cd8-4599-ab7e-504f992840b1)

* We will calculate the **entropy** of every node.

## Entropy

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a4c925d0-6cda-4e7d-87c5-6ba293de5e2d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7715115e-5476-4b8a-9d0b-f2b9f45245f4)

* Entropy formula [Formula] [**VERY IMPORTANT**]
* p(x) -> Probability of that particular node(x).
* Entropy -> S() [Representation]
* We have **True '3' times** and **False** also **'3' times**.
* Take either class as **positive or negative**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6c30e2a5-510a-4c4c-b7d9-b9b963f28ed7)

* S(y) -> Entropy of the complete data.
* Probability of P(True(T)) = 3/6 [P(y)]
* Probability of P(False(F)) = 3/6 [P(y)]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0a8fe61a-2808-43b3-9df6-949b335f4771)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3c530e74-b620-43da-b30d-f572bb9ba4fc)

* We calculated the **Entropy of the complete data** which is **S(y)**.
* We also have to find the **Entropy** of the **individual data**.
* **x1** feature/independent variable has two variables(a1 and a2).
* We have to find the **entropy** with respect to the **output** variable only.
* True -> Positive Class.
* False -> Negative Class.
* We have **'3' times a1** in **x1** and we got **2 times 'True' and '1' time 'False'**. So **a1** is going to the **positive class** for **2 times** and to the **negative class** for **1 time**.
* We have **'3' times a2** in **x1** and we got **2 times 'False' and '1' time 'True'**. So **a1** is going to the **negative class** for **2 times** and to the **positive class** for **1 time**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9d25c6fb-c218-4d5c-a02b-e4aa2083262a)

* We have calculated **entropy** for individuals in **x1**.
* Out of all the **datapoints**, in **x1** we have **'3' a1's and '3' a2's**.
* Probability of **a1** in **x1**, P(a1) -> 3/6
* Probability of **a2** in **x1**, P(a2) -> 3/6
* S(a1) -> Entropy of **a1**.
* S(a2) -> Entropy of **a2**.
* Total **a1** with respect to **x1**.
* Total **a2** with respect to **x1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cf4136b7-829d-46af-86a2-3171734d7dc8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/20826819-e042-4737-9cd0-94d52720ade0)

* Gain(X1).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6c5229a-9e37-4041-a71a-2e9745b98ebf)

* X1
* Now we have to find for **X2**.
* **X2** has two class which are **b1 and b2**.
* **b1** is **'4' times** and we have **'2' times 'True** and **'2' times 'False'**. We have **equal distribution**.
* Whenever there is **equal distribution** then that is the  **best case** for **us**. Whenever we solve for it we always get the **entropy** as **1**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a9b72799-c3c2-4c73-a7d8-076a190bf5f5)

* **b2** is **'2' times** and we have **'1' time 'True** and **'1' time 'False'**. We have **equal distribution**.
* Whenever there is **equal distribution** then that is the  **best case** for **us**. Whenever we solve for it we always get the **entropy** as **1**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a9e11e08-705b-448b-b35f-ede3b7b9eb7a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4e597fb1-e09b-488d-b41c-300cbb6cfbc9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8feacf90-1edf-4b10-bf39-ecbcb9f7ae43)

* Entropy for **X2**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c1861cbe-01bd-4f74-8d8b-b030978777ff)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/50fa32d6-1213-4e7c-8917-c34cbad14bb9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8445f337-33f8-40fc-a515-58d16e7795e7)

* Whenever the **entropy** is **1** which means that there is **100% change of inpurity** or **impurity is high** **completely/complete impure**. [**IMPORTANT**]
* Whenever the **entropy** is **0** which means that there is **100% change of purity** or **completely pure** or **pure**. [**IMPORTANT**]
* Probability of **b1** in **x2**, P(b1) -> 4/6
* Probability of **b2** in **x2**, P(b2) -> 2/6
* S(b1) -> Entropy of **b1**.
* S(b2) -> Entropy of **b2**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/779f5794-3826-4ac4-aa44-e366abe3a30d)

* Gain(X2).
* **Gain** means **information gain**. [**IMPORTANT**]
* The **higher** is the **no. of Gain** the **more amount of information** we are gainng. [**IMPORTANT**]
* The **Gain** in **X2** is **zero(0)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e0d919ca-eecf-4c7d-9de4-bce5e7218de9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/93aae590-f97b-4c62-9cc5-43aee75c8ad4)

* Select those **variable/feature/independent variable** whose information gain is more. [**IMPORTANT**]
* So **X1 > X2** which means we have to select **X1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/00e2b8db-ed0a-456e-8166-732d3ebf2f25)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/39d66266-98f0-4719-8382-60cff107e576)

* Decision Tree.
* As the **Gain** of **X1** is **greater** than the **Gain of 'X2'** that's why we put **X1** as the **root node** of the final **decision tree**. [**IMPORTANT**]
* Inside **X1** we have **two classes/features** which are **a1 and a2**.
* When it is going to an **individual class** then no need to expand further.

### Converting the base in logs [**IMPORTANT**]

* Link -> https://www.purplemath.com/modules/logrules5.htm

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f65abad5-c02d-4799-a885-3c0404015a26)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9b6072d6-9d43-4e70-a32c-0f2ad9186973)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1744e5d1-cf44-40ef-84e5-6e4e18755e3b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/72511f90-58b0-455d-90c2-1c3c85180f96)

* Conversion. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d3c99942-8b5e-4156-b640-d13a16eaeac3)

* Gain(). [Formula] [With Example] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/73b3ae01-39e7-4c3d-bc14-55db948a9555)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dcceb82a-fbe0-45fd-b2dc-c510321dc793)

* Question [Example]
* First we will find the **Gain()** of all the **'4' features** which are **outlook, temperature, humidity, windy**.
* **Outlook** will have the **highest Gain()** so **outlook** is the **root node** of the **final tree**. [**IMPORTANT**]
* **Outlook** has **'3' parameters** and we had written them. We wrote **Yes** in **overcast** and we will not expand it further as it is going to a **particular class** which is the **Yes** class. We will expand **Sunny and Rain** as they are not going to any **particular class**.
* We have **'5' times 'sunny'** in **outlook** and they are going to **'3' times in 'No' class** and **'2' times in 'Yes' class**.
* As it is **'3' times in 'No' class** and **'2' times in 'Yes' class** so we have to further expand the **Outlook** node.
* We have **'4' times 'overcast'** in **outlook** and they are going to **'4' times in 'Yes' class** only.
* **Overcast** is always going to the **same** class which is the **'Yes' class**. That's why we didn't further expand the **overcast** node and directly written **Yes** there.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8dd318b3-36bd-4129-85eb-41a5ebe727a7)

* The **decision** we are taking is that if it is **outlook** and it is **overcast** then we will **definitely play**. We don't have to see anything else.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fed88c79-bc3f-4431-93b3-684fe0b748a7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/76cbd8f9-9028-4f0d-b477-5aedfffafd04)

* When there is **equal distribution** or 50/50 change of whether we will play or not play. These type of **data** is **100% impure**. [**IMPORTANT**]
* In **overcast** we had **4 "yes"** which means it is a **pure** data. [**IMPORTANT**]
* As **sunny** was not going to a **single/particular class** so we expanded **sunny** and calculated the **Gain** values and the **highest Gain** was of **Humidity**.
* The features of **Humidity** which are **high and normal** are going to **single/particular class** which are **No** and **Yes** respectively. So no need to **expand further**.
* As **rain** was not going to a **single/particular class** so we expanded **ran** and calculated the **Gain** values and the **highest Gain** was of **Wind**.
* The features of **Wind** which are **Strong and Weak** are going to **single/particular class** which are **No** and **Yes** respectively. So no need to **expand further**.
* We didn't need to expand **temperature** because the tree has already reached the **leaf node**. [**IMPORTANT**]
* We are going to expand still the tree reaches the **leaf nodes**, it doesn't mean we have to expand all of the **features**. It is not necessary. [**IMPORTANT**]
* Whatever the **temperature** is, we will **play**. Indirectly we can say that the **play** is not dependent on the **temperature** feature.  [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/529e79fb-4ce1-4803-8ac0-7c396fd5fb6d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/24e7784d-15eb-477b-8cff-f6772c824502)

* Example. [Question]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c5c29e5c-afd4-4f90-a17e-3693df1220d7)

* H(S) -> Entropy of **play**.
* C -> Class.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4802597e-be40-4077-bc30-ba26664e6b51)

* Entropy of **play**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e78359d0-6b92-492d-9ffa-7b1e1a41f666)

* In **sunny** we have **'3' times 'No' and '2' times 'Yes'** class. Total is **5**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3adbe3b3-0608-4304-ac88-2b4d873b4dfa)

* The **entropy** of **overcast** is **zero(0)** which means it is **pure data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e242dca7-d386-44fd-94ab-523ad79930d6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/85ae1886-7f69-4ff2-a0bd-7490bc8f8cd4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/87218543-f0dd-42f5-b483-8fdb18c3a1c8)

* As **outlook** has the **highest gain** so it is the **root node**.
* We got the **root node**.
* Entrophy is **zero(0)** means **pure data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b3896f42-2de1-44ef-bf22-c6eb9d5e368b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f40e6415-7aa8-4ea2-a2c3-ebe1e5a45b52)

* When the data values are going to a **particular/single class** only then the **entropy** is **zero(0)**. [**IMPORTANT**]
* When the data values are going to a **two class** and in **equivalent/equal amount** then the **entropy** is **one(1)**. [**IMPORTANT**]
* When the data values are going to a **two class** and in **unequal amount** then we have to use the **entropy formula** to calculate the **entropy**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a823352e-85b5-4422-882e-12ab3a046cf2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6895c943-3b27-47e8-bd17-4de567c244be)

* Gain calculation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c3170bd-9d3e-4d61-9c2c-d8afe5fcffbb)

* Humidity.
* If every types value belongs to same class for particular variable then information gain of that variable s same as parent node. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/271a070e-399c-4d75-b708-54aa335244c6)

* ID3 -> Classification.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e811010d-d5a1-41ce-9210-a5f8feb65378)

* Information Gain.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cca92dae-7f24-45cf-b170-c9e73d0ee2e4)

* Information Gain. [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e5e3a898-77c6-49ce-b895-945256dee299)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c196ad90-77db-4074-8f39-e54994452ba1)

* CART. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/29ce220b-a852-43d1-9428-3fb53e6b8be9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bf2950c2-dd34-4eb5-81bf-9e6182696043)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ec64dae8-f801-4b56-9c9d-0cb2d92c1b5b)

* Overall Gini for **outlook** feature.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3852d8cc-199f-43e1-85b9-026823265746)

* Temperature

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/791b0d68-9361-43a6-80eb-3e344ce681e2)

* Humidity and Wind

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0c0d4646-a6dc-4557-b0cc-524844401c69)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a11ae7aa-493c-4e52-854c-314a27a44c03)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/480c92ce-9bbb-4b50-aa67-1a07cc692fb5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7a92690e-391e-4637-a486-866175dcc00a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6512f434-19b1-4f4f-80d4-6ae661a85e6f)

* Temperature, Humidity and Wind Table.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c69b2396-f8bf-4dd1-8ae5-21da26cd361a)

* Temperature

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83e11316-3858-4254-8314-56c60dc9391c)

* Humidity and Wind

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56bcafac-ce9f-46e2-8cca-cd4dd8ed2d69)

* In the **previous example** we were selecting the **nodes** based on who had the **highest Gain**.
* In this **example** we were selecting the **nodes** based on who had the **minimum Gini index/value**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0322f156-acbb-449e-b9b7-b98083fd2bed)

* Final Tree [Solution] [**VERY IMPORTANT**].

## Doubts

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8fd18479-afbc-470f-9951-6f10b5e3e995)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4ebe0720-fa44-415c-a901-bcb167d517e9)

* Wanted to represent in **y = mx + c**.
* Both are **same** in this case.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cc1139f-be2e-4614-b089-780cc45b9672)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1203aaf1-1101-4b1a-8dfc-15439ebf0754)

* Cases.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/611aa95f-0630-4901-9f1c-b06f81bc4df4)

* Exanple.

## artificial-neural-network-part-ii (9)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a66d41b6-e8a1-4e21-9fa2-e801e9fb5757)

* Decision Tree -> Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ce006178-a610-4831-b3d6-6d71c21c7851)

* Example

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b6c3f1ee-2a41-4a3c-8fdc-08f0323af1e1)

* Decision Tree Algo

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bff0b734-9ccd-4c17-8969-d45d52cc6d0a)

* We are calculating **Standard Deviation(S)** here. [Formula] [**IMPORTANT**]
* Hours Played -> X -> Output Variable/Independent Variable.
* Average -> X'.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05415d70-7cd4-44f4-96e3-307622f6e7d0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/06de31e1-e1eb-4b7d-a327-67d85db54559)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ff8fa241-21ac-4493-82ec-95f4ab36d542)

* Standard Deviation(S) and Coefficient Deviation(CV).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/33c4ef95-a2f3-4d14-96ba-9f67d981469a)

* Standard Deviation(S) for two attributes. [Formula] [**VERY IMPORTANT**]
* P(C) -> Probability of the variable(x).
* S(C) -> Standard Deviation of the variable(x).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/512469d6-24e7-433c-8390-a00d985334b6)




















