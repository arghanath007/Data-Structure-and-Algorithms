# Machine Learning

* Link -> https://unacademy.com/course/course-on-machine-learning/53AX3KFZ

## introduction-to-machine-learning (1)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/340c019c-efee-4571-8d3a-e33ff7365beb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0018ff2c-5297-4773-a52e-2d39dca8e48f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1b5be1c0-6952-4298-8d0c-93f8fc7aecd5)

* Machine Learning
* We will give some **input** to the **ML model** and we will get some **output**. The **output** will be based on the **previously trained model** and the **type of input** that is given to the **model**.
* We need to design a **model** and the model will be created based on different type of learnings. The model is created based on the analysis of the **data**.
* We have given **data** to the model and sometimes we send **output** with the **input** sometimes only the **input** is given to the model and the model is made to **predict** on the **input**.
* Finally the aim is to **design the model**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/61bd0336-5c20-4681-92c1-623f33e3a4ef)

* Types.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/384ec7b7-f061-47ab-9a55-a58c20c3bbca)

* Supervised and Unsupervised learning.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac54a626-befd-48fc-a2ef-ca1b191f543b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/831540dd-526d-4820-b506-8027cc263756)

* Application of ML.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee6702ae-09cf-436f-af17-2a08a33ec72b)

* Algo.
* Statistical -> Mathematics.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ce848092-ca6a-41d9-8790-ce884e6adf39)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b61aae7c-586e-4952-89d6-abd4a7f512fd)

* Model.
* It has **data collection -> Training -> Testing**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c1a4744-2498-4f98-9d8d-738bb562a4bb)

* The **variables** used to predict the **output** are called as **predictor variables**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/395eb206-497a-4042-a537-e2ae5a8b004e)

* The **parameters/variables** on which the **outputs** are based on are called as **response variables**.
* The **data** used while **training the model** is called as the **training data**.
* The **data** used for **testing the model** is called as the **testing data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c51627ad-58a1-4839-a9fa-a4ea8e650d2f)

* ML Process.

## Supervised Learning

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ef8ac95d-e7f4-4f17-9a6a-053363ffa2d5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5a1e4a47-5f5b-42df-8798-edd5235b14ec)

* **Labeled dataset** -> For all of the corresponding **inputs**, we have all of their corresponding **outputs** along with them. For the **specific input**, we have it's **specific output**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/07316df8-58a9-4317-add9-a39f73cc92c3)

* We have trained a model on the **labeled dataset**.
* We are applying a **new input** to the model which is the **testing dataset**. The model will give us the **ouputs** of the **testing dataset**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8c6bc4a7-3d1d-4674-bd2e-8f043d1ce328)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/da15be4d-4d3f-483d-b003-a4528c95b227)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed2d4921-3c6c-4f61-85f3-f647606738e7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fa9cc8d1-9a5c-4b0b-836d-48875879484d)

* Types of **Supervised learning**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b2792fd5-6ad2-4826-90b3-95cbfcfa6eb1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1b8d36fc-2ce6-43e5-a920-dbd09fff7fbe)

* Unsupervised learning.
* **Unlabeled data** -> We are not sending the corresponding **output** with the corresponding **input**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/946674e6-9179-4643-a9ac-eebb05fcba84)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f5f245b4-5cb1-4b6e-8244-4aea73deac20)

* **Supervised learning**.
* Learning algo.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d5c003e1-573b-49ee-b697-50ef4c5e7f67)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b107e36-c65f-4c71-81f9-21db4fdb9885)

* **Unsupervised learning**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/aaab6f14-765f-4d57-b196-f377a42aa9c8)

* **Unsupervised learning**. [Example]
* We will get **training data** on **supervised learning**.
* We will **not** get **training data** on **unsupervised learning**. We cannot separate the data. We just analyze the data and design a **cluster/group**.
* In **classification** the **output** will be **discreet**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3db053e7-145e-4845-8e9a-111c581cc977)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/021fc06b-3dae-4029-bf5a-868e55b96635)

* Supervised VS Unsupervised.
* Regression:-

1) Linear
2) Rigge
3) Lasso

* Classification:-

1) Logistic Regression
2) Naive Bayes
3) LDA (Linear discriminant analysis)

* Common algos between **Regression and Classification**:-

1) Random Forest
2) SVM (Suport Vector Machine)
3) KNN (K-nearest neighbor)
4) NN (Neural Network)

* Unsupervised:-

1) PCA (Principal component analysis)
2) K-means

## Reinforcement Learning

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6b01729e-f858-45d3-b7af-8a56fd397b9f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/846b5da3-b7dc-438d-862f-fed4d7b3c777)

* It provides **feedback** to the model. [**VERY IMPORTANT**] 
* In **Unsupervised learning** we are **not teaching** much to the **model**, it is **learning itself** only by doing **analysis**. It is using it's own **analysis** and it's own **brain** to do the **predictions**. [**VERY IMPORTANT**] 
* In **supervised learning** we are **teaching** most or everything to the **model** and it is **not learning itself**. It is not using it **brain**. It is using the things that it has **learned** via **training** on the **training data**. [**VERY IMPORTANT**]
* **Semi-supervised** learning it contains mixture/combination of both the **labeled and unlabeled** data.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8924f42d-f4e8-4db9-ab18-7a3bb5dfbc4a)

* Regression.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/43125abe-ebb5-4b55-8f1a-e44ef5a1c07e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4caf3fd1-6a2a-4702-832a-87f15d128d41)

* Option **A**. [Classification] [Question]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/51f9ac32-648e-4743-9640-fd9a23e44fff)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2419312a-a561-4e42-a433-aec689d7fc19)

* Option **C**. [Question]
* Same work is getting repeated again and again.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/819761af-efd7-49c1-aaf3-89ad9103d8d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3f7154fd-ba08-45cd-a5eb-855091e24636)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/49291adc-cf06-490f-929f-e97b4af867df)

* Option **A and B**. [Question]
* Unsupervised -> Clusters/Clustering.

## Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/00a19c4d-aeeb-4810-968a-3bcab2ae0f4f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/691a1cfd-6987-4d0f-abc5-a1b0ca17d360)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b5be30e1-8f6a-4307-bba0-9a458705f2b9)

* Relationship between two variables which are the **dependent and independent** varaibles.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3f616924-fe50-440d-a7d7-0b18b81c9b34)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/640f34af-4340-4eaf-b14e-2037cc33a739)

* **Dependent and Independent** varaibles.
* We are predicting the **salary** based on the **experience**. [Example]
* **Input** -> Experience -> Independent Variable/parameter.
* **Output** -> Salary -> Dependent varaible/parameter.
* **Dependent variable** will always be **one(1)** which is the **output/prediction**. [**IMPORTANT**]
* **Independent variable** can be **more than one(1)** which is the **input**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3e844ee4-6021-45d0-886f-79fc25615d18)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/19f0c29f-d6fa-43f5-8009-91e4b8991378)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7c259a31-0079-4421-a898-3a42b44abbfb)

* **Regression** Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2488b03-3cf0-455b-83c7-cb972f575d17)

* To show the **relationship** between the **Dependent and Independent** varaibles we use **regression**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9569521f-42b3-474c-921d-1934f7066b49)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1fd13514-9e6d-4d3d-ab28-5eaaa673510f)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f465194e-a7e8-463e-bd87-1410f891bce0)

* observations.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/53c53624-644c-4441-aedf-63db002cb9f5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e0bd8277-1bde-44cc-92be-05279f5a3a3c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c85ab828-4b47-47cc-bdb2-28303685908f)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1b0c116f-d5fb-438b-8901-452337904750)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c0a826e3-a81a-41a0-b2d9-f2e54a84223c)

* Why **regression**?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f206d761-9694-4997-8ac4-bb4af2712c35)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8a98ea5d-a297-4691-91a9-dbf56a0e7f58)

* Types of **Linear Regression**.

## Simple Linear Regression

* Next Class.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83418ee4-d93c-4b8d-b457-5e4445d8b73f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed064955-6dd7-4b71-81d9-1b80aff1ce48)

* **AI** Doubt.
* BFS -> Complete.
* DFS -> Not Complete.
* **No**, it will not be **complete**. [1]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8512de61-a48d-4483-9bfa-cf74874c9436)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8ec5d80f-00e0-48df-8bdb-b8bdd114c58b)

* 2.
* **Time and space complexity** same for **uniform cost search**.

## regression-classification (2)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/be76e787-942e-45f9-9463-655963be2703)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a8d83e19-dd22-4df6-8257-44e7081e183f)

* **Simple** linear regression -> **Independent and dependent** variables are exactly **one(1)** only.
* **Multiple** linear regression -> If **Independent** variables are **more than one(1)** and **dependent** variables are exactly **one(1)** only.

## Simple Linear Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7e193b10-727f-4582-bf78-9267a64e1833)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c371c79-a58d-47f8-8cbf-736916bf7ff3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/454adc58-8307-4cf9-9920-cf79f95abbc0)

* **Independent variable** is on the **X-axis**
* **Dependent variable** is on the **Y-axis**

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8cad00c1-3ff3-4cff-9c92-8e0f0da4f61a)

* Fitting line to the data.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5bd54dcd-be52-4b3c-ba0f-0db4a6e31266)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f3b1073b-2bd7-4d9b-98bd-4074549f0caf)

* Option **A**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1a0b8f4f-d9f9-4394-bdd9-b98b498dff8e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/42774cda-3f54-4331-a95e-20881670a18f)

* y -> Dependent variable
* x -> independent variable
* m -> slop of line (How much change in **y** for unit change in **x**0
* b -> intercept. (When **x** is zero(0) then what is the value of **y**?)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b793f72-135d-4c85-a90a-5c6a2481861e)

* **y** -> dependent.
* **x** -> independent.
* Types of Questions:- [**IMPORTANT**]

1) Find **m and b** value.
2) Graphs are given in the options and we have to find the correct graph for the given data in the tables.
3) Design the equation. Equations will be given in the options.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/436c116b-14b2-4dbc-8e81-dc979f3a7e8a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cffb96bd-3da8-41dd-8be1-f1c88ee2964e)

* The main aim of **simple linear equation** is that the line should be the **best fit** line. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9314af66-145a-42ba-89c6-a0ec5b3cce48)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/779f8b5d-4703-4917-ad76-0695bbc60779)

* What would be the value of **y** for **x = 1.5**? [x = 1.5 -> Testing data]
* The **main role** is that we have to make the **line** in such a way that **min. no. of errors** come. **Errors** will come but we want to **minimize the errors**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/841ef30c-3a65-4705-b79c-6fb6741942ee)

* **Actual value and predictor** are to be identified here. What is the **difference** we are getting.
* y' -> Predictor
* y -> actual

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/429f0a85-852c-4ee5-8f02-fe04a792f704)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/48656ff8-d4c7-40c4-85b5-4c1297dd7c93)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6045a03c-c1bf-49a4-8138-a7f92a9f47cd)

* Hypothesis.
* **y** is a **linear function** of **x**.
* **ho(x)** is a **linear equation** of **x**.
* Find the ** slope(m) and intercept(b) value.
* **Mean** means the **product of 'x' and 'y'** and their **sum**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/85b660c4-07e5-46ce-aa47-e02648ecd438)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c47b42bb-14b0-4795-8adf-9acc86bbe5c7)

* Value of **x and y** column are given in the quetion.
* We are finding the **summation of 'x' and 'y'** and also we are finding the **summation of (x ^ 2)** and we are finding the **product of (x * Y)**. [**IMPORTANT**]
* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e7b5e6a1-9b81-4bc1-a57b-dfb1ddbdbae9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/81324504-999f-4a63-8c5b-5c453071f17d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ce5687a8-2461-4b37-8688-3c2e10ce43d7)

* Formula [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e8dc5064-e1e6-4544-b93b-bc45e6435a74)

* x' -> mean of **x**.
* y' -> mean of **y**.
* (x ^ 2)' -> mean of **(x ^ 2)**.
* (x * y)' -> mean of **x * y**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c27b25b5-1eaa-45f8-a5b1-2e85fb2436dc)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/55984f5c-5557-4682-85e7-88630ed36a13)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3042af6d-65ce-4394-b1de-b805db61a98e)

* Solution. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/baed0669-3192-486c-94b5-c3b43a22d2d6)

* For some value of **x**, what will be the value of **y**? [Expected question]

> **x = 30**, so the value of **y** is **43**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c370a9aa-fa8e-4702-b829-cea9d6554cc3)

* y = (1.5 * x) - 2 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47165e5a-1c2b-4ad9-8709-c848320dc029)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83ee2628-f586-49f0-ad7f-51bef84b2a11)

* **Graph** for the **above question**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d578ab25-a1f2-4451-92b2-41185962a2cc)

* Question
* Find slop.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ee7297f-572b-4ad9-8758-46b8a0929206)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/839237f4-f96f-4f80-947a-fb873f38850d)

* **y** is intersecting at **40**. we can see it from the point of **(0, 40)**. From these only we can say that the value of **b** will be **40** only. [**VERY IMPORTANT**]
* According to **intercept** concept, if **x= 0** then **y = b** which means that **b = 40**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8fa54a96-05e1-4dd1-81b0-211fde2ac23a)

* Solution. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/71fc4c2b-13be-45bb-be91-e01bedbdab9c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2234fbf4-1d57-4c30-aa05-9d1d70bd8c8a)

* n -> No. of test data [Formula] [**VERY IMPORTANT**]
* m -> Slope data. Equation of slope.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47b88d9a-1bc6-45cc-b7b3-fc4d87df3773)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b6400f8-9a61-4079-9684-799fcc6cb168)

* Question [**VERY IMPORTANT**]
* n -> No. of elements -> 8.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/80a02742-dfe5-4a22-a0fe-8d304fd967fc)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/65920570-bc55-45f7-9ac2-1d8254858ca4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cf850b45-1274-48b2-bbae-e9339a840d98)

* Option **C**  [**VERY IMPORTANT**].

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7425fe9c-b239-4b92-853c-a25033b9b774)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/945ea577-b2db-487b-a3c6-d5faee568964)

* slope(m).
* We are calculating **directly**.
* This **example** will prove that we will get the **wrong answer/equation**.
* For the above reason we have to use the **formulas**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/75c1e29c-56be-47bd-ab64-8aef1f7e6da6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6d3d3f19-3090-4a1f-8463-aaabb8108a7e)

* We can clearly see that **b** is **-15**.
* We got the **mx + b** equation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4152ccfa-ba24-435e-96cb-3ea673e03945)

* When we put the value of the **equation** we will get an **error**.
* We got the **equation** directly.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1fa94f9b-70aa-49f2-b4bb-50dd3854a145)

* This is the **equation** when we use the **formula**. [**IMPORTANT**]
* We use the **list square regression technique**.
* Use the **mean** formula.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a23b2ae4-5f88-46fe-aeca-8fd6f2d4c793)

* Formulas [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/90c31882-96c6-478d-aa20-b1565bded5a1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5af60a94-6135-4aac-97e2-040236a46dc3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1a2a283a-f263-4411-b66c-c0e41e71f00e)

* x -> independent variable
* y -> dependent variable
* Find the **mean square error(MSE)**?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/153c08d8-fe22-41d2-9655-aeae6c4e3507)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9d4ba194-e4d4-48d2-b7e4-6a83a2a1dc47)

* Estimated, **y'**.
* Actual, **y**.
* To calculate the **error** = y - y'.
* Never take **difference** in **negative**. We have to take **positive difference** only. So we will square the error which is **(y - y') ^ 2**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/474e669f-cbb6-42b2-87ae-1cdc97343375)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/36865b92-9108-43b1-a930-d534fbb280d7)

* **n** is the no. of datasets.
* Estimated, **y'**.
* Actual, **y**.
* **Mean square error(MSE)** -> (1/n) * (Summation of ((y - y') ^ 2)) [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/329f956a-76ad-4eb0-8b4c-0c751692245c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/71d10480-d8b5-46ff-aa22-3201b338bfd0)

* Solution [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/427d5189-ec75-4418-9bac-4e3f43e17fe1)

* The **min.** is the **Mean square error(MSE)** value the better it is. It tells how much **accurate** our predictions/output are.
* The **min. MSE** means the **better or more efficient** is the **solution**.
* **MSE** should never be **zero(0)** which means that the **predictions/outputs** are **100%** correct. If it is so then the model is doing **overfitting** which is a **problem** of **linear regression**.

## regression-classification-part-ii (3)

* The **error** calculated should be **minimum**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a762b641-720e-4f79-9e63-53b122330d44)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e2d98bb0-fa9e-4bf1-8d0d-1ac75dfe0bff)

* Cost function. [**IMPORTANT**]
* Theta0 = b
* Theta1 = m
* They are just representation. Someplaces **b** is written someplaces **theta0** is written.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a67e6676-447d-4b0d-9645-63dc787c91f6)

* We are checking if it is the **best fit line**. All of the **data points** coming in the future in this **problem** will give the **best error** or not.
* For every new **data point** plotted in te graph we will calculate the **error/difference** of the point and see if it is the **best fit line** or not.
* We are doing the **above calculation** using the **cost function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/beb53feb-42ca-41bb-b1b0-474479399a1b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/79c93dfb-1e17-41c8-929b-b89325ca94c6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1f909fc6-74cb-44b0-90db-761e99153810)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b409fa6-603e-4e08-bf0b-cca462d45b3d)

* Cost Function.
* We are trying to find the **exact** of **Theta0 and theta1** or **slope(m) and intercept(b)**. which will be the **best slope(m) and intercept(b)** so that we get the **best fit line** which we can **calculate**. For that we are using the **cost function**.

* x1 = 1, x2 = 2
* y1 = 1, y2= 2 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bafa5bb7-879c-4632-b293-8e70e3f99bd0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/85d18793-2547-41c9-a48f-f6ab71121b8f)

* When **theta1** is **1** then **theta0** is **0**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4669a89d-da48-4b6f-9c23-04e9faddb2c2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/68dbc709-61a1-4979-b23c-eb1f538bd2f0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1cbdf740-6e2e-44b4-82ff-8c57e02317d4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e82f0e0b-9c3e-4d77-813b-4d240969584c)

* Slope.
* The point is called as the **global minima**.
* Till we find the **global minima** we will continue **finding it**.
* The value of **Q1** at **global minima** that will be the **best value** and the line created from it will be the **best line**.
* The **graph** is called as **gradient descent**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/04ea6cd9-0610-444c-a15f-701c91455da8)

* Goal is to **minimize the cost function**. Till it is **reduced** we have to continue doing it.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09c9e696-1a28-4223-a81e-7f606e7479a5)

* What is the meaning of **gradient descent** and why we are using it? [Potential Questions] [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cc63e5ab-032b-4a2b-b00b-dbfed3e5be2b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e24637c0-236a-4f03-89fb-b9404251145a)

* Cost function [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/476328b9-d65b-4b65-8808-b694f303a821)

* Alpha -> Learning rate or hyperparameter.
* Best learning rate(alpha) is **0.01**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05ebdba2-9791-482b-9162-0979de0f4a98)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3aa5f9a6-aee1-4497-b567-3f9dd012ea0f)

* **Learning rate** is saying at what rate the **value of alpha** is going down.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4d7d2474-ce64-492b-a682-45ea69cb2252)

* MSE [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6ca60f42-151e-4468-9cef-f638a77c13af)

* Because of the **Squaring** the units can change for that reason we can use **absolute mean error**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ef0fac58-80dd-4278-b2d8-f398d7d0a650)

* Absolute Mean Error(AME) -> (1/n) * (summation of (mod(y' - y))). [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c7c23316-8e42-4e96-8c78-eb5925f87df6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/58f281ca-14ef-438a-8011-b9640b03d2ad)

* Root Mean Square Error(RMSE) -> sqrt(MSE). [Formula] [**VERY IMPORTANT**]
* Which **error** will be used will be **mentioned in the question**, if it is not mentioned in the question then use the **MSE** to calculate the **error**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3021a075-3a48-433e-9680-dc2d806bb1d8)

* Find the **Mean Squared error**? [Question]
* y -> Actual
* predicted -> f(x) or y'

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/98fc2e01-c711-4c8a-9017-791666ea2ad4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/913a8d44-1a75-4892-9d5c-5ef6271975f2)

* Solution [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56137110-2664-4ee8-8f3d-092b8f97b674)

* Absolute error would have given the **same error** value as well.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8f59959b-92e7-4f9a-907b-230e03ef0dc1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a07a939d-4cb0-40d6-b429-255314476c47)

* **(8, 45)** is an **outlier**.
* From the **testing data/values**, the **data points** that are **moving very differently** those are called as **outliers**.
* It is creating a **large difference** and hence creating a **large error** from the **best fit line**. [**IMPORTANT**]
* They are out of the **normal pattern of the data points**.
* **Linear regression** suffers from **outliers**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5dd1b0cf-3ef1-4df2-bdb6-638a678e6eeb)

* Multiple Linear Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/101f3163-c937-4cee-89c0-34236f98c26c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/35ae8243-f42a-4d6d-8416-fa0307d79707)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/416cf9e6-9bea-4577-a83f-076d127875c8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09277a14-837a-49d8-9615-ed784dc8f9af)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/570119bc-3ad3-449c-b12c-28550b4f1c92)

* **x1, x2 and x3** are three **independent variables** and **y** is the **dependent variable**.
* **Q0** is the **intercept**.
* **Q1, Q2 and Q3** are the **co-efficients** of **x**.
* **x** terms are always **independent variables** and the **y** terms are the **dependent variable**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/329ab8cb-c8e4-496a-a0bf-415bb16f6417)

* What is the equation?
* What will be the equation?
* Formula?
* Equation? [Expected Questions]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/34bdcff8-a040-4e55-bd40-b7cd684077bf)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/adb0dd5a-45ca-4596-82ac-09eb03827914)

* We always put **1** in the **1st column**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/18c58577-e755-48d8-853b-ba9f8acd32d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/69e65b2a-eaf6-46e7-837d-d70007ad4fa7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0c6b96a5-3f49-4b86-949c-bd1d38fd5fc9)

* We have to find both **co-efficient(slope) and intercept**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d513771a-31cc-4047-9b5b-17370b4a45d0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0abc80cb-bdcd-45d7-a868-aa21f1b8bbb2)

* Multiple linear regression. [Formula] [**VERY IMPORTANT**] [Theory type Questions]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/84414a60-665c-40be-ae57-df84f9f16fc2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/981a049c-c454-4652-8f48-a9bb9b2217ba)

* Underfit and Overfit. [**IMPORTANT**]
* Variance and bias. [**IMPORTANT**]
* **Underfit** -> In both the **training and the test** datasets it is not giving the **best results/outputs**. [**IMPORTANT**]
* **Overfit** -> The model has **trained** very well or too well on the **training set** but it is not able to perform **better** on the **test dataset**. [**IMPORTANT**]
* The **model** should never be either **underfit** or **overfit**. [**IMPORTANT**]
* **Good fit/Robust** -> The **datapoints** should be **near** the **line**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/93023bbc-f8ce-481b-ab2f-60f122839ed2)

* [**VERY IMPORTANT**] [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e6b7dbe4-868f-4164-a791-f429a4e65fac)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/36caa95a-afc7-4285-8732-cf1e9a57ac08)

* Overfitting [Example]
* The model is just **remembering** the **training dataset** instead of **learning** from the **training dataset**. [Example]
* The model has trained too well on the **training dataset** but it is not able to perform on the **test dataset**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee8af129-b195-4abf-b69d-d7f89064e916)

* In **Overfitting** we will get the problem of **high variance** which means that the model is failing on the **test dataset**. [**IMPORTANT**]
* In **Overfitting**, the **bias** will be **low bias**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7687aece-bbab-4955-9afa-b60e157df7ae)

* Underfitting [Example]
* The model is either performing on the **training or the test** dataset. [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8d56317d-dc31-4e0e-84ab-3f3b4cd5af46)

* In **Underfitting** we will get the problem of **high bias** which means that the model is failing on the **training  dataset**. [**IMPORTANT**]
* In **Underfitting**, the **variance** will be **high variance** most probably because as it is failing on the **training  dataset**, the model will definitely fail on the **test dataset** as well. [**IMPORTANT**]

### Bias

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7f8075f7-c97b-46ca-9b38-3ec50502d0e1)

* We will use the **bias** word when we are talking about **training dataset**. [**VERY IMPORTANT**]

### Variance 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fba6839b-34cb-4c20-a995-4c0518736a62)

* We will use the **variance** word when we are talking about **testing dataset**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4cf506ab-72bb-46fb-ab12-99d6ae543f37)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09ac86d8-7eb9-4ec9-a6a3-446782205280)

* Bias and Variance. [Overfit and Underfit] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05e9710d-db5e-44f8-9eab-ef8ed716d1b7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0ac8a61d-e05a-4865-87dc-835b8eb3eff9)

* For the **Good Ft/Robust** we will have **low bias** and it also has **low variance** as well. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a0bb6a8c-42fc-4513-aaa1-4f81ff96a027)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/45fe1e48-59dd-4d83-97a3-d23843132a71)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac4fdeaf-8077-4c8f-92a7-c08f93da045c)

* Option **D**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5e3ac8b3-b756-4d19-90e9-b9140ab55c22)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5f370763-b147-4ba3-b0b1-135724c4c8bb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47dae788-f46f-4ab9-9f05-8a9851380200)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/505f7b98-fe2b-4320-b2af-57b299aae1d8)

* Option **B**.
* Depends on the **slope(a)**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dca222c7-2f64-4fe2-977a-99ebe9a7c2cd)

* Question
* The model is doing **Underfitting**.
* **Higher number** means **better results**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b0f33fcf-6bf7-4dc5-be6f-6ab5d5cb86a2)

* Question
* The model is doing **Overfitting**. [**IMPORTANT**]
* It is because we are getting **more accuracy** in the **training dataset** and we are getting **significantly less accuracy** in the **test dataset** which is the sign of **Overfitting**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3657eeb2-9741-4eae-8c64-851fdd288a6e)

* Question
* The model is doing **underfitting**. [**IMPORTANT**]
* It is beacuse the **training and the test** error percentages are too **high** for the model to be any usuable.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b143343e-689e-4a5d-ae92-976bdae9af7e)

* Question
* The model is doing **Good fit/robust**. [**IMPORTANT**]
* It is beacuse the **training and the test** error percentage are almost identical which is **less than 1%** difference in between them and the percentage of error overall is less than **5%** which is very impressive.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ff74fb2e-2198-4ba3-9eb2-90aade355be6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4e96a253-068f-421b-ad5a-6f73256d5098)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b2418635-bcd0-42f8-a171-25fe28c83430)

* Example. [**VERY IMPORTANT**]
* As there are based on **error %** so we choose the **lower number** being **better**. [**IMPORTANT**]
* If they were given based on **accuracy %** then we choose the **hgher number** being **better**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f1eab0cf-89db-4b60-aa8b-2537366fd655)

* Example.

## regression-classification-part-iii (4)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2878900e-f064-4639-821c-399ec1c38140)

* In **underfitting** we focus on **high bias** more than the **high variance**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fe5936d4-5899-4c5d-b727-e619a22eb5af)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/82e0c812-bda6-4323-80fc-8026c10ef3b5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/43da1641-b94e-4119-b924-267445629543)

* Outlier [Examples]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1ca70cb9-e3e8-44e7-af58-7a29a08ccc8b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/18f1b2eb-e837-43fc-92c2-d1f51e587141)

* Multicollinearity.
* The more no. of **features or variables** there in the **data points**, the **accuracy** of the model will be **less only**. If the **complexity** of the model is **high** then the **model accuracy** will be **low/less only**.
* If the **complexity** of the model is **less/low/simpler model** then the **model accuracy** will be **high/higher only**.
* If we **reduce** the **features or variables** then the **model accuracy** will be **high/higher only**.
* The **less** is the no. of **features or variables** then better is the **model accuracy** only.
* We can detect the **duplcate features** and **delete them**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d38f67ec-98a5-435c-b737-de3e3cd1c721)

* Co-related features. [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bc82f6c3-fce3-48f8-829c-491b3b78ea14)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1de2809c-a7fb-401f-a032-3f361fbe09fd)

* Correlaton Coefficient.
* Pearson's Correlaton Coefficient [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bca884eb-956a-4926-8b59-0846eb5262ca)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/30213b02-26ab-4325-acd6-6403ed3cec46)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/32bb553b-86ef-464e-a5d4-e845e060c467)

* Correlation. [**VERY IMPORTANT**]
* The model wants to see out of all the **features** which **features are correlated**.
* The model can easily identify the **highly correlation** features.
* To find the **correlation** values then we have to use a **formula** for that.
* **0.6** closes to **1** so it is **highly positive correlated**.
* **0.4** closes to **0** so it is **highly negative correlated**.
* **0.5** will be considered in **low positive correlated**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e6398c7d-13b0-4c8e-8d59-557f2f698bf3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d39d9c82-0443-4ed2-af76-e511e3543850)

*  Pearson's Coefficient Correlaton(r) -> This **formula** is used to find the **correlation** values** we studied **above** [Formula] [**VERY IMPORTANT**]
*  **n** is the **no. of data/values**.
*  To calculate the **Pearson's Coefficient Correlaton(r)**, use the **above formula** than the **below formula**. Below one is **time consuming**. Still **Learn both**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c37d57d4-c30e-40c9-9484-2667f272556a)

* Cov -> Covarience [Formula] [**VERY IMPORTANT**]
* Var -> Variance.
* **n** is the no. of elements/data/dataset.
*  Correlaton Coefficient(r)
*  Standard Division(Sigma) from **maths**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/50c79e2f-02f3-4826-aa8a-1398d3b054f1)

* Question [**VERY IMPORTANT**] [MSQ]
* We have to use the **above formula** which is **Pearson's Coefficient Correlaton(r)** for this **question**. [**IMPORTANT**]
* We have to apply the **formula two times**, so it will be **time consuming**. So trying to do with the **graphs**. [**IMPORTANT**]
* If exact value was asked then we had to **compulsorily** apply the **formula** and find the **values**. [**IMPORTANT**]
* As **exact value** is not asked in the question, so we can use **graphs** and try to find out the **answers** of the question. [**IMPORTANT**]
* The **correlation** between **X and Y** is **0.9** which is **high positive correlation**.
* The **correlation** between **X and Z** is **-0.5** which is **low negative correlation**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b7869f7f-7a10-43e1-965c-83d17baeaf54)

* **X-Y** correlation.
* The **graph** clearly shows that it is a **high positive correlation**.
* Option **A** [Correct]
* When we are making between **X-Z**, in the **Z** column the values are **decreasing** as we go down the **'Z' column**. The values are **decreasing** so it is **negative**.
* So we will look at option **C and D**.
* Option **C** is **incorrect** as we already know that **Z** is **decreasing** which means it is **negative** and not **positive**. So,

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e9ae74fb-f2d8-43e6-a550-1946133958a3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7338a4b-5cdb-4b8b-80eb-9c92328dd587)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/817977f9-c829-4fdd-b369-43f4e006ccc2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7af236c-5e04-4648-8a81-499a24196113)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c3e53e43-8060-44b3-a8b5-f9c84ddd9b4d)

* Option **D** [Correct]
* Option **A and D** [Answer] [**VERY IMPORTANT**] [Practice it again]

## Regularization

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f6c91ee6-7cd5-4d0f-8897-758ed357b0b2)

* **Regularization** is a technique which is used to **overcome** the problem of **overfitting** and **feature selecton**. [**VERY IMPORTANT**]
* **Feature selecton** indirectly reduces **underfitting**. [**VERY IMPORTANT**]
* **Feature selecton** is removing **redundant features**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a0d398d2-8c88-4e30-86b5-116bb9e55c56)

* **Lasso** regularization is also called as **L1 regularization**. [**VERY IMPORTANT**]
* **Ridge** regularization is also called as **L2 regularization**. [**VERY IMPORTANT**]
* **Elastic Net Regularization** is also called as **L1 and L2 regularization**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/96bf3669-8b0c-45d5-9878-eb2deabde735)

* Outlier [Example]

## Lasso Regularization(L1)

* Lasso -> Least Absolute Shrinkage and Selection Operator.
* slop(m)
* n -> No. of datapoints/values/data.
* m -> No. of features(independent variables).
* Lambda -> Hyperparameter.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2729e918-5592-4b04-92d4-62993c2e18d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7fa1140e-841f-4f82-8fe3-21b89eb575b5)

* **Lasso** is used for **regularization and feature selection**. [Formula] [**VERY IMPORTANT**]
* The **formula** is the **addition of slope**.

## Ridge Regression(L2)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/46758f03-5133-4c31-8616-ae5a6e6020ad)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b3e2c954-629e-47a2-8c1e-21b6a02073fc)

* In this we add squared magnitude of the **feature/independent variable co-efficient** in the **cost function**.
* Cost Function -> ((1/(2 * n)) + lambda * (summation of (ai) ^ 2))
* The **formula** is the **multiplication of slope**. [Formula] [**VERY IMPORTANT**]
* With the **Ridge Regression** the problem of **overfitting** wll be **reduced**. [Formula] [**VERY IMPORTANT**]

## Elastic Net Regularization (L1 and L2)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/68a209ad-4b72-4530-8e45-16ab0928f25f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/196aa556-e3ad-4287-9b4a-d279d7232dff)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a198f8e8-7c72-428d-b92b-2699c5972060)

* Cost Function [Formula] [**VERY IMPORTANT**]
* Helps in reducing **overfitting** and also helps in **feature selection**. [**IMPORTANT**]

## Logistic Regression(Classification)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/651ea12e-8b97-4fd9-82a7-ff0c57b2da0e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4d78254b-3c30-4545-b51c-62545fbcb1f7)

* It is a **classification** algorithm.
* It will be like **boolean values** either **True or False** or **Yes or No**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1da91099-8b01-4c73-adb8-076c3fd3dfef)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/02a69560-78a5-4914-ae71-3f10b7d96f65)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/88570037-0d4c-41f1-8647-4ff7d5fe5444)

* Types.
* Classification means **class**. We have to find how many **classes** are there. How many different **class** are there or are made.
* Binary -> Two classes -> **True or False** or **Yes or No**.
* Binary -> Two classes -> Pass Or Fail.
* **Output** is **fixed** either it is **Pass Or Fail**.
* **Logistic Regression** works/based on **probability**. It cannot go out of the range of **probability**.
* We cannot use **linear regression** on a **classification** problem. The range cannot go beyong the **linear**. [**IMPORTANT**]
* In **probability** the **max** value is **1** and **min** value is **0**. The **output** should lie between **0 and 1**. It shouldn't go beyond that.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b2899b6-ce94-4dc4-bb92-4e443723b37a)

* Example

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d9ee3614-ab6e-45da-bbc7-4a217db0dd39)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4fb3fa28-3e9b-45b4-9e24-a7e61e1e2501)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/31e474be-65cb-4a38-88d8-9c69c211655e)

* Using **sigmoid** function we implement the **logistic regression**.
* **Binary,ternary** these type of **classifications** use **logistic regression**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed26c44a-b84d-4b7e-9fa3-0d3ab62271f4)

* Sigmoid function or logistic function.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c7761e9-2c51-4dbb-b62d-a52932a7742a)

* Sigmoid function [Formula] [**VERY IMPORTANT**]
* With the help of the **Sigmoid function** the output is between **0 and 1** only.
* We are making **probabilistic model** for that we need **Sigmoid function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8ffa21d7-3f62-4ade-a567-542232e8963e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8c405def-2c86-4c59-8479-0c62479dd38a)

* **y** -> Dependent variable.
* **x** -> independent variable.
* Theta0 -> Intercept.
* Theta1 -> Slop.
* **Theta0 and Theta1** value will already be mentioned in the **question**.
* Logistic Regression [Formula] [**VERY IMPORTANT**]
* **Logistic Regression** will tell either **one of the classes**, it will never go out of the **classes**. [**IMPORTANT**]
* **Linear regression** can throw us outside of the **class** as well.  [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7fbae368-04f5-4865-86d6-d8a46b27e1f1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b459f87-7424-4148-af03-f0b28920afc8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/043f5956-fd3a-4e42-a711-a977b8c358f5)

* Example.
* The name is **logistic regression** but it is working for **classification** problems. [**IMPORTANT**]
* To solve **classification** problems we cannot use **linear regression** algo. It is never possible. We have to use **logistic regression**. [**IMPORTANT**]
* The **sigmoid** function value is always between **0 and 1**. [**IMPORTANT**]
* The **outlier** problem will be fixed/removed using **sigmoid** function. [**IMPORTANT**]

## regression-classification-part-iv (5)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f05fd552-6db3-4f36-a5d5-a28b6a8ab522)

* Formula.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/abe81402-e169-431c-af97-9053ac45c8d1)

* What is the probability of pass for the student who studied for **33hrs**?

> It is obviously **one(1)**/

* Study hours(x) is the **independent variable**.
* **Pass/Fail(y) is the **dependent variable**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/96052f17-d60f-4208-b928-18a5f3043b05)

* Solution [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cc8f006a-986d-4dfd-a6c0-b77663cfc2b8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6361664e-e759-4d23-b8db-e0520d6f3810)

* The probability of chance that the **student** will pass with **33hrs** is **0.88 or 88%**.
* Answer -> 0.8 or 88%,

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0fa4e6ba-b441-4a11-9550-267937baa442)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5ae30908-ea9c-4b36-b36c-69a0d2af13e7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/28dd21eb-d473-43c5-86a9-446e862afacc)

* Solution [**VERY IMPORTANT**]
* hours -> 33.47hrs.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1ba696f5-d5d9-4fc7-b86c-0e40dd1300f5)

* Logistic Regression [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4f04d136-16c0-466c-9aa4-28985162a99f)

* Cost Functon of Logistic Regression [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/749781ae-26dd-4c93-9581-a678760a2331)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6d0321ba-31bf-4ca7-a079-6792f117585b)

* We will not get **global minimas** we will get a lot of **local minimas**.
* The reason we don't use the **above formula** which is the **cost function of linear regression** because we get **multiple local minima**.
* To remove the **above problem** we use the **Cost Functon of Logistic Regression** formula.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6c3bbdc-e17c-4b7d-b915-80f42cc49037)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fdd56780-4b15-4628-bfc9-98331d9a961e)

* ln [Example] [**IMPORTANT**]

## KNN

* K-nearest neighbour.
* It is both a **classification and regression** algo.

### KNN classification

* classification -> classes.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4b63db97-42f3-401c-a32f-da94a0d31505)

* **x1 and x2** are the **features**.
* dot(.) -> Class 1
* plus(+) -> Class 0.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ed30cde-9f74-41c5-945a-b69aa5f0b0fd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb700c2f-d2a2-40f6-be3e-99ca94fd12c8)

* **New data** has been given and we have to find out with the help of the **data** what will be the **class** of the **new data? We have to identfy it. It is not given. [**VERY IMPORTANT**]

> Let say we have **k = 4** neighbors which means around the **new data** it will take the **4 nearest neighbors** from it. It will identify the **classes** of the **4 nearest neighbors**. Let's say that the **1st neighbor class is '0'** then the **2nd neighbor class is '1'** then the **3rd neighbor class is '1'** then the **4th neighbor class is '1'**. The **class** which is **coming come in-terms of count** then we will just consider that partcular **class** as the **class** of the **New data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/12dcc7ec-ad10-4a74-a675-e80081da1102)

* To calculate the **distance** we will use the **Eucledian distance**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/33c695b5-cc59-4541-a556-a2072aa036e9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/477accc2-2d42-43ed-b7e3-988bb72a48ac)

* **Eucledian distance** [Formula] [**VERY IMPORTANT**]
* **Distance** between **P and Q**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/46bf35bf-8cc9-445f-97ff-0ada62208c40)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1cbfab33-d238-4ba1-82c2-c94206243c49)

* As **K = 3** so the **3 nearest neighbors** are **2.5, 3.04 and 1.11** and their **class** are **0, 0 and 1**. So the **class** of the **new data** is **class 0**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cbb574d-b747-4a99-b75e-a513fb3e96ca)

* Answer -> Class **0**. [**IMPORTANT**]

### KNN regression

*  In which we 1st find the **K-nearest neighbor** and then find the **average** of their **output feature/parameter**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f419daa8-d4b9-46ea-af11-29781eadcea1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/10bbe3b5-ae69-4fba-83d1-be76e9f78813)

* We have to find the **average** in **regression**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fed23a5c-9c52-47c6-adf6-22afecca7ee3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/13639a84-ab14-4324-b11c-152b0b64baca)

* Example.
* **Distance** can be **same** because the distance can be mentioned equi-distant from each other.

## Performance Matrix

* Normally used in **classification**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0edf0b8d-2414-4ea7-b504-5141b60fdaa1)

1) Confusion Matrix -> We will calculate **accuracy, precision**.

* 1 -> Yes
* 0 -> No.
* We are counting how many times we have actually gotten **Actual '1' and predicted '1'** as well. **3** times.
* We are counting how many times we have actually gotten **Actual '0' and predicted '1'** as well. **2** times.
* We are counting how many times we have actually gotten **Actual '1' and predicted '0'** as well. **1** time.
* We are counting how many times we have actually gotten **Actual '0' and predicted '0'** as well. **1** time.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3ffe248a-3949-47c7-be92-5a00926c1d21)

* The **Actual '1' and predicted '1'** and the **Actual '0' and predicted '0'** are the **cases** where we should get exactly **correct** answers which means whatever **class** was there and the model was able to **predict** that class.
* Correct Prediction -> 3 + 1 -> 4
* Total Cases -> 3 + 2 + 1 + 1 -> 7.
* Accuracy -> Correct Prediction / Total Cases -> 4/7 -> 0.57 -> 57% [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c71b09c-e4f9-41b7-a1f2-875afb26cf70)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0b7a3fbc-be26-4688-9644-15ea310a7310)

* Calculated the **accuracy** parameter. [Example]
* Only with the **accuracy** parameter we cannot analyze any **model**. Maybe some data is **wrong**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/de58966d-2697-40e7-a6cd-81f26fc327eb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/691660b1-5073-4171-bf87-b5ee76948c77)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b980e907-06d9-4ec7-ae34-ba4b83e3d38a)

* **Point 2 and 3** are the **predictions** which we want.
* We will try to reduce the **false positive(FP)** where the mail is **not a spam** but the model predicts it as a **spam emal**. [We will try to reduce these case]

* Spam = 1 -> Positive
* Not Spam = 0 -> Negative.
* TP -> True Positive
* FP -> false positive
* FN -> false Negative
* TN -> True Negative

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/39167ad1-5268-4f67-b317-10cca20d167a)

* We want to reduce the **cases** where the mail is **not a spam** but the model predicts it as a **spam emal** which is called as **false positive(FP)**.
* We want the **false positive(FP)** to be at the **minimum**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/72e3d3ef-7c5f-4ef8-8c90-a52243ab0141)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9359d9b0-9410-4b07-a49e-3463f1ad36c5)

1) **Precision** -> TP/(TP + FP) [Formula] [**VERY IMPORTANT**]
2) **Recall** -> TP/(TP + FN) [Formula] [**VERY IMPORTANT**]

* We have to focus on which value has to be the **minimum**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/03d22345-778a-49fd-9668-fc3333c0f9e5)

* Example.
* In the **medical field** there should be **no False negatives(FN)**.  [**IMPORTANT**]
* It will vary from **one field/area**.
* In someplaces **FN** would be more important and in someplaces **FP** would be more important. [**IMPORTANT**]
* Maybe in some fields both the **FN and FP** are  more important.  [**IMPORTANT**]

### F-Beta Score

* We want to focus on both the **FN and FP** as they are more important in a **particular field/area**. [Both of them should be **minimum**]
* In that case we will use **F-Beta Score**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/28688c72-2047-4359-962e-779f2d804042)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/141a5554-bcec-47e8-b241-cdc498d9050d)

1) If both the **FN and FP** are **more important** then **Beta = 1**:-

* F-Beta Score = (2 * (Precision * Recall))/(Precision + Recall) [Formula] [**VERY IMPORTANT**]

2) If **FP** is more important than **FN** then **Beta = 0.5**:-

* F-Beta Score = ((1 + (0.5) ^ 2) * (Precision * Recall))/(0.5 ^ 2) * (Precision + Recall) [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/55895ded-e3a3-4f73-a46f-7b87413523d7)

3) If **FN** is more important than **FP** then **Beta = 2**:-

* F-Beta Score = ((1 + 2 ^ 2) * (Precision * Recall))/(2 ^ 2) * (Precision + Recall) [Formula] [**VERY IMPORTANT**]

* We are trying to **minimize** the problems.
* **TP and TN** are the **good** cases.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/62c0324f-acf0-4ec5-b198-3060fac701e1)

* Actual
* Predicted. [**IMPORTANT**]

## Naive Bayes Classifier

* It is on **classification** problems.
* x1, x2, x3 -> Independent variables/event
* y -> dependent variables/event.
* c1, c2 -> Different classes.
* **Event** because we have **probability**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/52ed0cfa-5ef6-4be0-a374-6fe9219cda03)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/376d3a63-84d9-4d1c-af2e-7a860f27f5ab)

* Next class.

## cross-validation-part-1 (6)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d659948d-9c0f-4f13-83d0-8a006c9b4ef2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/475ce4ad-353a-4ee6-b010-f70901c29fe9)

* Classification Algo
* Category -> Class.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f69dbb4f-7cc3-4178-86dc-23cec817e191)

* Applications.

## Naive Bayes Classification

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/70e11ddd-f3cf-4204-8819-9043238ddeff)

* Naive Bayes Classification
* It works on **probability** of an object.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5b000ee6-576c-4c57-a140-7c90d0806b82)

* Why?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d7f5c6ea-f5d2-4521-babe-cc1917d85c09)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5e30d5e5-33b2-49f1-a41e-9c07847311be)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2577b6f4-dd57-4614-9989-ba06c2f7712f)

* Bayes Theorem Probability. [Formula] [**VERY IMPORTANT**]
* P(A|B) -> Probability of **A** given **B**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0bc66590-5740-47fa-862e-8136bd5f5bd3)

* Working.
* **x1, x2 and x3** are **independent variables/events**.
* **y** is the **dependent variables/events**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/00532104-29c2-4dda-95fe-b2a1911fd1db)

* The **output** is classified either it will go to the **Yes** class or the **No** clas. There are **two** different classes.
* No. of Class -> 2 (Yes, No)
* No. of feature -> 3 (x1, x2, x3)
* Datapoints are now **4**.
* No. of value of each feature -> 2

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac3e32d9-630d-4fc4-a0db-c6ac1e5c9943)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/346338e0-2b69-48b0-b59d-f315d3535094)

* The **no. of classes** we have that many we have to **calculate**.
* VDK + K
* V -> Samples
* D -> Value of that Feature.
* K -> Class

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bcce578e-bbf1-4b35-9318-d462f2b19166)

* Total cases -> 12 + 2 -> 14.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ab1b2915-bd24-4d2e-b583-dde5d8badaf3)

* Formula [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e446e49d-5b8f-433e-ac94-1b0a82787994)

* For every separate feature there is a **table** for it.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/97f321ac-54d2-4a42-8301-f4a140cf82c4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6ee8dc5b-3fbf-4486-896f-d064e79140c7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/edd228a4-7479-4bdf-a7f6-51ea24ba64de)

* We have to predict the value of dependent variables.
* Probability of **y**, P(y | Sunny, Hot)
* We will solve by **removing** the denominator because **denominator** is the **common part** and it will get **eliminated** eventually and we want to calculate both the conditions.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7c506fbc-c884-4bcc-921f-38813f061108)

* The total probability of **Yes(Y) and No(N)** doesn't add upto **1**. It should be **1**. For these reason we have to calculate for **Yes(Y) and No(N)**. Those are not **normalized** value. We are doing **Normalization**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bcb44e5a-9079-4bb8-ba0e-665121463bda)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/47b2878f-e240-4cff-832f-7e5780c98569)

* Now **Yes(Y) and No(N)** add upto **1**.
* We will go to the **No(N)** class because it has **higher chances/probability**. [**VERY IMPORTANT**]
* We are using it to predict the **classes**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/75c46a47-b89b-46b3-8b42-7140d8c615e0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b26a6026-8147-41aa-b722-34cab50fc4d6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2182ce82-e8ef-42cd-b329-27556fbe4cb9)

* **5** places have **Sunny** and the total no. of places is **14**.
* P(Sunny) = 5/14.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/41ad9a96-910e-47e9-8e37-8a78f8893aec)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cce5b71a-3a6e-4f0e-b6fe-c7691309372f)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/22a94a9f-6fb2-45c2-9e24-1c2aaa51f94f)

* f1 -> 6
* f2 -> 6
* 6 + 6 -> 12
* We also have to find out the **P(C1), P(C2) and P(C3)** which is **3**.
* Final is **6 + 6 + 3 -> 15**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/879017b2-e7f4-464b-a514-cc085c5ed06b)

* For the values of **D = 2, V = 2 and K = 3** we are getting **15** as the **answer**.
* Now check which option is giving **15** by inserting the values of **D, V and K**.
* D = 2, V = 2 and K = 3
* (V ^ D) * K -> (2 ^ 2) * 3 -> 12 [Incorrect]
* (k ^ V) ^ D -> (2 ^ 2) ^ 3 -> 4 ^ 3 -> 64 [Incorrect]
* V * D * K + K -> 2 * 2 * 3 + 3 -> 15 [Correct]
* K * (V + D) -> 3 * (2 + 2) -> 12 [Incorrect]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7930410-2044-4d62-84e4-a5783c44516a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee26108e-0de1-478b-9417-2cd6daac8dce)

* Option **C** [Answer] [**VERY IMPORTANT**] [Practice Paper Question]
* We didn't take **K = 2** then option **D** would have given **8**, we wouldn't be able to **eliminate** the options. That's why took **K = 3**.
* We will **reject** the others.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6a510f8a-1f68-4f86-8bea-57a5099035d2)

* Take an **example** and try to solve the **question**.

## SVM

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/268e1d0b-15b9-4b37-9d65-63d3b6bc46fd)

## SVM Classification

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7d5fa103-c329-49f7-bf9d-9caafc10d0a1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05e67e14-3491-42cd-917d-2bc5814ab863)

* The **line** is called as the **hyperplane**.
* The **points** are the **vectors**.
* We have to draw the **line** in such a way that the points/vectors get **max. margin**. That **line** we have to draw.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/86a28a03-d923-4355-aa57-177f3fd05419)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/647d346f-3715-4c0b-98be-e371d9304f4d)

* We have **two lines**. Which line is the best?

> The line which is properly dividing the vectors then that line is the **best line**.

* To select the **best hyperplane** we have to find the **max. distance** between the nearest data points on either side of the **hyperplane**. The distance should be **max** then that **hyperplane** is the **best hyperplane**.
* Between the two lines which line is the **best** and for that reason we are looking at **margins**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/954fcb79-e4c4-4fe8-813e-04eb5c51d8c0)

* The inbetween distance among the **margins** should be **max.**.
* Distance between margins should be maximum.
* Marginal Line.
* Maximum margin from nearest data point.
* If we have drawn the **best hyperplane** and the **vectors** helped in making the **best hyperplane** are called as **support vectors**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/67d85eab-803f-416b-bb78-e7ca482c0c6a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a030210d-e4eb-49d8-9da5-8b69b76d1dbe)

* The data points are called as **support vectors** through which the **margin lines** are passing.
* **Support vectors** are those **data points** which helped in making the **margin lines**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a2a68030-2bad-4b08-9f0a-f84765f0cc5b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cfebbd0a-d101-47a2-ad5f-3b76bc884c68)

* **G1 and G2** are **Two margins**.
* **B and D** are the **hyperplane**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9236e739-8d10-4a65-92c3-736d17dd999d)

* Which hyperplane is better **B or D**? [**IMPORTANT**]

> We can see that the **Max. margin(M1)** in **'B' hyperplane** is **more/greater** than the **Max. margin(M2)** in **'D' hyperplane** which is **M1 > M2**.

* We have to consider the **noise/errors**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fe0f033d-8d37-44f1-b393-40f5ad9cfe02)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb6daf35-bde1-4648-b38f-b471055f11dc)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b06d599-4452-4afb-ab4b-2950ae69d716)

* Soft and Hard Margins.
* Hard Margin -> No errors we can tolerate and the **margin** should be **maximum**. [Not Practical]
* Soft Margin -> Some errors we would tolerate but the **margin** should be **maximum**. [Practical]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6b114003-f52d-42f3-95d0-c2ff7974a756)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/765c8a74-519f-4a32-a8e0-c86569ff0326)

* Support Vectors.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/de5fd71a-7a7f-45f0-8463-65b5940bf1d4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/92879a98-224f-400f-a682-6cbcdd98fa83)

* Hyperplane

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ccf26713-b640-41d3-865d-df4124db3438)

* Comparisons.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/59711f7b-3eb1-4ba1-bffd-dd362a584a93)

* Degree of tolerance.

## cross-validation-part-2 (7)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6934661-c0e4-4c36-9774-c6e13541a93f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/80220033-b5e7-45b3-bcf8-8c421397f6cb)

* Hyperplane [Formula] [**VERY IMPORTANT**]
* W1 and W2 are **slope**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5cbda122-0a49-40a2-b8d7-113098e7b143)

* Degree of Tolerance.
* * **C** is a **hyper-parameter** and the value of **C** represents the **count of misclassified points** we are allowing .
* We cannot allow/take more than the value of **C**.
* If it is more than the value of **C** then the model is not perfect for that particular data.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9c9d15c6-a9e9-4cb7-bf10-57764a8edcc8)

* According to the hyperparameter(C), we will allow that many **misclassified points** as is the **count/value of 'C'**.
* If **C = 50** then we can allow **50 misclassified points**.
* The **greater** is the value of **C** the higher is the penalty for the **SVM** when a **misclassified points** comes.
* Degree of Tolerance -> How many **misclassified points** we will allow in the **SVM**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9a4c1281-d4ce-423e-b639-0815174dae74)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7776fbd2-83e1-4ff8-ab5c-461e3131b588)

* The line we are making for the **margin**, there is a **positive and a negative side**.
* The points on the **hyperplane** are on the **positive side** then they are in **one class say 'C1'**.
* The points on the **hyperplane** are on the **negative side** then they are in **one class say 'C2'**.
* It is a **binary classification**.
* We ar considering the points on **positive and negative side**.
* Some vectors/points are given directly and we are asked to create a **hypeplane**?

> We will say that some points lie on **positive side** and some lie on the **negative side**. Between the **positive and negative side**, the **hypeplane** is created.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1075687e-ff65-4bba-972b-8bea7d2c5ddd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/943594d9-6024-4990-968a-e42d7a1c9850)

* Explainations.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0f13b5ce-ffbc-4779-a33e-08d5b458e97e)

* We want the **max. margin** between these **two lines**.
* The difference between the **two lines** should be **max**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/66c6e076-9554-42b4-85c0-d09ae33d3656)

* W ^ T -> Transpose Value.
* **k** is any **positive integer**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9210869f-f7ec-4054-806e-df10756b24a0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9049212a-5f4f-444e-aaa5-1e6abcb2ebb3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/385f20f0-2dd0-41bf-abb2-69be06df86e6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac837fbd-92c6-42d1-bf38-09a21e144f96)

* The difference between the **two lines** is **2/(|W|)**. We want to **maximize** the **difference** which is **2/(|W|)**.
* **2/(|W|)** will be **maximized** when **|W|** is **minimum**.
* The distance between the **marginal plane** is **2/(|W|)**. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cf32bb56-3a3f-48d1-b65f-2aa08d9ed1f1)

* Cost function [Formula] [**VERY IMPORTANT**]
* We want to **maximize** the **2/(|W|)**. In terms of **cost function** we want the equation to be **minimized**.
* So we need to **minimize the **(|W|)/2**.
* We always want the **Cost function** to be **less**.
* We can say that it is a **perfect line** and we are not creating any **misclassified points**.
* We have some **misclassified points** and have to calculate the distance of them from their **margins**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ae67b18a-e4ca-4bb7-bec5-6161ba4c959c)

* Explaination.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c7e63f78-a0e7-48c2-95eb-b1aeaf306055)

* Maximize and minimize.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ee3da0d-fc5a-4443-b6cd-bcaf23fe5e2f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/88bdd9ce-c881-438e-bb7f-4d08d312d004)

* We have to calculate the distance of all the misclassified points.
* C -> No. of misclassified points.
* Eta -> Distance of each misclassified points from **margin**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bbcafec1-7250-458b-8021-38af650a0b27)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/483642d7-6cbe-4f33-acc8-bf3b4c7058d1)

* We want to **minimize** the **cost function** equation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e12a6228-6836-431f-83e6-74a7b8bacb24)

* Which is the **best line**? Which one is to be considered? [Example] 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/35d92780-61ae-4258-8de7-67f49b5fe642)

* Hyperplane -> a1 = 2, a2 = 5
* Hyperplane -> a1 = 20, a2 = 50
* With the help of the **coefficients** we have calculated the **value**.
* **H1 and H2** are nothing but **|W|** only. H1 = H2 = |W|

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7b85fb18-51f5-448c-b917-c198c5e6519e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fb4fda21-c1b5-4e8a-ad80-2cb565f011f7)

* **0.37** is the **distance**.
* We need to take **H1** as the **best line**. [Solution] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fc41b475-0e4a-4d94-8762-13eb2c233cce)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dc18de42-78bf-4ca7-adfa-73dc12b0a6d9)

* Example
* **Positive Class** means that the **points** are **ahead/above** the **hyperplane**.
* **Negative Class** means that the **points** are **behind/below** the **hyperplan**.
* We can get the **Positive and Negative Class** as well.
* We have to identify the **support vectors** in both of the **classes**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d077689d-d423-4ac2-8c1b-86c7ef889d7f)

* We are plotting the points on the graph.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/61951885-9201-41b3-baa4-c6c987aca2ab)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/78375333-5985-4fc1-87b3-64e803349432)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c05e31d6-6835-496f-a5c5-060705c18e39)

* We found **three support vectors**.
* We need to find the **hyperplane equation**. We need those **three support vectors** to find the **hyperplane equation**..

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d806d5e5-7c38-4fe3-b9e2-1abe58d87339)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/af356f86-c206-4686-9d20-81f231cd48d1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/02609925-5d88-483c-bf0f-357c38803798)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/886860b9-34a0-4093-ab09-16120d77bc2b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2508ea6-4d20-4728-b3c0-4bda1ba2fd3e)

* We **biased(bias)** the vector. We added **1** at the end of each vector.
* We added **1** at the end of each vector because we want to find the **intercept(C)** also.
* As we have **three vectors** so we will have **three equations**.
* We have to solve those **three equations** to calculate the **co-efficients**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e2dffa08-958f-4466-876f-0e47ce58ea67)

* The value of **a1,a2 and a3** will tell us at the end what will be the **line**.
* **a1,a2** -> Slop
* **a3** -> Intercept.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ac8a637d-668e-4465-adf3-8991c3948294)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1d5466b9-9c5d-4039-9752-58b7f5da453a)

* y = (W ^ T) * x + b
* (W ^ T) -> a1, a2 [Slop]
* b -> a3 [Intercept]

* We are talking about the **1st vector** which is **S1' -> 1, 0, 1**. In all of three vectors we will multiply with **S1'**. As it is **1, 0, 1 -> 1,0**, it belongs to the **negative class(C2)**. As it is from the **negative class(C2)** so we will write **-1** on the right side of **equal to(=)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2841b542-29bf-4081-bb9a-706d7626272e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cd0a477-0dfb-4aa5-97fd-6f6ce541fd1c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7ed67f86-db15-4b31-b796-dd48f867b4a1)

* We are now calculating for **S1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3485274c-2611-4171-a0ea-c6eb48682b6f)

* Vector multiplication. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/44bbeea6-a6a7-4347-b628-eab830be4d5a)

* For **three variables** we will get **3 equations**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/74b48faf-c173-4306-9f58-b11d530ff348)

* We are now calculating for **S2**.
* We are talking about the **2nd vector** which is **S2' -> 3, 1, 1**. In all of three vectors we will multiply with **S2'**. As it is **3, 1, 1 -> 3, 1**, it belongs to the **positive class(C1)**. As it is from the **positive class(C1)** so we will write **+1 or 1** on the right side of **equal to(=)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3eb8c7f4-587a-49f5-aaa7-783e113f70d0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/66af7552-3ed9-4754-b465-0f65df833753)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/64109fa8-49e4-4580-b164-daf0e22ec36d)

* We are now calculating for **S3**.
* We are talking about the **3rd vector** which is **S3' -> 3, -1, 1**. In all of three vectors we will multiply with **S3'**. As it is **3, -1, 1 -> 3, -1**, it belongs to the **positive class(C1)**. As it is from the **positive class(C1)** so we will write **+1 or 1** on the right side of **equal to(=)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/78f583b5-7197-4b12-b58c-f8340856ac11)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5cc76688-5230-4f47-8d69-9804d29a5f15)

* Equation **III** is correct only.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2cc4ee31-ebd5-40b9-b709-7069c1b5df8f)

* Equation 1.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7dacaa8c-7b9f-4c75-aa71-6f09e13f2af5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/74e24d5d-ce1f-47b9-9449-2cd82b966a0e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f7ccffa8-7fa7-486f-8cbe-916b6e484351)

* We got the values of **a1, a2 and a3**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c8e1bff-dd0c-4927-8c04-086f71ba0069)

* Original vector was of **two points** only and we added the **bias** for the **intercept**. So the Original **two points** are the **slop**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/be1e0e53-f963-4e77-8a72-abf21d7534c7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bb75f9c7-88fe-40e4-8486-aa386c06fc60)

* x = 1, y=0.
* As it is **x,y -> 1,0** so the **line** will be parallel to the **y-axis**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1f4849bd-da27-486d-9716-162dca5114ea)

* **-2** is the **distance**.
* b = -2

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cdb1e6d-6fa7-47f5-85a9-3070e1d96996)

* It means that we have to take the **line** at a **distance of '2'**.
* The line is parallel to the **y-axis**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a78af763-71a6-4886-a46a-78f9dd57d0f7)

* Found the **hyperplane**. [Solution] [**VERY IMPORTANT**] [Numerical] [Practice it again]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8be67ff7-12ef-495a-b118-74f454cb2072)

* Representation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/887dae2d-d657-422f-833d-09978419c44d)

* To solve the equation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/35a378fb-c60a-440a-9fe6-de2a19a1068d)

* This is the **generalized equation**, we have to use it everytime for any vector. [Formula] [**VERY IMPORTANT**]

## Decision Tree

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e10c4712-6ac3-4c7d-9cf1-05157d5468d6)

* Decision Tree

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cadaaa85-bc65-4184-b174-d02cd8af3d3b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/58e56276-0e54-4983-bac9-ee0253fc7554)

* **Leaf node** is telling/showing the **output/dependent variable** which means that it is showing which **class** it is belonging to.
* **Internal node** is telling/showing the **feature/independent variables**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a05cd20b-ca5c-458d-a9b8-3394ac386f36)

* Algos.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/16cf79f4-2af2-42a4-9567-bd9cb76e0b6d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4f46e8a3-e39f-4c94-ac4e-b28f429e3191)

* Example.
* On **every node** in **every level** we have to take a **decision** whether we have to go to the **left side or the right side**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09a92b7b-a7ed-464b-8a12-1ccfe34c9199)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/82a48886-23f1-4cab-acb7-67ad2a8d0e50)

* Example.
* Class ended abruptly.

## artificial-neural-network-part-1 (8)

## Decision Tree (Classification)

* **x1 and x2** -> independent variables.
* **y** -> dependent variables.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c5bfd4a6-9cd8-4599-ab7e-504f992840b1)

* We will calculate the **entropy** of every node.

## Entropy

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a4c925d0-6cda-4e7d-87c5-6ba293de5e2d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7715115e-5476-4b8a-9d0b-f2b9f45245f4)

* Entropy formula [Formula] [**VERY IMPORTANT**]
* p(x) -> Probability of that particular node(x).
* Entropy -> S() [Representation]
* We have **True '3' times** and **False** also **'3' times**.
* Take either class as **positive or negative**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6c30e2a5-510a-4c4c-b7d9-b9b963f28ed7)

* S(y) -> Entropy of the complete data.
* Probability of P(True(T)) = 3/6 [P(y)]
* Probability of P(False(F)) = 3/6 [P(y)]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0a8fe61a-2808-43b3-9df6-949b335f4771)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3c530e74-b620-43da-b30d-f572bb9ba4fc)

* We calculated the **Entropy of the complete data** which is **S(y)**.
* We also have to find the **Entropy** of the **individual data**.
* **x1** feature/independent variable has two variables(a1 and a2).
* We have to find the **entropy** with respect to the **output** variable only.
* True -> Positive Class.
* False -> Negative Class.
* We have **'3' times a1** in **x1** and we got **2 times 'True' and '1' time 'False'**. So **a1** is going to the **positive class** for **2 times** and to the **negative class** for **1 time**.
* We have **'3' times a2** in **x1** and we got **2 times 'False' and '1' time 'True'**. So **a1** is going to the **negative class** for **2 times** and to the **positive class** for **1 time**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9d25c6fb-c218-4d5c-a02b-e4aa2083262a)

* We have calculated **entropy** for individuals in **x1**.
* Out of all the **datapoints**, in **x1** we have **'3' a1's and '3' a2's**.
* Probability of **a1** in **x1**, P(a1) -> 3/6
* Probability of **a2** in **x1**, P(a2) -> 3/6
* S(a1) -> Entropy of **a1**.
* S(a2) -> Entropy of **a2**.
* Total **a1** with respect to **x1**.
* Total **a2** with respect to **x1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cf4136b7-829d-46af-86a2-3171734d7dc8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/20826819-e042-4737-9cd0-94d52720ade0)

* Gain(X1).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6c5229a-9e37-4041-a71a-2e9745b98ebf)

* X1
* Now we have to find for **X2**.
* **X2** has two class which are **b1 and b2**.
* **b1** is **'4' times** and we have **'2' times 'True** and **'2' times 'False'**. We have **equal distribution**.
* Whenever there is **equal distribution** then that is the  **best case** for **us**. Whenever we solve for it we always get the **entropy** as **1**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a9b72799-c3c2-4c73-a7d8-076a190bf5f5)

* **b2** is **'2' times** and we have **'1' time 'True** and **'1' time 'False'**. We have **equal distribution**.
* Whenever there is **equal distribution** then that is the  **best case** for **us**. Whenever we solve for it we always get the **entropy** as **1**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a9e11e08-705b-448b-b35f-ede3b7b9eb7a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4e597fb1-e09b-488d-b41c-300cbb6cfbc9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8feacf90-1edf-4b10-bf39-ecbcb9f7ae43)

* Entropy for **X2**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c1861cbe-01bd-4f74-8d8b-b030978777ff)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/50fa32d6-1213-4e7c-8917-c34cbad14bb9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8445f337-33f8-40fc-a515-58d16e7795e7)

* Whenever the **entropy** is **1** which means that there is **100% change of inpurity** or **impurity is high** **completely/complete impure**. [**IMPORTANT**]
* Whenever the **entropy** is **0** which means that there is **100% change of purity** or **completely pure** or **pure**. [**IMPORTANT**]
* Probability of **b1** in **x2**, P(b1) -> 4/6
* Probability of **b2** in **x2**, P(b2) -> 2/6
* S(b1) -> Entropy of **b1**.
* S(b2) -> Entropy of **b2**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/779f5794-3826-4ac4-aa44-e366abe3a30d)

* Gain(X2).
* **Gain** means **information gain**. [**IMPORTANT**]
* The **higher** is the **no. of Gain** the **more amount of information** we are gainng. [**IMPORTANT**]
* The **Gain** in **X2** is **zero(0)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e0d919ca-eecf-4c7d-9de4-bce5e7218de9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/93aae590-f97b-4c62-9cc5-43aee75c8ad4)

* Select those **variable/feature/independent variable** whose information gain is more. [**IMPORTANT**]
* So **X1 > X2** which means we have to select **X1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/00e2b8db-ed0a-456e-8166-732d3ebf2f25)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/39d66266-98f0-4719-8382-60cff107e576)

* Decision Tree.
* As the **Gain** of **X1** is **greater** than the **Gain of 'X2'** that's why we put **X1** as the **root node** of the final **decision tree**. [**IMPORTANT**]
* Inside **X1** we have **two classes/features** which are **a1 and a2**.
* When it is going to an **individual class** then no need to expand further.

### Converting the base in logs [**IMPORTANT**]

* Link -> https://www.purplemath.com/modules/logrules5.htm

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f65abad5-c02d-4799-a885-3c0404015a26)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9b6072d6-9d43-4e70-a32c-0f2ad9186973)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1744e5d1-cf44-40ef-84e5-6e4e18755e3b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/72511f90-58b0-455d-90c2-1c3c85180f96)

* Conversion. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d3c99942-8b5e-4156-b640-d13a16eaeac3)

* Gain(). [Formula] [With Example] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/73b3ae01-39e7-4c3d-bc14-55db948a9555)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dcceb82a-fbe0-45fd-b2dc-c510321dc793)

* Question [Example]
* First we will find the **Gain()** of all the **'4' features** which are **outlook, temperature, humidity, windy**.
* **Outlook** will have the **highest Gain()** so **outlook** is the **root node** of the **final tree**. [**IMPORTANT**]
* **Outlook** has **'3' parameters** and we had written them. We wrote **Yes** in **overcast** and we will not expand it further as it is going to a **particular class** which is the **Yes** class. We will expand **Sunny and Rain** as they are not going to any **particular class**.
* We have **'5' times 'sunny'** in **outlook** and they are going to **'3' times in 'No' class** and **'2' times in 'Yes' class**.
* As it is **'3' times in 'No' class** and **'2' times in 'Yes' class** so we have to further expand the **Outlook** node.
* We have **'4' times 'overcast'** in **outlook** and they are going to **'4' times in 'Yes' class** only.
* **Overcast** is always going to the **same** class which is the **'Yes' class**. That's why we didn't further expand the **overcast** node and directly written **Yes** there.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8dd318b3-36bd-4129-85eb-41a5ebe727a7)

* The **decision** we are taking is that if it is **outlook** and it is **overcast** then we will **definitely play**. We don't have to see anything else.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fed88c79-bc3f-4431-93b3-684fe0b748a7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/76cbd8f9-9028-4f0d-b477-5aedfffafd04)

* When there is **equal distribution** or 50/50 change of whether we will play or not play. These type of **data** is **100% impure**. [**IMPORTANT**]
* In **overcast** we had **4 "yes"** which means it is a **pure** data. [**IMPORTANT**]
* As **sunny** was not going to a **single/particular class** so we expanded **sunny** and calculated the **Gain** values and the **highest Gain** was of **Humidity**.
* The features of **Humidity** which are **high and normal** are going to **single/particular class** which are **No** and **Yes** respectively. So no need to **expand further**.
* As **rain** was not going to a **single/particular class** so we expanded **ran** and calculated the **Gain** values and the **highest Gain** was of **Wind**.
* The features of **Wind** which are **Strong and Weak** are going to **single/particular class** which are **No** and **Yes** respectively. So no need to **expand further**.
* We didn't need to expand **temperature** because the tree has already reached the **leaf node**. [**IMPORTANT**]
* We are going to expand still the tree reaches the **leaf nodes**, it doesn't mean we have to expand all of the **features**. It is not necessary. [**IMPORTANT**]
* Whatever the **temperature** is, we will **play**. Indirectly we can say that the **play** is not dependent on the **temperature** feature.  [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/529e79fb-4ce1-4803-8ac0-7c396fd5fb6d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/24e7784d-15eb-477b-8cff-f6772c824502)

* Example. [Question]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c5c29e5c-afd4-4f90-a17e-3693df1220d7)

* H(S) -> Entropy of **play**.
* C -> Class.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4802597e-be40-4077-bc30-ba26664e6b51)

* Entropy of **play**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e78359d0-6b92-492d-9ffa-7b1e1a41f666)

* In **sunny** we have **'3' times 'No' and '2' times 'Yes'** class. Total is **5**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3adbe3b3-0608-4304-ac88-2b4d873b4dfa)

* The **entropy** of **overcast** is **zero(0)** which means it is **pure data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e242dca7-d386-44fd-94ab-523ad79930d6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/85ae1886-7f69-4ff2-a0bd-7490bc8f8cd4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/87218543-f0dd-42f5-b483-8fdb18c3a1c8)

* As **outlook** has the **highest gain** so it is the **root node**.
* We got the **root node**.
* Entrophy is **zero(0)** means **pure data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b3896f42-2de1-44ef-bf22-c6eb9d5e368b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f40e6415-7aa8-4ea2-a2c3-ebe1e5a45b52)

* When the data values are going to a **particular/single class** only then the **entropy** is **zero(0)**. [**IMPORTANT**]
* When the data values are going to a **two class** and in **equivalent/equal amount** then the **entropy** is **one(1)**. [**IMPORTANT**]
* When the data values are going to a **two class** and in **unequal amount** then we have to use the **entropy formula** to calculate the **entropy**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a823352e-85b5-4422-882e-12ab3a046cf2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6895c943-3b27-47e8-bd17-4de567c244be)

* Gain calculation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c3170bd-9d3e-4d61-9c2c-d8afe5fcffbb)

* Humidity.
* If every types value belongs to same class for particular variable then information gain of that variable s same as parent node. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/271a070e-399c-4d75-b708-54aa335244c6)

* ID3 -> Classification.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e811010d-d5a1-41ce-9210-a5f8feb65378)

* Information Gain.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cca92dae-7f24-45cf-b170-c9e73d0ee2e4)

* Information Gain. [Example]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e5e3a898-77c6-49ce-b895-945256dee299)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c196ad90-77db-4074-8f39-e54994452ba1)

* CART. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/29ce220b-a852-43d1-9428-3fb53e6b8be9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bf2950c2-dd34-4eb5-81bf-9e6182696043)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ec64dae8-f801-4b56-9c9d-0cb2d92c1b5b)

* Overall Gini for **outlook** feature.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3852d8cc-199f-43e1-85b9-026823265746)

* Temperature

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/791b0d68-9361-43a6-80eb-3e344ce681e2)

* Humidity and Wind

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0c0d4646-a6dc-4557-b0cc-524844401c69)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a11ae7aa-493c-4e52-854c-314a27a44c03)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/480c92ce-9bbb-4b50-aa67-1a07cc692fb5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7a92690e-391e-4637-a486-866175dcc00a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6512f434-19b1-4f4f-80d4-6ae661a85e6f)

* Temperature, Humidity and Wind Table.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c69b2396-f8bf-4dd1-8ae5-21da26cd361a)

* Temperature

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83e11316-3858-4254-8314-56c60dc9391c)

* Humidity and Wind

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56bcafac-ce9f-46e2-8cca-cd4dd8ed2d69)

* In the **previous example** we were selecting the **nodes** based on who had the **highest Gain**.
* In this **example** we were selecting the **nodes** based on who had the **minimum Gini index/value**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0322f156-acbb-449e-b9b7-b98083fd2bed)

* Final Tree [Solution] [**VERY IMPORTANT**].

## Doubts

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8fd18479-afbc-470f-9951-6f10b5e3e995)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4ebe0720-fa44-415c-a901-bcb167d517e9)

* Wanted to represent in **y = mx + c**.
* Both are **same** in this case.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cc1139f-be2e-4614-b089-780cc45b9672)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1203aaf1-1101-4b1a-8dfc-15439ebf0754)

* Cases.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/611aa95f-0630-4901-9f1c-b06f81bc4df4)

* Exanple.

## artificial-neural-network-part-ii (9)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a66d41b6-e8a1-4e21-9fa2-e801e9fb5757)

* Decision Tree -> Regression

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ce006178-a610-4831-b3d6-6d71c21c7851)

* Example

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b6c3f1ee-2a41-4a3c-8fdc-08f0323af1e1)

* Decision Tree Algo

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bff0b734-9ccd-4c17-8969-d45d52cc6d0a)

* We are calculating **Standard Deviation(S)** here. [Formula] [**IMPORTANT**]
* Hours Played -> X -> Output Variable/Independent Variable.
* Average -> X'.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05415d70-7cd4-44f4-96e3-307622f6e7d0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/06de31e1-e1eb-4b7d-a327-67d85db54559)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ff8fa241-21ac-4493-82ec-95f4ab36d542)

* Standard Deviation(S) and Coefficient Deviation(CV).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/33c4ef95-a2f3-4d14-96ba-9f67d981469a)

* Standard Deviation(S) for two attributes. [Formula] [**VERY IMPORTANT**]
* P(C) -> Probability of the variable(x).
* S(C) -> Standard Deviation of the variable(x).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/512469d6-24e7-433c-8390-a00d985334b6)

* We have to find **standard devision** for the **outlook** as well.
* **Outlook** has **three** values **Rainy, Overcast, sunny**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1f4c60ca-d5fd-41b0-b460-e4e39f8a5505)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c0cc96d4-7578-48e6-8011-81635d752d67)

* Mean of **Overcast**, X' -> (46 + 43 + 52 + 44)/4 -> 46.25 [Hours played in overcast]
* Standard Devision -> sqrt(((46-46.25) ^ 2 + (43-46.25) ^ 2 + (52-46.25) ^ 2 + (44-46.25) ^ 2)/4) -> sqrt(48.75/4) -> sqrt(12.1875) -> 3.491.
* We we use the **above formula** to calculate the **Standard Devision(SD)** for **rainly,sunny**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/03917178-f291-4441-a749-002cbd4d156f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/af773b81-c30b-4454-9e45-f350e41c1307)

* The **formula** is same as when we were finding **Gain** after **entropy**. Instead of **entropy** we have **SD** here.
* We are finding the **SD** of whole **outlook**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f738e4a4-22ef-40df-b4e7-a89fae8740e0)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c35741c9-0ca4-4cc0-afd1-eb3d52471b8e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56e5edb3-2bc8-449b-ace1-a57f386924af)

* Standard Deviation Reduction(SDR).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/238979bf-994b-4044-a428-03492ba4b89b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c606a1c5-317a-47b3-9f18-8b9d957a6d5a)

* The one who has the **highest Standard Deviation Reduction(SDR)** make that one the **root node**.
* We can see that **outlook** has the **highest SDR** so **outlook** is the **root node**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/af1e45cc-016b-46fa-a6da-00ebbe6e29e2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b9e42867-4869-4983-b280-0e25a028a494)

* We have to see if any of the features will expand next.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3a7c6aaa-05c2-45ac-be79-9fdb82bf92a1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5d6855e0-8784-42e5-85e4-4b27f1480ff1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/253d7271-face-4b3d-8977-2ca67aad2e8b)

* Coefficients = (SD/X') * 100 [Formula] [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1d6bcd99-cc1b-4301-8cc7-a0c209330ecc)

* As the **Coefficients** of **rainly and sunny** are more than **10%** so they can be further broken down.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/68bc3a72-ad87-42cb-a2e8-d51a4b394585)

* The one who has the highest SDR is considered the **root node**.
* S -> Standard Deviation.
* **Wind** has the highest SDR so it is the **root node**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e521bf0b-8d5f-441b-8b79-0f402cc46514)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b88e1984-c282-4919-bdc4-f1f02db43898)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/79ef9480-d884-4b64-8ff5-bc346ca0bd33)

* Child(C) node. [Formula] [Summary] [**VERY IMPORTANT**]
* P -> Feature.
* P(C) -> probability of the node(C).

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7c023b4f-d793-4c23-ab83-1634a2f600d6)

* Alpha -> No. of instance. [Hyperparameter]
* If the **no. of instance** is **less than equal to 200** then we will not **expand further**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d976edb2-5263-4b8b-8746-ef9b781a9c87)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c98d4f6-eac5-495c-8324-f6728d9c9882)

* We know that when there is **equal distribution** the data is **highly impure**.
* We will get the problem of **underfitting** when we have kept the **hyper-parameter** value **too high or more**.[**IMPORTANT**]
* When the value of **hyper-parameter** is **more**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/204a3053-b856-4091-8d12-ac1c23c01a75)

* **Depth limit** -> It means that we cannot go below that **depth**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5056f671-af75-4731-9d55-6aaaa188edf1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d2bab00c-39e9-4c92-9e51-deab194eb4c0)

* **Hyper-parameter**
* Apply limit on **no. of instance(data points)** i.e alpha <= 200.
* Apply **depth limit**.

1) If the **depth limit** is **very low** or the value of **alpha(no. of instances)** is **very high** then there is a problem of **underfitting**. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8e89cdda-7d42-4a3b-8d17-96a39ee9763e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fc32a67d-b7ae-4add-909c-bd2f9d7472a2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb4c4d19-c1f3-434a-97dd-27f1a4e092c7)

* This is the problem of **overfitting**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/230e812e-cbaf-4ed4-903b-b8a0cc61cafd)

* If value of **alpha(no. of instance)** is **very very less** or if the **depth limit** is **very high** then there is a problem of **overfitting**.
* In **decision tree** there is **pruining**.  [**IMPORTANT**]
* **Pruining** means that we just **prune/remove/don't use** the remaining nodes.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2dd9affd-f20f-4dd0-8d63-bbbff4699f6e)

* By applying **depth limit** of value of **alpha(no. of instance)**, we just **prune** the node of the tree. It means that we are not exploring the nodes below the **depth limit**. [**IMPORTANT**]
* First we create a tree and afterwards we realized that the tree is too big and we have to do **pruining** on the tree. We applied a **depth limit** and we did **pruning** and removed the **unwanted nodes**. That is **post pruining**.
* If we have applied the **depth limit** while **creating the tree** or before **creating the tree** that we will not go **below** a specific **depth** then that is called as **pre pruining**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/22707a3c-8a65-4775-bf7b-489b7052373d)

* Pre pruining -> Apply depth limit **before** tree construction.
* Post pruining -> Apply depth limit **after** tree construction.

## Bias-Variance Tradeoff

* We want to get a value between the **underfitting and overfitting**.
* When we **increase the complexity** of the model then there is **some possibility** that the **error value or error chances** of the model also **increases**.
* Error -> Actual Value - Predicted Value.
* When the model is **less complex** which means we have worked on **very less data point/sets**, in that case there is a **higher chance** of **errors**.
* As we start to **increase** the **complexity** of the model, the **chance of error** keeps on **decreasing**.
* After **some point** if we **increase** the **complexity** of the model, the **chances of the error** keeps on **increasing**. After **some point** the graphs goes **unwards**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f7c4f413-d6cf-4ba5-9608-a872bc44b576)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/775a5d58-4d17-4f40-97e1-027d639b7353)

* Why **Overfitting**:-
* The model will work on the **training data** and the **error** is nearing to **zero(0)** which means the model is **perfect** on the **training data** but it will **give error** in the **test/unseen data**.
* Why **Underfitting**:-
* As we have **less data** and the **chances of error** are **more** which means **underfitting** only on the **traning data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/098a00fd-1f23-4452-b974-b78209d4fd23)

* The main model should be a **trade-off** between the **Bias-Variance**. The **complexity** shouldn't be **much more** nor the **errors chances** should be **very high**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fdd3ae24-2440-45e4-97e1-7d8362b9856e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d0237266-b8a2-424b-9e22-41dbfd3625d0)

* Training Data -> The model on which the data is trained on.
* Test/Testing Data -> The model on which the data is tested on.
* Validation Data -> Part of the **training data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cacae2f4-9b8a-45f6-95eb-746168b037e1)

* Data Types.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3cce2b57-971d-4022-85f2-16793bfae03e)

* Training Data 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c1ec8617-f56e-4b19-ae76-93c4b18823b1)

* Test/Testing Data 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0e707d6c-1234-4bfc-9419-06a0450e6597)

* Validation Data

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/220304cf-edc7-4ee1-b460-cc8b8a37a19a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/77840191-031c-4f2b-bacc-607c473c20f7)

* Example.
* Works as **Test data** during model construction.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83501898-51d5-4498-85c6-c38e1c818e1e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/65675cb5-7756-41fd-ac06-9174b9da9e51)

* Purpose.

## Cross Validation

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2f919b4-0cbe-47a3-8149-2b98a51ca640)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/32320a2a-0b7c-4a8f-b39f-5f990a404428)

* Cross Validation -> How much data we are taking from the **training data** and keeping as **validation data**.
* Inbetween the **training data**, we are using the **validation data**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/297343cc-a337-4148-8abf-ae526cf9e179)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ec3244f4-9e5b-4e6a-90f8-e086d12ec4b9)

* Types.

## Leave P Out

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6591fd71-8407-420b-a399-2f2781475a62)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d577bca3-8f00-465f-958e-31ea407f0802)

* We are taking a portion of the **training data**.
* If we have **50  data items** then we are taking **'p' no. of data** as the validation data and the rest is used as the **traning data**. As we have **50  data items** so we have to run it for **50** times.
* It is a very time consuming task.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c699f2c-30d9-418a-a049-7418521c9816)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1c7786f6-8c84-4bef-8fe8-b342969d133d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/71a86d37-8bc0-4b39-91a4-60fb83ac7a8b)

* Explaination.

## Leave 1 Out

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/330bda53-e9ca-4756-82c1-bb786ad81838)

* **Leave P Out** and **Leave 1 Out** are **same** only.
* In **Leave P Out** we can take **more than '1' data** at a time but in **Leave 1 Out** we can only take **'1' data** at a time.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/62737090-de2d-4121-b36d-d90f4cbc2e4a)

* Explaination.

## clustering-part-1 (10)

* The problem in **Leave 1 out or Leave P out** was that we are taking **1 or more than 1** data points each time and if we have **n** data points then in the **worst case** we have to do **validation** for **n** times.
* Time taken will be **more**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8876b088-9606-4c7f-a6fd-0c076a5b0567)

* There will be problem of **overfitting** as well for **Leave 1 out or Leave P out**.

## Hold Out Method

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dea3f6c2-3cf1-450c-a5f4-f4fedd4e5593)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2d58313-cdf5-489e-832b-d3949d106b55)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/792c8a12-635b-4360-b938-c8a0fd970b68)

* Out of the whole **training data** we are **holding/hold** some of the **dataset** for the **validation data/dataset**. We are not taking **single data**, we are taking a **chunk** from the **training data** for the **validation data/dataset**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8e6c5e19-d760-4ad6-bd50-f5b22bba57d9)

* Explaination.
* We are selecting the **dataset randomly**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/76ea3ed3-a9ff-40df-811f-d70cb75d4fa4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/95137db9-653a-40d7-89d9-13fc0d52ff65)

* The problem is that the **Hold Out Method** may not work properly for the **imbalanced data**.
* **Imbalanced data** -> Max. data belongs to a **single/same/one class**.

## K-Fold Cross Validation

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f72922ff-469c-4109-9ce8-314653a57e26)

* We will consider **K** times the data of the **training data**.
* We are **validating** for **k** times.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5e9fa1bc-b02c-438b-9c4d-dad7229864c2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e60f3879-afa0-4f03-ba56-7e5860181a33)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/24a04f9d-2168-4bd4-90e0-833989ee590c)

* Explaination.
* The problem is that the **K-Fold Cross Validation** may not work properly for the **imbalanced data**.
* **K-Fold Cross Validation** is better than **Hold Out Method**.
* We will take an **avg. of the accuracies** and tell the **avg accuracy** as the **accuracy of the model**.

## Startified K-fold cross validation

* In the **data** we have equal distribution of data in all of the **classes**.
* We consider equal portion of data that belongs to both the class of dataset.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/87fcece1-1521-42c1-bcff-0c108a408934)

* Data repeatation is possible.
* **Startified K-fold cross validation and K-Fold Cross Validation** are **similar/related**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e9c42742-eacc-43da-83a5-b7ebd9de76a7)

* Limitations.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/99321659-e1d7-46cf-9d93-857b904e72ee)

* Applications.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/60bb9cd6-3f18-45c2-93b0-f20f19ec9565)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ae1edcb3-773f-4f59-9967-f63c7c4a4e73)

* Question
* We have **two classes(Slow and Fast)** and they are **equally distributed**.
* Whenever we are finding **entropy** and it is an **equally distributed**, so the **data items** are going to **equal class** which means that the data is **highly impure**.
* We know that **highly impure** means **1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/44dc6f11-dda6-4f41-a48a-d77af6a0e675)

* Option **C** [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bd4de0bf-3daa-4ae0-ae86-fcb0016117c1)

* Question

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6da64c1a-4c2f-4c70-99a5-56bfcd58ba93)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ceae683b-4617-43cb-aaae-8dfec7000d11)

* When **one feature** totally goes to **one class** then the **entropy** of the **feature** is **0**.
* This is what happened with the **entropy** of **flat** from the **Elevation**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/09e39ace-6052-464a-bc14-897d9dd86df6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/df20c6fe-e062-4ef2-8bdc-884a5dbfdaaf)

* Entropy of **steep**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/672026ec-aaa6-44a7-b58c-3d05da2fe109)

* Entropy of **S**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9c54fea9-4ab4-4302-adc4-224e2b426d13)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/20a173b2-32f3-480c-910b-21f13d60d9d1)

* Option **D**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c376ead-b492-4c27-856a-1168327f8b86)

* Question.
* **Entropy** of **speed limit** is **zero(0)** because it has **Yes and No** as **data** and they are belonging to the **same speed classes(Slow and Fast)**. 
* **Entropy** of **speed limit** is **zero(0)**.
* **Entropy** of **Road Type** is **one(1)** because it has **Uneven and smooth** as **data** and they are **equally distributed** to the **same speed classes(Slow and Fast)**. The data is **highly impure**.
* **Entropy** of **speed limit** is **one(1)**.
* We also know that when the **Entropy** is **zero(0)** then the **information gain** is **one(1)** because **1 - 0 -> 1**.
* So **information gain** of **speed limit** is **one(1)**.
* We also know that when the **Entropy** is **one(1)** then the **information gain** is **zero(0)** because **1 - 1 -> 0**.
* So **information gain** of **Road Type** is **zero(0)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/66a8a9a7-668e-4fa9-a070-692955e3442c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e54414b6-d81a-4815-bed9-2056d6da1dac)

* Option **A**. [**VERY IMPORTANT**] [Practice Again]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/df13548b-be2b-4aaa-bd07-c00ecf1c2b68)

* log calculation. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dfc179fc-e9fb-46ad-9acf-e56c45fd7222)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/54659d26-94aa-4d1b-a864-7c56f3489dc0)

* Question
* Option **A**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ee896c21-8223-4a59-b73e-0bd24c12f7e5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e8ed60ae-358f-4a6a-a592-b1d8d2fabbc3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bf9c4db4-6ad9-4010-ba01-d103724a05d8)

* Question
* Option **C**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/811084ca-d399-4504-90bc-75bf827e2576)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bff78c69-ce52-45ed-9dcc-4c0e1f651372)

* Question

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e7109198-e8eb-4041-9eca-5d331db1df44)

* We will get **1** as the distance for both **(0, 1), (1,2) and (1, 0)**.
* So the **3 nearest points** are **(0, 1), (1,2) and (1, 0)**.
* All of the **3 nearest points** have the **plus(+)** class.
* So the point **(1, 1)** belongs to the **plus(+)** class as well.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b7e058a-f2ca-4a9c-9c23-0fadd6eeeddf)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/782428b9-20b4-4810-bf63-dff45f8819ca)

* Option **A**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6b432bf9-75ea-44d6-bb9f-275dfda1c5f9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ae6a7828-761d-4e5a-a0f0-26fd9464ad27)

* Question
* Option **D**.

* Out of all the training algos we have studied, which model rejects the **feature**?

> Decision Tree. It is not expading all of the **features**.

* L1 and L2 regularization.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/aeed7884-75c3-4b02-8ae6-d522ff5c11de)

* Question [MSQ]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/445d342c-0fcd-49d6-a6b5-59ac2fb9087b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f2d426a5-8089-402d-b801-4e3cabc211df)

* Option **B and D**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d806b11c-4682-4591-8142-f0b8b16d5590)

* Question
* Whichever is generating more we will put **k** in that **class** and that is the **answer**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bce8b22b-d7f7-4c9f-bcf5-0c7ff411dff4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b759889e-bbbf-4c6e-b43f-3b2a76aa1489)

* P(a = 0 | 1) -> We are checking where **K = 1** and then we are checking for **a = 0** and seeing if any of the **a = 0** has **K = 1**.
* We can see that there are **3 '1' in 'K'** and we have **2 '0' in 'a'**. Only **1** of **a= 0** gives us **K=1**. So the probability is **1/3** as there was **3 '1' in 'K'**.
* P(b = 0 | 1) -> We are checking where **K = 1** and then we are checking for **b = 0** and seeing if any of the **b = 0** has **K = 1**.
* We can see that there are **3 '1' in 'K'** and we have **3 '0' in 'b'**. Only **2** of **b= 0** gives us **K=1**. So the probability is **2/3** as there was **3 '1' in 'K'**.
* P(c = 1 | 1) -> We are checking where **K = 1** and then we are checking for **c = 1** and seeing if any of the **c = 1** has **K = 1**.
* We can see that there are **3 '1' in 'K'** and we have **4 '1' in 'c'**. Only **2** of **c= 1** gives us **K=1**. So the probability is **2/3** as there was **3 '1' in 'K'**.
* P(K = 1) -> How many times **'1'** is coming in **K**. We can see that there are **3 '1' in 'K'** and the total is **6**. So the probability is **3/6 -> 1/2** as there was **3 '1' in 'K'**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/44f56ecc-13ef-4110-9678-1c63b9a09647)

* P(K = 1) -> How many times **'0'** is coming in **K**. We can see that there are **3 '0' in 'K'** and the total is **6**. So the probability is **3/6 -> 1/2** as there was **3 '0' in 'K'**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f21a84d6-fe05-4959-a2ba-c6ac0515db4a)

* We haven't done **normalization**.
* To find the **actual probability** we have to do **normalization**.
* Whatever we multiply with to **2/27 or 1/27**, **2/27** will always be **greater than '1/27'**.
* So the class **k = 1** is **greater**.
* Class **1** greater.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1a9e0b4f-0ac2-434c-8974-f816547c4888)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/05439053-0681-463a-b702-cb1bcd7616d6)

* Option **B**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e516dd43-d537-4479-864b-353cedf6b96a)

* Question.
* When we are talking about **exact probability** then **normalization** is needed.
* P(K = 0 | a = 1 | b = 1) -> P(a = 1 | 0) * P(b = 1 | 0) * P(K= 0) -> 2/3 * 2/3 * 3/6 -> 2/9 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4c802743-a6de-42cb-b2a6-bbf001c1d4cb)

* We have to do **normalization**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/81f4a64f-83ba-44bd-bfd3-ee6ce1a30fef)

* 2/9 / (2/9 + 1/9) -> 2/9 / (3/9) -> 2/9 * 9/3 -> 2/3 [Answer]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/38de08f5-46d8-42c3-8441-f78daccef21a)

* Option **B**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3688b9cb-3768-4782-9011-92db94206a27)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e6ab8dea-35c4-419f-93c9-f6a62de45cf4)

* Option **C**.
* Seeing the **nearest data points**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7f327c52-e67b-49ae-a9bc-1b93dac9b14c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9337607d-0ce7-4e3b-92b2-654aa291ec78)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e6da5aea-2397-4608-a7f5-43ff49135574)

* Question
* Option **2** -> Soft Margin.
* Option **1** -> Hard Margin.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/465f7b4a-2f88-4be1-8375-a039629b84ef)

* Question
* If we remove any of the **support vectors** then the **decision boundary change** will be **affected** by the removal of the **support vectors**.
* With the combination of the **support vectors**, we draw the **hyperplane** line.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1928111d-c27d-4ee0-94e2-809362d6c726)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3034d24a-6642-49c1-a76d-787a542db644)

* Option **A**. [**VERY IMPORTANT**].
* If we had removed the **non support vectors** then we wouldn't have **any problems**. The **hyperplane** line won't be affected.  [**IMPORTANT**].

## Artifical Neural Network

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6f340584-7c85-4f57-96f9-db44764233cd)

* ANN.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9d8b911e-a4ee-48c7-84eb-cb9fab26d882)

* NN.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7c382d56-85d7-4fd0-ae59-bc0488476e32)

* Perceptron -> Single Layer Perceptron -> If there is **no hidden layer** then also it is fine.
* NN -> Input layer, Hidden layer, Output layer.
* Perceptron are used to build **ANN**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e7f5bc4c-96aa-4ed5-bdb4-027fe5a5949b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5438345c-4deb-44c7-ad51-26b1e3e4bacd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6a8741fb-82df-4aea-bdfe-20f0dd880bc6)

* Neuron.
* Activation Function.
* We are training then we are modifying then again we are **training** and then we are **modifying** and so on and on.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c36a0382-d347-4a64-ac6e-1b4acf6edff2)

* Implementation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1fa6de04-c64c-4851-b77a-d009734477b1)

* Activation Function identifies a **threshold values**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/951a92da-3c79-4763-bbd4-7f60d63700df)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c5279129-ce30-487e-b0e9-10b8e539027a)

* Bias -> Without any data, the output should give/generate some response. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/32289f26-77b6-403c-b225-053d41c03a1d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/094fa016-05b4-42e6-a4e4-2a6316c0d587)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/847be023-6c95-4624-9632-42968b22610b)

* Equation.

## Activation Function

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/03a6545e-687b-4728-86d0-a3319b742619)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/eefa20d7-6466-423c-9794-c7b8d6611ebf)

* Step Function.
* We are setting a **threshold value** and if we get a value/result **greater than** the **threshold values** then the **output** will be **1**. 
* We are setting a **threshold value** and if we get a value/result **smaller than** the **threshold values** then the **output** will be **0**.
* We are not talking about the **sum** as the **output**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4a2f7329-7f45-4636-b211-a17df63b2a25)

* Example

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/19f28d5f-3b3b-4cc4-81fa-19da17471729)

* Error Calculation.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/67c79d6e-685a-437a-a35e-664f906d4cc3)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2440eca1-6629-4a3e-89da-3b8485c22f3d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/503ecf9e-a927-497d-8bbb-47a47823e4d2)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/078221c9-641c-4102-80c7-f0d10886b1c6)

* Alpha -> Learning Rate -> It is a **hyper-parameter** with which speed we are changing the **weights**.
* e -> Error
* Xi -> Input
* We are modifying the **weights** and we are modifying with what **rate**?

> That is the **Learning Rate** which is **alpha**.
> The **hyper-parameter** helps in **increasing** the **accuracy** of the model. [**IMPORTANT**]

* Error(e) is used to **modifying the weights**.

## clustering-part-2 (11)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/920cfc92-a318-40ae-b3a9-7d5f7de6a7d2)

* Example [Perseptron]
* We have to perform **AND** operation of **two inputs**.
* We can design **logic gates**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/99808093-2c97-4f27-8b00-22204397637f)

* **X1 and X2** are always binary inputs.
* Threshold(Theta)
* Learning Rate(Alpha)
* We are going to use **binary step function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/391ac5a5-34d5-44dd-be7f-c52096d369d7)

* First we have to find the **summation** and the **output of summation** is sent/applied to the **activation function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4b00be59-c00f-4b63-883e-66d076129fae)

* Bias(b)
* We can **add bias** as well.
* weights can also be sent along with the **bias(b)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9cf693d6-30ce-4249-95d1-d49ca75ff453)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0254c06c-3e6f-4632-af73-d6ef21ed1f3a)

* The predicted output(y) = 0
* The actual output = 0.
* The **predicted and actual** outputs are **same**. So we don't have to do **any modifications**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/94b0da6a-54c9-436f-a6d0-308876f65efd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b027f9d3-7a6d-4679-8b4a-694b1f4f8101)

* We have to do **modifications** when the **output** from the **activation function** is **different** from the **actual output**.
* W1 = 1.2
* W2 = 0.6
* X1 = 0
* X2 = 1

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3546769f-34ba-4d4a-b18e-c7e45a9489fd)

* This is for **second output**.
* We got **q = 0.6** and it is **less than '1'**, so **y = 0**. The actual output it also **zero(0)**.
* So the **predicted(y) and the actual** output are the **same**.
* So we don't have to do **any modifications**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6f469e63-8d74-4320-8188-2c17571e63ba)

* W1 = 1.2
* W2 = 0.6
* X1 = 1
* X2 = 0
* This is for **third output**.
* We got **q = 1.2** and it is **more than '1'**, so **y = 1**. The actual output it **zero(0)**.
* So the **predicted(y) and the actual** output are **not the same**.
* So we have to do **modifications** of the **weights**.
* Weights -> W1 and W2
* Error -> Actual Value - Predicted Value.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/50effd26-f5ce-45ec-9d3e-43f3bc48a1a1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8f1d86f9-7e90-4a4c-8a3c-3cf19891c7eb)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6d726c1d-7797-4738-beac-8c9f429396bd)

* **Modifications** of the **weights**. [**IMPORTANT**]
*  We have to apply new **W1 and W2** for the **same inputs of X1 and X2**.
* If the **q** is **less than '1'** then **y = 0** otherwise it is **y = 1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/de3c94e6-7a19-4dbb-8b43-2f4c8f2bcff8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/44e1618a-6935-4dc2-926f-76b9a3060ac5)

* We got the **final weights**. [**IMPORTANT**]
* How many times we have modified the weights?

> **1 time**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f4d6c9a1-327e-4b5f-967d-772320388bba)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/681b35d8-9a83-4a63-9edf-aafc1f06d7a3)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6bc313a9-c9c5-449e-b864-8174b46b031b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/222f7a9c-e7b7-4ae7-9b2f-3dec1cfe6899)

* We know that **X0 = 0 and X1 = 0** for the **1st input** and the **actual output** is **0**, so the **1st output** is dependent on **W2** and we want the **output** to be **0** and in order to get the **output** as **0** we want the **summation** to be **less than '0'**. For that to happen **W2** should be **-1** then the **summation** would be **-1** which is **less than '0'** which we wanted then the **prediction** for the  **1st output** will be **0** which matches with the **actual 1st output**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/62e8d821-435e-4720-a798-374fff76b664)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fc2ffe60-2da3-4ed7-a076-1019caf5aa93)

* For the **4th output** we have **X0 = 1 and X1 = 1**. The actual output is **1**. To get **1** in the **predicted output** we have to have the **summation** to be **greater than 1**.
* We already have **W2 = -1** from the **1st output**. For that we can have **W0 = 1 and W1 = 1** and the **X0 = 1 and X1 = 1** so we get **2** from **W0 * X0 and W1 * X1** then **2 - 1 = 1** which is **greater than 1**.
* As the **summation** is  **greater than 1** so the **predicted output** is **1** which is **same** as the **actual 4th output**.
* So we got **W0 = 1, W1 = 1 and W1 = -1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6f3d48db-b874-4acd-8490-754c95a65097)

* It is dependent on the **weights**.
* Option **B**. [**VERY IMPORTANT**] [Practice Again]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ed610f1c-72f0-492e-974a-9026eef4a6e7)

* Question.
* From the **1st ouput** we can have **W2** as either **0 or -1** both satisfy the **actual output**.
* From the **2nd ouput** we can have **W2** as **0** only which will satisfy the **actual output** which we want and if we put **W2 = =1** then we will get **summation** as **0** and as **0** is **less than '0'** so the **predicted output** will be **zero(0)** which is **not equal** to the **actual output**. So **W2 = 0** to get the correct **actual output** for **4th output**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f6a7ece1-360e-4547-b620-0179068252d6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a0933736-8860-403f-ba98-f1fe068f54a5)

* Option **A**. [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1839cfbb-b291-495e-83a7-0bf043e3b24d)

* Remember the **truth tables** of the **Logical Gates**. [**VERY IMPORTANT**]

## Types of Activation Function

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/399b5dab-f232-4f0b-9460-3082152e9fcf)

1) Linear/Identity Function:-

* Final output is same as input of the activation function.

2) Binary Step Function:-

* Theta -> Threshold Value.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a90cabd5-25c6-4cb8-b2c3-14fa685958eb)

* **Threshold Value** is given here.

3) Bipolar Step Function:-

* It is exactly like **Binary Step Function** but instead of **0 and 1** as the **output** we have **1 and -1** as the output.
* Theta -> Threshold Value.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3a1bced8-d261-44b5-8dd4-eb109d0fc75c)

4) Ramp Function:-

* Theta -> Threshold Value.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1fc11e13-c579-4d03-b0c0-da308b71e7b5)

* Giving **ternary** output.

5) Sigmoid Function:-

a) Binary Sigmoid Function:-

* lambda -> hyper-parameter or steepness parameter. [Sometimes **lambda** is considered as **1** and it is ommitted]
* By default **lambda = 1** is considered.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d7c61458-98c8-4ae4-bf7f-135f111f10ef)

* Binary Sigmoid Function [Formula] [**VERY IMPORTANT**]

b) Bipolar Sigmoid Function

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bb34a9bc-e94f-40e7-bfcb-de6f9e9c1c44)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56378383-bb3b-4714-ae2e-cae6d671f57f)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4dabd077-61a9-41d3-9f86-ac9c340ca584)

* Bipolar Sigmoid Function [Formula] [**VERY IMPORTANT**]
* lambda -> hyper-parameter or steepness parameter.
* By default **lambda = 1** is considered.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/098fb302-4905-4737-99d2-6e5080f4a251)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c8cd49c4-5163-4de6-98c1-1f4778c1efc4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7d237a6e-0611-427c-bc34-ae5a16463d6c)

* x = yin = x1 * w1 + x2 * w2 + x3 * w3 + b
* b = 0.3
* Sigmoid function = 1 /(1 + e ^ (-x))
* Inplace of **-x** we can write **-yin** as well.
* We will compare the **predicted output** with the **actual output**.
* This is for **single layer**.
* **x1, x2 and x3** are **feature** here.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f7411467-96e0-4128-b34d-56a33d297296)

## Multilayer Perceptron Feed-Forward Network

* **Feed-Forward Network** can contain **single layers** as well. Doesn't necessarily needed to be a **multi-layer**. Can work on a **single layers**.
* If **Multilayer Perceptron Feed-Forward Network** is written then there is a **minimum of '1' hidden layer** there. The **hidden layer** is the extra layer that should be there in the **middle**.
* **Hidden layer** can be **more than '1'**.
* **Input and output layer** can be **only '1'**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/82f63c6f-56d5-4d1f-a398-9e146fb3653c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ffbc355f-1af3-4b80-8869-0915c6a60f31)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9c41d3a1-04ae-4f0e-b000-257f2e080ce9)

* **Multilayer Perceptron Feed-Forward Network** is a fully connected network. Every **input** is connected to every hidden layer's neurons.
* We are using **Activation Function(AF)** in the **Hidden layer and the output layer**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb875a9c-0738-467d-a46e-7c6a4db9533a)

* We have to apply **bias** to the **neurons** of the **Hidden layer and the output layer**.
* We have to understand the **formula**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ba079fb9-ad88-4846-8aba-3ee511312ce2)

* For the **Activation Function(AF)** we are using the **Sigmoid Function**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/92c17a9e-62a2-49ef-ab7c-f21fc7f982bb)

* NN.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7f08456b-6be5-49c5-810e-fa03e893b173)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3bc8b676-08ad-468b-a2c5-ec166f1edd44)

* Formula [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2205742b-162c-46da-b3dc-0dc558867e53)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/95c16354-144f-4db6-b2cb-33444ff205aa)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/915d3b76-9ffd-4bd2-89d6-9b41a8a81183)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/deff65ca-4fa0-4c08-a454-e02a7b26d359)

* With every **neuron** we have to add the **bias**.
* It maybe possible that with the **output**, the **bias** is given.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ece9f3fd-9a8c-4be6-9aff-f409a1758ce6)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fb3c1959-aec1-4489-90d2-3693377d3bd4)

* Weight modification in the case of **outputs.
* To calculate the **error** we have **hidden layer and output** layer.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7b438164-e6ad-4ba1-8c23-97685a15d68a)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6de50c4-d5b8-47ef-8a7c-234b6bda24e6)

* Error. [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e5216990-9794-4d61-9d31-23f9c8bdd9c7)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c911ac1b-89f7-449d-ac38-fd19b0b59c75)

* Updation of weights and Updation of bias [Formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dcbca0cb-9580-4d85-a636-966495ca991a)

* 12 are the **inputs** from the **4 neurons** and the **4 bias** required for the **4 neurons**. So **4 combination** for each **neuron**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0e8e2385-979f-48a4-be05-a38e7ed5be2d)

* Total paramemters in all of the neurons -> 31 [Addition].
* **Bias** is added to both the **hidden and the output** layer.

## clustering-part-3 (12)

## Clustering (Unsupervised learning)

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/26d9d1df-0426-4585-a064-4d1bf5e40997)

* Clustering:-

1) K-mean
2) K-medoids
3) Hierarchical

* Top-Down
* Bottim-Up
* Linkage (single)
* Complete/Multi Linkage

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f98c2bcb-21f6-4597-a5c3-011ce32922d0)

* K-mean Clustering Algo.
* Cluster -> Similar type of data is put/made into a group.
* The **various/different** categories we have that many **clusters** will be formed.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d2e6504d-d098-4b4c-a8ce-289425893e1c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b58fe5a3-e1b9-46c7-84ac-59f636f5c857)

* Example.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/80f34856-3de7-446c-b6eb-92e6a555737f)

* Working of **K-means** algo.
* We will execute the steps until we get **proper clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/52265409-c535-4c2e-84f2-18341fe7d06b)

* Example.
* We have to calculate the distance from the **centroids**. We will use the **Euchidean distance**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8502f52d-4a0d-4467-8d36-eca8eb51fbf5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/02897cf0-69a3-40a9-bfc5-360f40f0ac22)

* **Euchidean distance** formula -> sqrt((x1 - x2) ^ 2 + (y1 - y2) ^ 2) [Two points]
* **Euchidean distance** formula -> sqrt((x1 - x2)) [Single point] [formula] [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e32f9bc8-1fab-4429-bd4e-3595b44437cb)

* The intial **centroid** will be mentioned in the question.
* **Centroid and cluster** should be mentioned in the question.
* We have **2 clusters(K)**.
* **Centroid(C1)** is **(2,8)** and **Centroid(C2)** is **(4,9)**.
* We have to find the **minimum**, so we don't have to calculate the values fully.
* **'3' data points(P1, P2, P4)** are going to **C1** cluster.
* **'2' data points(P3, P5)** are going to **C2** cluster.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c9611c68-f627-4c4f-8e2d-52bff49a5349)

* Now we are going to make the **clusters** now.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/26b7c9ea-ff0a-4807-b17e-1b996a0dc542)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/36bf3234-b0e6-4c31-a9f7-ec2fd430e67f)

* Now we are going to find the **minimum** distances of the **points** and find their **new clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f6d151d3-6071-4c75-ac41-8395226cf30b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/93f846fa-ca6d-421e-aa2c-70ce5a362201)

* Except **P1** point, all of the other points are going back to their **old clusters**. **P1** point is going to a **new cluster** which is the **C2**.
* It means that we haven't still found the **correct/right centroids**.
* We have to **continue** till all of them are in their **same clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8a778ffc-17b3-42d4-8265-5386d3ba694e)

* We have to calculate for **centroid** again.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/973ce446-254e-4008-83c7-aa5f1f72007f)

* Now we are going to find the **minimum** distances of the **points** and find their **new clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cd96b85c-4b68-4e9b-91e1-12b89fcd2c73)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/44491883-7342-4bfa-be0b-755d3f98732a)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9e65c21e-47ac-4c48-8d96-0fb0c81d53f9)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/5dd70b1d-3154-42e9-b963-da82b1d3965d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b43cc493-5044-4345-b180-7db3d9536c2d)

* Example.

## clustering-part-4 (13)

## Hierarichica Clustering

1) Agglomerative -> Bottom Up [This is **more** important, more questions are asked about it]
2) Divisive -> Top Down.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb0eef00-f7ed-4918-9f86-41512565f31c)

* Grouping the nearest points.
* Clustering structure [Example]
* We don't have to make the **clusters** before hand only.
* How to identify the clusters/Clustering?

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/da1fced8-2d02-415e-8bd7-b3c8546ac16a)

* Dendrograph. [Which is the correct dendrograph from the options] [Expected Question]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cffa1a23-446d-4665-a8a0-8c77e9e808a7)

* Question

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/421fba70-24d3-497c-8d80-46c76c48a861)

* Write the points in **increasing** order.
* **21 and 22** are in the **nearest order** that's why we are merging them. As the distance between them is **1**, we can calculate the **normal distance**.
* We can merge **22 and 24** or **24 and 26** as the distance between them is **2**. We can **merge** either of them as we want. So we merged **24 and 26**.
* We have **17 and 21** who have distance as **4** and **22 and 24** who have distance **2**. So we will **merge** the **22 and 24** as their **more closer/nearer**. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/ec28f9ed-67f4-4f7f-bbd1-958698554c37)

* Next we are merging **17 and 21**.
* Next we are merging **17 and 40**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/503f7860-7392-4254-bb81-6f061d429cd4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/adbf8965-b0a2-4360-905a-8aae11a833fd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e27035f4-e2ae-4702-8d06-0be7151c4c50)

* Output

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/966ae933-f81e-448b-b95c-1af016e9f671)

* Bottom to Top -> Agglomerative
* Top to Bottom -> Divisive.
* We have to do pairing of the **closest/nearest** numbers.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a5205f8f-379c-47e6-9961-b72dcc256aca)

* Divisive.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3d2ffe9b-bd16-473a-8be2-e608702a7d47)

* We have to find the **difference** between these values.
* We have to write the **differences** between their **distances**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/977a4f8e-0dd9-496e-8de4-f966dcfb3b10)

* **Symmetric or proximity** matrix.
* We have to find the **smallest** value? [Expected Question]

> There is a difference of **1** between **21 and 22** also between **26 and 27**. **21 and 22** rows will be **merged** into a **single row**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/571b41fe-db49-46eb-9e63-e3314457cb56)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83134a4d-924f-423d-a628-6981c227262f)

* **21 and 22**.
* Now we will do for **26 and 27**.
* In the **Symmetric or proximity** matrix, we have to find the **minimum** value.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/90827f26-2e78-4224-9994-ddf4c47cafde)

## Single Linkage Heirarchial Clustering

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/eeb2dee8-ad6b-4130-9770-8901adaa31d3)

* We use **Agglomarative method(Bottom-up)** and by default we use **Euclidean distance**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c03033c4-424f-4744-9b1c-b70869d4f699)

* Formula [**VERY IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1928d2f3-274f-4dd3-aeb8-c25ea547156b)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/10eeff2c-d2b7-4d1a-bf57-73cf7ee59f8d)

* We are finding the **distance** using the **Euclidean distance**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a617a50b-4875-4a0e-9cc7-4b174d716bb8)

* **sqrt(5)** is the **min.** value.
* **2** is the **smallest value**. So we have to **merge** the **(2,3) and (4,3)** values.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/11b22a6a-3920-491c-ba6d-f60fce36992b)

* We have to seen the **non-diagonal values** when filling the **merged matrix**. [**IMPORTANT**]
* Next smallest is **sqrt(5)** we can do merging with **((2,3), (4,3)) and (5,6)** or **(3,5) and (5,6)**. We can do either of them.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d4ad9a57-05f8-4a28-94f6-64d2a258967a)

* We are making the **(3,5) and (5,6)** cluster.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/22e6faff-b05e-4646-b29c-00a2e980e584)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/7aea7bec-52fb-4e59-8b72-3f9514b8b64c)

* We don't have to write the values below the **diagonal** of the matrix. They will be the **same** values** as the **above** ones.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e924eb32-3958-4bdb-b57c-49d6ce1d14f4)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e2e33d38-e396-4a69-b7ac-96e448df92f5)

* Solution.
* How many clusters are there? [Expected Question]

> A **threshold value** would be given and from that we have to find/identify the **clustering**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/63faaecc-ff72-4256-81ee-1cc30059a1f1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f15afb44-1df0-443c-b3dc-ea060df57169)

* **Threshold value** is **4** [Example] [Given]
* It means from point **4** we have to draw a **straight line**. The groups below the **Threshold value** point line, they are called as **clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/57ef5eb5-f605-41f0-85ec-580f51200b00)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/08bbafde-b6fc-45ac-99fd-77b8b6417954)

* I did a mistake would be **4-clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/bed306d1-87fd-4b0b-9a34-0fb91f098b29)

* **4-clusters**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0fa52f62-6b5d-4645-86ce-5b645c646f54)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3ae4f6de-dbb0-47ff-937c-dabfcb86ea02)

* **Threshold value** is another **hyper-parameter**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dfc77533-cc22-4f58-b3b7-a02672c05439)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/31dd4b93-e498-454c-bc9d-223f1dd303e4)

* To find **cluster** in **Heirarichal linkage(For all of the tinkages)** clustering we use some **Threshold value**, that is a cutting point or value of **Euclidean distance** in **dendrograph** from that point we design a horizontal line and all the group below that line is the **total no. of cluster**. [**IMPORTANT**]
* Select the longest vertical line(Max distance) that do not intersect with any horizontal line.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c2a23022-6aa9-46de-b0d3-1f793b0a7dd0)

* **2** clusters.
* In comparison to **K-means**, the **above** one is **better** because in the **linkages** the calculations are more so time taken is more as well so the complexity is also **more** but in comparison to **K-means** the problem of finding **cluster** is not there in **linkages**. We don't need to find pre-defined **clusters**.
* When we talk about **dataset size**, when there is **large dataset** we use **K-means** and in **small datasets** we can use **hierarichal dataset**.

* **Linkage** disadvantages:- [**IMPORTANT**]

1) Compared to **K-means**, **linkages** are **more time consuming** hence **more complex**.
2) We cannot use it for **large datasets**.

* **Linkage** advantages:- [**IMPORTANT**]

1) Good for **small datasets**.
2) No need to define number of cluster in the beginning.
3) Point can not be moved from one cluster to another cluster.

* In **K-means** the point can **move** from one cluster to another cluster. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b51925e7-a357-46fb-a70b-13e774d385ee)

## Complete Linkage

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/018f54ae-e51b-4f1b-a8c3-333b15fcacbe)

* Same as **single linkage** but at the time of merging for the remaining points we need to take maximum distance.
* Doesn't need to me in **increasing or decreasing** oder.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2fe14dec-e104-4ba9-8051-b8300bfee474)

* Example
* We have to find the **min. distance** or **min. value** cell.
* Symmetric Matrix.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d5a099e4-e4b4-4861-805b-349b87a10513)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/16a782c7-dbc2-4460-8288-1cab581af125)

* 1st row and 5th row are affected.
* We are **merging**, 1st and 5th row. 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/0c8f907e-4588-4828-aa01-e581edef71e1)

* Finding the **values**. [**IMPORTANT**] [Formula] [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2b93db18-ce94-40c6-ad95-2bf3319b10bc)

* Whatever we are getting in **(1,2) and 5**, the same thing we will get in **5 and (1,2)** as it is a **symmetric** matrix.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9c6cd0ad-7839-4086-9ce1-8bae6c598bf0)

* Find the **next min. values**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6ab164a7-665a-4e5a-9fdc-f7c04271c472)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3a0b8175-7cdc-483a-87d0-14fd9f2c751d)

* So, we will merge the **3rd and 4th rows(8 and 10)**.
* The **last table** is the **bast table** when we are solving in the **new table**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/caa3fd68-7103-462d-8935-824f4f1e69fd)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c371058-08c5-46f3-806e-467ee643a15c)

* Finding the **values**. [**IMPORTANT**] [Formula] [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/cb4f3ddb-451f-42fe-af4e-5ac700a61ce9)

* Next min is **4**.
* So we will merge **(1,2) and 5**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/534dafe2-7848-4e1c-9d1c-5b1e3cbe8b47)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3580c545-58bc-4cd4-a115-b4dfa74cecb5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a7357ab0-b219-4387-ae50-f234ca9d5ba5)

* Finding the **values**. [**IMPORTANT**] [Formula] [**IMPORTANT**] 

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fba198aa-2efc-49e9-b8bd-49dda62996be)

* We will **merge** them into a **single cluster** and get **0** value. That's the **final table**.
* The **graph** making part will remain the **same** as the **last linkage** one.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/03efb8d5-1b26-4987-be2b-1b2a78ed64a3)

* Dendograph.
  
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2c473b05-b45d-429a-a1ac-c5b6b6638dc4)

* Question.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/4c42ff6b-fd1e-4837-ac68-37a3478d5e1b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/beceff40-7ffc-47b1-b73d-f5cd73a3306d)

* Option **B**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8bdd5036-c5e5-4526-899f-f8c14d0463a5)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/77930759-e3e1-4f86-b0a9-45ee4caf66c2)

* Question.
* Find the **min** value in the **distance matrix** table where we can do the **merging**.
* The **min. value** is **0.1100** which is between **p3 and p6**, so **p3 and p6** are **merged** first.
* Now find the **next min.** value which is **0.1388** which is between **p2 and p5**, so **p2 and p5** are **merged** first.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c13d18ea-23ea-45a2-be77-5ccbac59ca2c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d0126dfd-4c4d-426b-85fa-6d591a851d08)

* Solution. [**IMPORTANT**]

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8b0f059e-a8c7-41c3-af64-f5db8e079dcf)

* **AI** doubt.

## principle-component-analysis-and-lda (14)

* **Supervised** -> We get labelled data which means input and output is given.
* **Unsupervised** -> We get unlabelled data which means only information is there i.e **no output** is there. We are predicting the **output**. We have the **input** and we are predicting the **output**.

## Dimensional Reduction

* Transform the higher dimension dataset to lesser dimension dataset.
* **Feature removal** is something else. That is different that **Dimensional Reduction**.
* **Feature extraction** is a part of **Dimensional Reduction**.
* From many of the **features** we are **extracting** the **important features** that is **feature extraction**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/e044a9d8-a932-4fdd-83cd-a44282ff9bb4)

1) When **X** is increased, **Y** is also decreasing. This is **negative corelation**.
2) When **X** is increased, **Y** is also increasing. The relation between the data points is a **positve corelation**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1024ba9b-afda-4a41-9008-b113b344f327)

* The range **corelation** is from **+1 to -1**.
* If the **corelation** is **0** then they are **not corelated**. 
* **Dimensional Reduction** means between the **variables/elemetns** we have to see the **dependency**. How much they are **dependent**. How much one variable is dependent on another variable.
* Why we are doing **dimensional reduction**?

> Why we are reducing **features**. We have to **remove** the unimportant/not important features.

1) Feature Selection

* We have many **independent** features.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/83f2a074-ffe2-454c-9582-c2d1fb8d9be3)

* No feature is dependent/co-related to **f4**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/582b8b6a-e305-400f-959a-27acd66712c0)

* PCA is based on **unsupervised** learning.
* LDA is based on **supervised** learning.
* In **dimensional reduction** we are mainly doing **feature extraction**. We are not doing **reduction/reduce**. Does not look the **feature/property**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/589a9918-9d4e-4590-84f5-e180dc23969b)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/221d45a9-db0e-4438-86f5-53e76e4036d8)

* The main motive of **feature extraction** is selecting the **important features**.

## PCA

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/6f13e013-f27a-4373-b911-e42cd65f5738)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9861acc6-98a5-4cfb-bfff-ab4fa743f668)

* We are taking the common properties of the **two**.
* We had many **specialized entity** and we took the **common properties** and made it **generalized**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/fef953f0-51b0-45e1-8cde-ffb0efe0873e)

* PCA. [Step By Step]
* The **value and feature** are **very important** and through them only the **data** is **dimentionally reduced**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/251989ac-a45e-4bcc-a669-05c38142578e)

* **n** -> Features(X1, X2 and X3).
* **N** -> Value of the features.
* To extract the **value of a feature** we need the **feature-value** combination.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/56e977ae-b0c5-4155-ba16-dde2de8329cf)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/1d89e76e-2680-42d1-9ac0-5b44fb6acca0)

* X15 -> 1st feature and it's 5th value.

1) We need to find the **mean** of the **datapoints**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/69f2eda4-02d9-440d-82e8-0ae49bbefea3)

* Mean [Formula] [**VERY IMPORTANT**]

2) Find **covariance** between the variables.

* We need to find the **covariance matrix**.
* We have to find **covariance** between every two variables. We will get an **n X n** matrix.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/9fb73b63-e465-4c63-9404-86b3268d285e)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/af0ccfa1-49a8-45fd-8bba-06d12144e195)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3d6b9626-61de-41a2-b5c9-b87a8e8a90a9)

* We are calculating in terms of **values**.

3) calculate Eigen Vectors and values.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/18b3a7d9-61a8-4034-9b47-94baeb22704c)

* We have to find the values of **V1, V2 and V3**.
* Eigen Values -> Lambda1, Lambda2, Lambda3.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/37dcf000-0e1e-475e-bda9-332c4b743a4e)

* Put value of each eigen value to find vector

4) Normalize Eigen Vector

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d752c68b-eb60-46a9-b54c-6223b24b1b1a)

* Formula [**VERY IMPORTANT**]

5) Design New Dataset

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/3c4787e9-57b0-493c-8d34-019d679e9a26)

* Will see using a **question**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/a6b8b701-0a65-457e-99da-5f4d33c64f70)

* Question.
* N = 4.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/80b10dde-88a9-4d36-9cb2-3a415b07d41b)

* Mean.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f2d6b1f9-ee4b-45ff-be2b-7380454e6033)

* Covariance between **X1, X1**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dd08d951-83bc-4c82-90fa-89a26dd98131)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/628ac367-70c3-4583-9370-a6a79bdf33c1)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b50c2221-0d97-4c56-bce5-6d65f8a64cf2)

* Covariance between **X1, X2**.
* Instead of **8.8** would be **8.5**.
* Covariance of **X2, X1** is **same** as Covariance of **X1, X2**..
* Covariance of **X2, X2** is **23**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/45620ebc-9c85-4a8b-8921-c1865426d3c8)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/521fea9d-9ba4-43bb-a832-08d7ab6cb639)

* I -> Identify matrix
* We have to calculate the **determinant** of the matrix.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/95291453-fd85-4aa8-b929-87bb0bb18ee8)

* We will get a **quadratic equation** and from that we will find the **roots of the lambda**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2a7a9298-4dbc-46d3-af8f-b97d2b9dbb0d)

* We will equate the equations with **zero(0)**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/524a2670-bc8b-44a8-a111-c9851129121c)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/c1ceb2b4-2414-48cf-ad02-c1f9e518dc3c)

* Final Vector.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/92c555b3-4228-4b21-8297-b5ba34a4d150)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/713c41a5-bd1a-4c62-a2b4-d8c2b55090a5)

* We have to select **one eigen vector** and we have to select that **eigen vector** which is **max/high**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2352b522-7226-4fa2-9445-29ac4a013cb4)

* **e1** vector.
* We are not taking **e2** because **e1** is a **principal component**.
* **e2** is a **second principal component**.
* From every **principal component** a line is drawn. **e2** will give us **two lines**.
* We have to convert the **2D** into **1D**. All of the points should be in a **single line**.
* Which line we should take?

> Take the line which has **higher eigen value**. That is the **concept**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/d27d9d3e-08c5-4885-9437-84f24f061ec3)

* We don't have the requirement of **two lines**.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2e8f4768-6f71-4d41-9ae2-0b2fbd713497)

* Typo in **e1** value before.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/f06f6113-544f-40fe-8ac9-52ee1e9b16c4)

* **e1 and e2** are **perpendicular** to each other.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/2863b1a9-da5c-424d-8ad7-6ff3cc456559)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/745b4e48-588b-4a66-947c-5063d1f9d0c8)

* Concept of principle component analysis.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/dd3c38b7-7ded-4c7e-86a2-918ddc7671c7)

## LDA

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/8d0db786-faf7-4e30-8765-85cc4858413d)
![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/91f7f956-878c-463b-b808-39a83e21a88b)

* LDA.
* If we have **n** classes then we have to take **(n - 1)** points.

![image](https://github.com/arghanath007/Data-Structure-and-Algorithms/assets/54589605/b7d6c86e-1482-4616-95e2-656d2e105625)

* We have to do **max of 'SB'**  and we have to do **min. of 'SW'**.

## sample-paper-question-analysis-of-aiml (15)

































 












